{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECKAJiLXiTlN"
   },
   "source": [
    "## Hardware check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "e7odgm5VsOsb",
    "outputId": "cd4abc44-f4d3-43d2-fffb-8d38304e09f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 20 22:32:07 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   30C    P0              40W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-32GB           On  | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   32C    P0              41W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2504      G   /usr/libexec/Xorg                             8MiB |\n",
      "|    1   N/A  N/A      2504      G   /usr/libexec/Xorg                             8MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# gpu check\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oEEUeIW3sOsc",
    "outputId": "2a9ba788-fe62-482d-fab1-6490901982af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of cores\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count() \n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.7\n"
     ]
    }
   ],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY9I5eXWeOom"
   },
   "source": [
    "## Environment Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis\n"
     ]
    }
   ],
   "source": [
    "cd /pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RpTg0QzPqqKv",
    "outputId": "59a45a87-7972-422f-9a3b-f6d40ae0fabb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 23:52:28.230461: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-08 23:52:30.609508: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-08 23:53:04.931010: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Lambda\n",
    "from keras.utils import pad_sequences\n",
    "# from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# tqdm.pandas()\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "import pandas as pd\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, pipeline, AutoModel\n",
    "import resources.smart_cond as sc\n",
    "# from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ax1p4f8cUI-s",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = 'Data/sepsis_removed_0.pkl'\n",
    "pkl = pickle.load(open(data_path, 'rb'))\n",
    "data = pkl[0]\n",
    "oc = pkl[1]\n",
    "train_ind = pkl[2]\n",
    "valid_ind = pkl[3]\n",
    "test_ind = pkl[4]\n",
    "embs = pkl[5]\n",
    "del pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/slurm_tmpdir/job_22411740/ipykernel_545646/3991245697.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_data['value'] = embs_list\n",
      "/scratch/slurm_tmpdir/job_22411740/ipykernel_545646/3991245697.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = text_data.append(physio_data, ignore_index=False)\n"
     ]
    }
   ],
   "source": [
    "text_data = data[data['variable'] == 'Text']\n",
    "embs_list = []\n",
    "\n",
    "for emb in embs:\n",
    "    embs_list.append(emb)\n",
    "\n",
    "text_data['value'] = embs_list\n",
    "physio_data = data[data['variable'] != 'Text']\n",
    "\n",
    "del data\n",
    "data = text_data.append(physio_data, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "114564it [00:00, 791559.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len 880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19267073it [00:20, 961908.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter labeled data in first 24h.\n",
    "data = data.loc[data.ts_ind.isin(np.concatenate((train_ind, valid_ind, test_ind), axis=-1))]\n",
    "data = data.loc[(data.hour>=0)&(data.hour<=24)]\n",
    "oc = oc.loc[oc.ts_ind.isin(np.concatenate((train_ind, valid_ind, test_ind), axis=-1))]\n",
    "# Get y and N.\n",
    "y = np.array(oc.sort_values(by='ts_ind')['in_hospital_sepsis']).astype('float32')\n",
    "N = data.ts_ind.max() + 1\n",
    "# Get static data with mean fill and missingness indicator.\n",
    "static_varis = ['Age', 'Gender']\n",
    "ii = data.variable.isin(static_varis)\n",
    "static_data = data.loc[ii]\n",
    "data = data.loc[~ii]\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "static_var_to_ind = inv_list(static_varis)\n",
    "D = len(static_varis)\n",
    "demo = np.zeros((N, D))\n",
    "for row in tqdm(static_data.itertuples()):\n",
    "    demo[row.ts_ind, static_var_to_ind[row.variable]] = row.value\n",
    "# Normalize static data.\n",
    "means = demo.mean(axis=0, keepdims=True)\n",
    "stds = demo.std(axis=0, keepdims=True)\n",
    "stds = (stds==0)*1 + (stds!=0)*stds\n",
    "demo = (demo-means)/stds\n",
    "# Trim to max len.\n",
    "data = data.sample(frac=1)\n",
    "data = data.groupby('ts_ind').head(880)\n",
    "# Get N, V, var_to_ind.\n",
    "N = data.ts_ind.max() + 1\n",
    "varis = sorted(list(set(data.variable)))\n",
    "V = len(varis)\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "var_to_ind = inv_list(varis, start=1)\n",
    "data['vind'] = data.variable.map(var_to_ind)\n",
    "data = data[['ts_ind', 'vind', 'hour', 'value']].sort_values(by=['ts_ind', 'vind', 'hour'])\n",
    "# Add obs index.\n",
    "data = data.sort_values(by=['ts_ind']).reset_index(drop=True)\n",
    "data = data.reset_index().rename(columns={'index':'obs_ind'})\n",
    "data = data.merge(data.groupby('ts_ind').agg({'obs_ind':'min'}).reset_index().rename(columns={ \\\n",
    "                                                            'obs_ind':'first_obs_ind'}), on='ts_ind')\n",
    "data['obs_ind'] = data['obs_ind'] - data['first_obs_ind']\n",
    "# Find max_len.\n",
    "max_len = data.obs_ind.max()+1\n",
    "print ('max_len', max_len)\n",
    "# Generate times_ip and values_ip matrices.\n",
    "# times_inp = np.zeros((N, max_len), dtype='float32')\n",
    "# values_inp = np.zeros((N, max_len), dtype='float32')\n",
    "# varis_inp = np.zeros((N, max_len), dtype='int32')\n",
    "texts_inp = np.empty([N, max_len], dtype=object)\n",
    "for row in tqdm(data.itertuples()):\n",
    "    ts_ind = row.ts_ind\n",
    "    l = row.obs_ind\n",
    "    # times_inp[ts_ind, l] = row.hour\n",
    "    # if isinstance(row.value, str):\n",
    "    if row.vind == 124:\n",
    "        # values_inp[ts_ind, l] = 1.0\n",
    "        # print(row.value)\n",
    "        texts_inp[ts_ind, l] = row.value\n",
    "    else:\n",
    "        # values_inp[ts_ind, l] = row.value\n",
    "        texts_inp[ts_ind, l] = None\n",
    "    # varis_inp[ts_ind, l] = row.vind\n",
    "    \n",
    "data.drop(columns=['obs_ind', 'first_obs_ind'], inplace=True)\n",
    "# Generate 3 sets of inputs and outputs.\n",
    "# train_ip = [ip[train_ind] for ip in [demo, times_inp, values_inp, varis_inp, texts_inp]]\n",
    "# valid_ip = [ip[valid_ind] for ip in [demo, times_inp, values_inp, varis_inp, texts_inp]]\n",
    "# test_ip = [ip[test_ind] for ip in [demo, times_inp, values_inp, varis_inp, texts_inp]]\n",
    "# del times_inp, values_inp, varis_inp\n",
    "train_ip = [ip[train_ind] for ip in [texts_inp]]\n",
    "valid_ip = [ip[valid_ind] for ip in [texts_inp]]\n",
    "test_ip = [ip[test_ind] for ip in [texts_inp]]\n",
    "del texts_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36551/36551 [00:01<00:00, 20725.11it/s]\n"
     ]
    }
   ],
   "source": [
    "train_text_emb_list = train_ip[0]\n",
    "train_text_embs = []\n",
    "\n",
    "for l in tqdm(train_text_emb_list):\n",
    "    tmp = []\n",
    "    for i in l:\n",
    "        # get rid of the None\n",
    "        if i is not None:\n",
    "            tmp.append(i)\n",
    "    if tmp == []:\n",
    "        tmp = [np.array([0.0])]\n",
    "    train_text_embs.append(np.concatenate(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9262/9262 [00:00<00:00, 20622.32it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_text_emb_list = valid_ip[0]\n",
    "valid_text_embs = []\n",
    "\n",
    "for l in tqdm(valid_text_emb_list):\n",
    "    tmp = []\n",
    "    for i in l:\n",
    "        # get rid of the None\n",
    "        if i is not None:\n",
    "            tmp.append(i)\n",
    "    if tmp == []:\n",
    "        tmp = [np.array([0.0])]\n",
    "    valid_text_embs.append(np.concatenate(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11469/11469 [00:00<00:00, 20590.04it/s]\n"
     ]
    }
   ],
   "source": [
    "test_text_emb_list = test_ip[0]\n",
    "test_text_embs = []\n",
    "\n",
    "for l in tqdm(test_text_emb_list):\n",
    "    tmp = []\n",
    "    for i in l:\n",
    "        # get rid of the None\n",
    "        if i is not None:\n",
    "            tmp.append(i)\n",
    "    if tmp == []:\n",
    "        tmp = [np.array([0.0])]\n",
    "    test_text_embs.append(np.concatenate(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36551, 33792)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding\n",
    "max_len = 33792\n",
    "# padding\n",
    "padded_train = pad_sequences(train_text_embs, maxlen=max_len, dtype='float32', padding='post')\n",
    "padded_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9262, 33792)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding\n",
    "max_len = 33792\n",
    "# padding\n",
    "padded_valid = pad_sequences(valid_text_embs, maxlen=max_len, dtype='float32', padding='post')\n",
    "padded_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11469, 33792)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding\n",
    "max_len = 33792\n",
    "# padding\n",
    "padded_test = pad_sequences(test_text_embs, maxlen=max_len, dtype='float32', padding='post')\n",
    "padded_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dump to pkl, update sepsis_removed_0.pkl\n",
    "pickle.dump([padded_train, padded_valid, padded_test], open('Data/classification_embs.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = 'Data/classification_embs.pkl'\n",
    "train_text, valid_text, test_text = pickle.load(open(data_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36551, 33792)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
