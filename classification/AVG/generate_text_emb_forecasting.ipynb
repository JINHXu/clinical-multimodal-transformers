{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECKAJiLXiTlN"
   },
   "source": [
    "## Hardware check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "e7odgm5VsOsb",
    "outputId": "cd4abc44-f4d3-43d2-fffb-8d38304e09f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr  8 13:08:46 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000000:3A:00.0 Off |                    0 |\n",
      "| N/A   31C    P0              41W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-32GB           On  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   32C    P0              41W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2-32GB           On  | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   30C    P0              40W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2-32GB           On  | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   32C    P0              41W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2516      G   /usr/libexec/Xorg                             8MiB |\n",
      "|    1   N/A  N/A      2516      G   /usr/libexec/Xorg                             8MiB |\n",
      "|    2   N/A  N/A      2516      G   /usr/libexec/Xorg                             8MiB |\n",
      "|    3   N/A  N/A      2516      G   /usr/libexec/Xorg                             8MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# gpu check\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oEEUeIW3sOsc",
    "outputId": "2a9ba788-fe62-482d-fab1-6490901982af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of cores\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count() \n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.7\n"
     ]
    }
   ],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY9I5eXWeOom"
   },
   "source": [
    "## Environment Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis\n"
     ]
    }
   ],
   "source": [
    "cd /pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RpTg0QzPqqKv",
    "outputId": "59a45a87-7972-422f-9a3b-f6d40ae0fabb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:00:02.303993: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-08 10:00:02.351161: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-08 10:00:03.466770: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import pad_sequences\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylFHWoydK5S9"
   },
   "source": [
    "### Version Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AeG1PfTVsOsd",
    "outputId": "5bea12e5-90f1-463b-89f0-ab5e02d42208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf. __version__)\n",
    "\n",
    "pickle.format_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ax1p4f8cUI-s",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = 'Data/sepsis_removed_0.pkl'\n",
    "pkl = pickle.load(open(data_path, 'rb'))\n",
    "data = pkl[0]\n",
    "oc = pkl[1]\n",
    "train_ind = pkl[2]\n",
    "valid_ind = pkl[3]\n",
    "test_ind = pkl[4]\n",
    "# embs = pkl[5]\n",
    "del pkl\n",
    "data_path = 'Data/CLS_emb_keywords_reserved.pkl'\n",
    "pkl = pickle.load(open(data_path, 'rb'))\n",
    "embs = pkl[0]\n",
    "del pkl\n",
    "text_data = data[data['variable'] == 'Text']\n",
    "text_data\n",
    "embs_list = []\n",
    "\n",
    "for emb in embs:\n",
    "    embs_list.append(emb)\n",
    "\n",
    "text_data['value'] = embs_list\n",
    "text_data\n",
    "physio_data = data[data['variable'] != 'Text']\n",
    "physio_data\n",
    "del data\n",
    "data = text_data.append(physio_data, ignore_index=False)\n",
    "pred_window = 2 # hours\n",
    "obs_windows = range(20, 124, 4)\n",
    "\n",
    "# Remove test patients.\n",
    "data = data.merge(oc[['ts_ind', 'SUBJECT_ID']], on='ts_ind', how='left')\n",
    "test_sub = oc.loc[oc.ts_ind.isin(test_ind)].SUBJECT_ID.unique()\n",
    "data = data.loc[~data.SUBJECT_ID.isin(test_sub)]\n",
    "oc = oc.loc[~oc.SUBJECT_ID.isin(test_sub)]\n",
    "data.drop(columns=['SUBJECT_ID', 'TABLE'], inplace=True)\n",
    "# Get static data with mean fill and missingness indicator.\n",
    "static_varis = ['Age', 'Gender']\n",
    "ii = data.variable.isin(static_varis)\n",
    "static_data = data.loc[ii]\n",
    "data = data.loc[~ii]\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "static_var_to_ind = inv_list(static_varis)\n",
    "D = len(static_varis)\n",
    "N = data.ts_ind.max()+1\n",
    "\n",
    "# Get variable indices.\n",
    "varis = sorted(list(set(data.variable)))\n",
    "V = len(varis)\n",
    "var_to_ind = inv_list(varis, start=1)\n",
    "data['vind'] = data.variable.map(var_to_ind)\n",
    "data = data[['ts_ind', 'vind', 'hour', 'value']].sort_values(by=['ts_ind', 'vind', 'hour'])\n",
    "# Find max_len.\n",
    "fore_max_len = 880\n",
    "# Get forecast inputs and outputs.\n",
    "fore_texts_ip = []\n",
    "fore_inds = []\n",
    "def f(x):\n",
    "    mask = [0 for i in range(V)]\n",
    "    values = [0 for i in range(V)]\n",
    "    for vv in x:\n",
    "        v = int(vv[0])-1\n",
    "        mask[v] = 1\n",
    "        values[v] = vv[1]\n",
    "    return values+mask\n",
    "def pad(x):\n",
    "    return x+[0]*(fore_max_len-len(x))\n",
    "for w in tqdm(obs_windows):\n",
    "    pred_data = data.loc[(data.hour>=w)&(data.hour<=w+pred_window)]\n",
    "    pred_data = pred_data.groupby(['ts_ind', 'vind']).agg({'value':'first'}).reset_index()\n",
    "    pred_data['vind_value'] = pred_data[['vind', 'value']].values.tolist()\n",
    "    pred_data = pred_data.groupby('ts_ind').agg({'vind_value':list}).reset_index()\n",
    "    pred_data['vind_value'] = pred_data['vind_value'].apply(f)    \n",
    "    obs_data = data.loc[(data.hour<w)&(data.hour>=w-24)]\n",
    "    obs_data = obs_data.loc[obs_data.ts_ind.isin(pred_data.ts_ind)]\n",
    "    obs_data = obs_data.groupby('ts_ind').head(fore_max_len)\n",
    "    obs_data = obs_data.groupby('ts_ind').agg({'vind':list, 'hour':list, 'value':list}).reset_index()\n",
    "    obs_data = obs_data.merge(pred_data, on='ts_ind')\n",
    "    for col in ['vind', 'hour', 'value']:\n",
    "        obs_data[col] = obs_data[col].apply(pad)\n",
    "    fore_inds.append(np.array(list(obs_data.ts_ind)))\n",
    "    \n",
    "    matrix = list(obs_data.value)\n",
    "    obs_strings = []\n",
    "    for l in matrix:\n",
    "        string_list = []\n",
    "        for value in l:\n",
    "            if not np.isscalar(value):\n",
    "            # if isinstance(value, str):\n",
    "                string_list.append(value)\n",
    "        obs_strings.append(string_list)\n",
    "    del matrix\n",
    "    fore_texts_ip.append(np.array(obs_strings)) \n",
    "del data\n",
    "fore_texts_ip = np.concatenate(fore_texts_ip, axis=0)\n",
    "fore_inds = np.concatenate(fore_inds, axis=0)\n",
    "# Get train and valid ts_ind for forecast task.\n",
    "train_sub = oc.loc[oc.ts_ind.isin(train_ind)].SUBJECT_ID.unique()\n",
    "valid_sub = oc.loc[oc.ts_ind.isin(valid_ind)].SUBJECT_ID.unique()\n",
    "rem_sub = oc.loc[~oc.SUBJECT_ID.isin(np.concatenate((train_ind, valid_ind)))].SUBJECT_ID.unique()\n",
    "bp = int(0.8*len(rem_sub))\n",
    "train_sub = np.concatenate((train_sub, rem_sub[:bp]))\n",
    "valid_sub = np.concatenate((valid_sub, rem_sub[bp:]))\n",
    "train_ind = oc.loc[oc.SUBJECT_ID.isin(train_sub)].ts_ind.unique() # Add remaining ts_ind s of train subjects.\n",
    "valid_ind = oc.loc[oc.SUBJECT_ID.isin(valid_sub)].ts_ind.unique() # Add remaining ts_ind s of train subjects.\n",
    "# Generate 3 sets of inputs and outputs.\n",
    "train_ind = np.argwhere(np.in1d(fore_inds, train_ind)).flatten()\n",
    "valid_ind = np.argwhere(np.in1d(fore_inds, valid_ind)).flatten()\n",
    "fore_train_ip = [ip[train_ind] for ip in [fore_texts_ip]]\n",
    "fore_valid_ip = [ip[valid_ind] for ip in [fore_texts_ip]]\n",
    "del fore_texts_ip\n",
    "\n",
    "fore_train_text_ip = fore_train_ip[0]\n",
    "fore_valid_text_ip = fore_valid_ip[0]\n",
    "del fore_train_ip, fore_valid_ip\n",
    "train_text_embs = []\n",
    "\n",
    "for obs in tqdm(fore_train_text_ip):\n",
    "    if len(obs) < 50:\n",
    "        for i in range(50 - len(obs)):\n",
    "            obs.append(np.array([0.0]*768))\n",
    "    train_text_embs.append(np.array(obs))\n",
    "valid_text_embs = []\n",
    "\n",
    "for obs in tqdm(fore_valid_text_ip):\n",
    "    if len(obs) < 50:\n",
    "        for i in range(50 - len(obs)):\n",
    "            obs.append(np.array([0.0]*768))\n",
    "    valid_text_embs.append(np.array(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max len\n",
    "max_len = 0\n",
    "for obs in fore_train_text_ip:\n",
    "    if len(obs) > max_len:\n",
    "        max_len = len(obs)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max len\n",
    "max_len = 0\n",
    "for obs in fore_valid_text_ip:\n",
    "    if len(obs) > max_len:\n",
    "        max_len = len(obs)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449482/449482 [15:01<00:00, 498.45it/s]\n"
     ]
    }
   ],
   "source": [
    "train_text_embs = []\n",
    "\n",
    "for obs in tqdm(fore_train_text_ip):\n",
    "    if len(obs) < 50:\n",
    "        for i in range(50 - len(obs)):\n",
    "            obs.append(np.array([0.0]*768))\n",
    "    train_text_embs.append(np.array(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dump to pkl, update sepsis_removed_0.pkl\n",
    "pickle.dump([train_text_embs], open('Data/text_emb_input_train_1_2d.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Ctd5oKMQUI-t",
    "outputId": "002f0508-07bd-4606-b628-54787bbe37be",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136823/136823 [03:16<00:00, 696.74it/s] \n"
     ]
    }
   ],
   "source": [
    "valid_text_embs = []\n",
    "\n",
    "for obs in tqdm(fore_valid_text_ip):\n",
    "    if len(obs) < 50:\n",
    "        for i in range(50 - len(obs)):\n",
    "            obs.append(np.array([0.0]*768))\n",
    "    valid_text_embs.append(np.array(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dump to pkl, update sepsis_removed_0.pkl\n",
    "pickle.dump([valid_text_embs], open('Data/text_emb_input_val_1_2d.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/268823753.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_data['value'] = embs_list\n",
      "/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/268823753.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = text_data.append(physio_data, ignore_index=False)\n"
     ]
    }
   ],
   "source": [
    "data_path = 'Data/sepsis_removed_0.pkl'\n",
    "pkl = pickle.load(open(data_path, 'rb'))\n",
    "data = pkl[0]\n",
    "oc = pkl[1]\n",
    "train_ind = pkl[2]\n",
    "valid_ind = pkl[3]\n",
    "test_ind = pkl[4]\n",
    "# embs = pkl[5]\n",
    "del pkl\n",
    "\n",
    "# embs\n",
    "data_path = 'Data/CLS_emb_keywords_reserved.pkl'\n",
    "pkl = pickle.load(open(data_path, 'rb'))\n",
    "embs = pkl[0]\n",
    "del pkl\n",
    "\n",
    "text_data = data[data['variable'] == 'Text']\n",
    "embs_list = []\n",
    "for emb in embs:\n",
    "    embs_list.append(emb)\n",
    "text_data['value'] = embs_list\n",
    "physio_data = data[data['variable'] != 'Text']\n",
    "del data\n",
    "data = text_data.append(physio_data, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26 [00:00<?, ?it/s]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      "  4%|▍         | 1/26 [00:05<02:09,  5.20s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      "  8%|▊         | 2/26 [00:10<02:05,  5.24s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 12%|█▏        | 3/26 [00:15<01:59,  5.21s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 15%|█▌        | 4/26 [00:20<01:49,  4.99s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 19%|█▉        | 5/26 [00:24<01:37,  4.63s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 23%|██▎       | 6/26 [00:28<01:28,  4.43s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 27%|██▋       | 7/26 [00:31<01:18,  4.15s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 31%|███       | 8/26 [00:35<01:09,  3.88s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 35%|███▍      | 9/26 [00:38<01:01,  3.61s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 38%|███▊      | 10/26 [00:41<00:54,  3.39s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 42%|████▏     | 11/26 [00:43<00:48,  3.22s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 46%|████▌     | 12/26 [00:46<00:42,  3.05s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 50%|█████     | 13/26 [00:49<00:37,  2.89s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 54%|█████▍    | 14/26 [00:51<00:33,  2.76s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 58%|█████▊    | 15/26 [00:53<00:28,  2.60s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 62%|██████▏   | 16/26 [00:55<00:24,  2.41s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 65%|██████▌   | 17/26 [00:57<00:21,  2.34s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 69%|██████▉   | 18/26 [01:00<00:18,  2.26s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 73%|███████▎  | 19/26 [01:02<00:15,  2.18s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 77%|███████▋  | 20/26 [01:03<00:12,  2.04s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 81%|████████  | 21/26 [01:05<00:09,  1.99s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 85%|████████▍ | 22/26 [01:07<00:07,  1.87s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 88%|████████▊ | 23/26 [01:09<00:05,  1.84s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 92%|█████████▏| 24/26 [01:10<00:03,  1.75s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      " 96%|█████████▌| 25/26 [01:12<00:01,  1.73s/it]/scratch/slurm_tmpdir/job_23331787/ipykernel_47459/2484361121.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(obs_strings))\n",
      "100%|██████████| 26/26 [01:13<00:00,  2.83s/it]\n"
     ]
    }
   ],
   "source": [
    "pred_window = 2  # hours\n",
    "obs_windows = range(20, 124, 4)\n",
    "\n",
    "# Remove train, val patients\n",
    "data = data.merge(oc[['ts_ind', 'SUBJECT_ID']], on='ts_ind', how='left')\n",
    "train_sub = oc.loc[oc.ts_ind.isin(train_ind)].SUBJECT_ID.unique()\n",
    "valid_sub = oc.loc[oc.ts_ind.isin(valid_ind)].SUBJECT_ID.unique()\n",
    "data = data.loc[~data.SUBJECT_ID.isin(train_sub)]\n",
    "data = data.loc[~data.SUBJECT_ID.isin(valid_sub)]\n",
    "oc = oc.loc[~oc.SUBJECT_ID.isin(train_sub)]\n",
    "oc = oc.loc[~oc.SUBJECT_ID.isin(valid_sub)]\n",
    "\n",
    "data.drop(columns=['SUBJECT_ID', 'TABLE'], inplace=True)\n",
    "# Get static data with mean fill and missingness indicator.\n",
    "static_varis = ['Age', 'Gender']\n",
    "ii = data.variable.isin(static_varis)\n",
    "static_data = data.loc[ii]\n",
    "data = data.loc[~ii]\n",
    "\n",
    "\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "\n",
    "\n",
    "static_var_to_ind = inv_list(static_varis)\n",
    "D = len(static_varis)\n",
    "N = data.ts_ind.max()+1\n",
    "\n",
    "# Get variable indices.\n",
    "varis = sorted(list(set(data.variable)))\n",
    "V = len(varis)\n",
    "var_to_ind = inv_list(varis, start=1)\n",
    "data['vind'] = data.variable.map(var_to_ind)\n",
    "data = data[['ts_ind', 'vind', 'hour', 'value']\n",
    "            ].sort_values(by=['ts_ind', 'vind', 'hour'])\n",
    "# Find max_len.\n",
    "fore_max_len = 880\n",
    "# Get forecast inputs and outputs.\n",
    "fore_texts_ip = []\n",
    "fore_inds = []\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    mask = [0 for i in range(V)]\n",
    "    values = [0 for i in range(V)]\n",
    "    for vv in x:\n",
    "        v = int(vv[0])-1\n",
    "        mask[v] = 1\n",
    "        values[v] = vv[1]\n",
    "    return values+mask\n",
    "\n",
    "\n",
    "def pad(x):\n",
    "    return x+[0]*(fore_max_len-len(x))\n",
    "\n",
    "\n",
    "for w in tqdm(obs_windows):\n",
    "    pred_data = data.loc[(data.hour >= w) & (data.hour <= w+pred_window)]\n",
    "    pred_data = pred_data.groupby(['ts_ind', 'vind']).agg(\n",
    "        {'value': 'first'}).reset_index()\n",
    "    pred_data['vind_value'] = pred_data[['vind', 'value']].values.tolist()\n",
    "    pred_data = pred_data.groupby('ts_ind').agg(\n",
    "        {'vind_value': list}).reset_index()\n",
    "    pred_data['vind_value'] = pred_data['vind_value'].apply(f)\n",
    "    obs_data = data.loc[(data.hour < w) & (data.hour >= w-24)]\n",
    "    obs_data = obs_data.loc[obs_data.ts_ind.isin(pred_data.ts_ind)]\n",
    "    obs_data = obs_data.groupby('ts_ind').head(fore_max_len)\n",
    "    obs_data = obs_data.groupby('ts_ind').agg(\n",
    "        {'vind': list, 'hour': list, 'value': list}).reset_index()\n",
    "    obs_data = obs_data.merge(pred_data, on='ts_ind')\n",
    "    for col in ['vind', 'hour', 'value']:\n",
    "        obs_data[col] = obs_data[col].apply(pad)\n",
    "    fore_inds.append(np.array(list(obs_data.ts_ind)))\n",
    "\n",
    "    matrix = list(obs_data.value)\n",
    "    obs_strings = []\n",
    "    for l in matrix:\n",
    "        string_list = []\n",
    "        for value in l:\n",
    "            if not np.isscalar(value):\n",
    "            # if isinstance(value, str):\n",
    "                string_list.append(value)\n",
    "        obs_strings.append(string_list)\n",
    "    del matrix\n",
    "    fore_texts_ip.append(np.array(obs_strings))\n",
    "del data\n",
    "\n",
    "fore_texts_ip = np.concatenate(fore_texts_ip, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131920,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fore_texts_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max len\n",
    "max_len = 0\n",
    "for obs in fore_texts_ip:\n",
    "    if len(obs) > max_len:\n",
    "        max_len = len(obs)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131920/131920 [04:04<00:00, 538.55it/s]\n"
     ]
    }
   ],
   "source": [
    "train_text_embs = []\n",
    "\n",
    "for obs in tqdm(fore_texts_ip):\n",
    "    if len(obs) < 50:\n",
    "        for i in range(50 - len(obs)):\n",
    "            obs.append(np.array([0.0]*768))\n",
    "    train_text_embs.append(np.array(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131920, 50, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_embs_np = np.array(train_text_embs)\n",
    "train_text_embs_np.shape\n",
    "del train_text_embs_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump to pkl, update sepsis_removed_0.pkl\n",
    "pickle.dump([train_text_embs], open('Data/text_emb_input_test_1_2d.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
