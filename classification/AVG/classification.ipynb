{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "e7odgm5VsOsb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun  5 13:50:10 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  |   00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   33C    P0             41W /  300W |      17MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-32GB           On  |   00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   36C    P0             42W /  300W |      17MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1918      G   /usr/libexec/Xorg                              17MiB |\n",
      "|    1   N/A  N/A      1918      G   /usr/libexec/Xorg                              17MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# gpu check\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oEEUeIW3sOsc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of cores\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count() \n",
    "cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY9I5eXWeOom"
   },
   "source": [
    "## Environment Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis\n"
     ]
    }
   ],
   "source": [
    "cd /pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 13:50:10.865622: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-05 13:50:11.427918: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-05 13:50:13.131275: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Lambda\n",
    "# from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "import pandas as pd\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, pipeline, AutoModel\n",
    "import resources.smart_cond as sc\n",
    "# from google.colab import files\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Data/CLS/cls_data.pkl'\n",
    "train_ip, valid_ip, test_ip, train_op, valid_op, test_op = pickle.load(open(data_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ip = train_ip[:4]\n",
    "valid_ip = valid_ip[:4]\n",
    "test_ip = test_ip[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'CLS/AVG/classification_embs.pkl'\n",
    "train_texts, valid_texts, test_texts = pickle.load(open(data_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ip.append(train_texts)\n",
    "valid_ip.append(valid_texts)\n",
    "test_ip.append(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_res(y_true, y_pred):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    minrp = np.minimum(precision, recall).max()\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    return [roc_auc, pr_auc, minrp]\n",
    "\n",
    "######################################################################################################## \n",
    "######################################################################################################## \n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=[0,1], y=train_op)\n",
    "def mortality_loss(y_true, y_pred):\n",
    "    sample_weights = (1-y_true)*class_weights[0] + y_true*class_weights[1]\n",
    "    bce = K.binary_crossentropy(y_true, y_pred)\n",
    "    return K.mean(sample_weights*bce, axis=-1)\n",
    "######################################################################################################## \n",
    "######################################################################################################## \n",
    "\n",
    "# var_weights = np.sum(fore_train_op[:, V:], axis=0)\n",
    "# var_weights[var_weights==0] = var_weights.max()\n",
    "# var_weights = var_weights.max()/var_weights\n",
    "# var_weights = var_weights.reshape((1, V))\n",
    "def forecast_loss(y_true, y_pred):\n",
    "    return K.sum(y_true[:,V:]*(y_true[:,:V]-y_pred)**2, axis=-1)\n",
    "\n",
    "def get_min_loss(weight):\n",
    "    def min_loss(y_true, y_pred):\n",
    "        return weight*y_pred\n",
    "    return min_loss\n",
    "\n",
    "class CustomCallback(Callback):\n",
    "    def __init__(self, validation_data, batch_size):\n",
    "        self.val_x, self.val_y = validation_data\n",
    "        self.batch_size = batch_size\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.val_x, verbose=0, batch_size=self.batch_size)\n",
    "        if type(y_pred)==type([]):\n",
    "            y_pred = y_pred[0]\n",
    "        precision, recall, thresholds = precision_recall_curve(self.val_y, y_pred)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        roc_auc = roc_auc_score(self.val_y, y_pred)\n",
    "        logs['custom_metric'] = pr_auc + roc_auc\n",
    "        print ('val_aucs:', pr_auc, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Embedding, Activation, Dropout, Softmax, Layer, InputSpec, Input, Dense, Lambda, TimeDistributed, Concatenate, Add\n",
    "from tensorflow.keras import initializers, regularizers, constraints, Model\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow import nn\n",
    "\n",
    "    \n",
    "class CVE(Layer):\n",
    "    def __init__(self, hid_units, output_dim):\n",
    "        self.hid_units = hid_units\n",
    "        self.output_dim = output_dim\n",
    "        super(CVE, self).__init__()\n",
    "        \n",
    "    def build(self, input_shape): \n",
    "        self.W1 = self.add_weight(name='CVE_W1',\n",
    "                            shape=(1, self.hid_units),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        self.b1 = self.add_weight(name='CVE_b1',\n",
    "                            shape=(self.hid_units,),\n",
    "                            initializer='zeros',\n",
    "                            trainable=True)\n",
    "        self.W2 = self.add_weight(name='CVE_W2',\n",
    "                            shape=(self.hid_units, self.output_dim),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        super(CVE, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = K.expand_dims(x, axis=-1)\n",
    "        x = K.dot(K.tanh(K.bias_add(K.dot(x, self.W1), self.b1)), self.W2)\n",
    "        return x\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape + (self.output_dim,)\n",
    "    \n",
    "    \n",
    "class Attention(Layer):\n",
    "    \n",
    "    def __init__(self, hid_dim):\n",
    "        self.hid_dim = hid_dim\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        self.W = self.add_weight(shape=(d, self.hid_dim), name='Att_W',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.hid_dim,), name='Att_b',\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        self.u = self.add_weight(shape=(self.hid_dim,1), name='Att_u',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask, mask_value=-1e30):\n",
    "        attn_weights = K.dot(K.tanh(K.bias_add(K.dot(x,self.W), self.b)), self.u)\n",
    "        mask = K.expand_dims(mask, axis=-1)\n",
    "        attn_weights = mask*attn_weights + (1-mask)*mask_value\n",
    "        attn_weights = K.softmax(attn_weights, axis=-2)\n",
    "        return attn_weights\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1] + (1,)\n",
    "    \n",
    "    \n",
    "class Transformer(Layer):\n",
    "    \n",
    "    def __init__(self, N=2, h=8, dk=None, dv=None, dff=None, dropout=0):\n",
    "        self.N, self.h, self.dk, self.dv, self.dff, self.dropout = N, h, dk, dv, dff, dropout\n",
    "        self.epsilon = K.epsilon() * K.epsilon()\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        if self.dk==None:\n",
    "            self.dk = d//self.h\n",
    "        if self.dv==None:\n",
    "            self.dv = d//self.h\n",
    "        if self.dff==None:\n",
    "            self.dff = 2*d\n",
    "        self.Wq = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wq',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wk = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wk',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wv = self.add_weight(shape=(self.N, self.h, d, self.dv), name='Wv',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wo = self.add_weight(shape=(self.N, self.dv*self.h, d), name='Wo',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.W1 = self.add_weight(shape=(self.N, d, self.dff), name='W1',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b1 = self.add_weight(shape=(self.N, self.dff), name='b1',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.W2 = self.add_weight(shape=(self.N, self.dff, d), name='W2',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b2 = self.add_weight(shape=(self.N, d), name='b2',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.gamma = self.add_weight(shape=(2*self.N,), name='gamma',\n",
    "                                 initializer='ones', trainable=True)\n",
    "        self.beta = self.add_weight(shape=(2*self.N,), name='beta',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        super(Transformer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask, mask_value=-1e-30):\n",
    "        mask = K.expand_dims(mask, axis=-2)\n",
    "        for i in range(self.N):\n",
    "            # MHA\n",
    "            mha_ops = []\n",
    "            for j in range(self.h):\n",
    "                q = K.dot(x, self.Wq[i,j,:,:])\n",
    "                k = K.permute_dimensions(K.dot(x, self.Wk[i,j,:,:]), (0,2,1))\n",
    "                v = K.dot(x, self.Wv[i,j,:,:])\n",
    "                A = K.batch_dot(q,k)\n",
    "                # Mask unobserved steps.\n",
    "                A = mask*A + (1-mask)*mask_value\n",
    "                # Mask for attention dropout.\n",
    "                def dropped_A():\n",
    "                    dp_mask = K.cast((K.random_uniform(shape=array_ops.shape(A))>=self.dropout), K.floatx())\n",
    "                    return A*dp_mask + (1-dp_mask)*mask_value\n",
    "                A = sc.smart_cond(K.learning_phase(), dropped_A, lambda: array_ops.identity(A))\n",
    "                A = K.softmax(A, axis=-1)\n",
    "                mha_ops.append(K.batch_dot(A,v))\n",
    "            conc = K.concatenate(mha_ops, axis=-1)\n",
    "            proj = K.dot(conc, self.Wo[i,:,:])\n",
    "            # Dropout.\n",
    "            proj = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(proj, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(proj))\n",
    "            # Add & LN\n",
    "            x = x+proj\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i] + self.beta[2*i]\n",
    "            # FFN\n",
    "            ffn_op = K.bias_add(K.dot(K.relu(K.bias_add(K.dot(x, self.W1[i,:,:]), self.b1[i,:])), \n",
    "                           self.W2[i,:,:]), self.b2[i,:,])\n",
    "            # Dropout.\n",
    "            ffn_op = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(ffn_op, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(ffn_op))\n",
    "            # Add & LN\n",
    "            x = x+ffn_op\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i+1] + self.beta[2*i+1]            \n",
    "        return x\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "\n",
    "def build_strats(D, max_len, V, d, N, he, dropout, forecast=False):\n",
    "    # demo\n",
    "    demo = Input(shape=(D,))\n",
    "    demo_enc = Dense(2*d, activation='tanh')(demo)\n",
    "    demo_enc = Dense(d, activation='tanh')(demo_enc)\n",
    "    \n",
    "    # text\n",
    "    texts = Input(shape=(33792,))\n",
    "    text_enc = Dense(1000, activation='relu')(texts)\n",
    "    text_enc = Dense(d, activation='relu')(text_enc)\n",
    "    \n",
    "    # triplet\n",
    "    varis = Input(shape=(max_len,))\n",
    "    values = Input(shape=(max_len,))\n",
    "    times = Input(shape=(max_len,))\n",
    "    \n",
    "    varis_emb = Embedding(V+1, d)(varis)\n",
    "    cve_units = int(np.sqrt(d))\n",
    "    values_emb = CVE(cve_units, d)(values)\n",
    "    times_emb = CVE(cve_units, d)(times)\n",
    "    \n",
    "    # comb_emb = Add()([varis_emb, values_emb, times_emb]) # b, L, d\n",
    "    comb_emb = Add()([varis_emb, values_emb, times_emb, text_enc]) # b, L, d\n",
    "#     demo_enc = Lambda(lambda x:K.expand_dims(x, axis=-2))(demo_enc) # b, 1, d\n",
    "#     comb_emb = Concatenate(axis=-2)([demo_enc, comb_emb]) # b, L+1, d\n",
    "    mask = Lambda(lambda x:K.clip(x,0,1))(varis) # b, L\n",
    "#     mask = Lambda(lambda x:K.concatenate((K.ones_like(x)[:,0:1], x), axis=-1))(mask) # b, L+1\n",
    "    cont_emb = Transformer(N, he, dk=None, dv=None, dff=None, dropout=dropout)(comb_emb, mask=mask)\n",
    "    attn_weights = Attention(2*d)(cont_emb, mask=mask)\n",
    "    fused_emb = Lambda(lambda x:K.sum(x[0]*x[1], axis=-2))([cont_emb, attn_weights])\n",
    "    \n",
    "#     # embed text input\n",
    "#     texts = Input(shape=(33792,))\n",
    "#     text_enc = Dense(1000, activation='relu')(texts)\n",
    "#     text_enc = Dense(d, activation='relu')(text_enc)\n",
    "    \n",
    "    conc = Concatenate(axis=-1)([fused_emb, text_enc, demo_enc])\n",
    "    fore_op = Dense(V)(conc)\n",
    "    op = Dense(1, activation='sigmoid')(fore_op)\n",
    "    model = Model([demo, times, values, varis, texts], op)\n",
    "    if forecast:\n",
    "        fore_model = Model([demo, times, values, varis, texts], fore_op)\n",
    "        return [model, fore_model]\n",
    "    return model\n",
    "\n",
    "# To tune:\n",
    "# 1. Transformer parameters. (N, h, dropout)\n",
    "# 2. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "D = 2\n",
    "max_len = 880\n",
    "V = 134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 0 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "CLS/AVG/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_10ld.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 13:50:35.572968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31117 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b2:00.0, compute capability: 7.0\n",
      "2024-06-05 13:50:35.573795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 31117 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b3:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 13:50:51.743403: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x14c95df6dd00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-05 13:50:51.743444: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-06-05 13:50:51.743453: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-06-05 13:50:51.756060: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-05 13:50:51.780789: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
      "2024-06-05 13:50:52.025077: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - ETA: 0s - loss: 0.6058val_aucs: 0.36992605982259336 0.8191540653079113\n",
      "115/115 [==============================] - 23s 78ms/step - loss: 0.6058 - custom_metric: 1.1891\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4564val_aucs: 0.4142308330659521 0.8287822339104389\n",
      "115/115 [==============================] - 6s 54ms/step - loss: 0.4564 - custom_metric: 1.2430\n",
      "Epoch 3/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4172val_aucs: 0.38705632297974363 0.8379428738403096\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.4172 - custom_metric: 1.2250\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3624val_aucs: 0.4254983264201154 0.8317627291986266\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.3624 - custom_metric: 1.2573\n",
      "Epoch 5/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3176val_aucs: 0.3419594986789781 0.8147855942727737\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3176 - custom_metric: 1.1567\n",
      "Epoch 6/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2953val_aucs: 0.31902849329680183 0.8130031412082694\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2953 - custom_metric: 1.1320\n",
      "Epoch 7/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2451val_aucs: 0.3538713526339471 0.8242968807071371\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2451 - custom_metric: 1.1782\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2129val_aucs: 0.3224852678473271 0.801577909270217\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2129 - custom_metric: 1.1241\n",
      "Epoch 9/1000\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.1709val_aucs: 0.37841456303678245 0.8033457520637007\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.1710 - custom_metric: 1.1818\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1578val_aucs: 0.3418120192269411 0.8068083862955658\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1578 - custom_metric: 1.1486\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1119val_aucs: 0.30835579100650723 0.8012418730367449\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1119 - custom_metric: 1.1096\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1024val_aucs: 0.31507144721614383 0.7985828037110088\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1024 - custom_metric: 1.1137\n",
      "Epoch 13/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1215val_aucs: 0.28687064557054265 0.7878588647819417\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1215 - custom_metric: 1.0747\n",
      "Epoch 14/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1554val_aucs: 0.3329201530389055 0.8051428153992257\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1554 - custom_metric: 1.1381\n",
      "Test res 0.8554508923228817 0.4110018804236198 0.4419512195121951\n",
      "[[0.8554508923228817, 0.4110018804236198, 0.4419512195121951]]\n",
      "Repeat 1 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "CLS/AVG/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_10ld.h5\n",
      "Epoch 1/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.5409val_aucs: 0.511232261695684 0.9046575024650543\n",
      "115/115 [==============================] - 15s 69ms/step - loss: 0.5409 - custom_metric: 1.4159\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4546val_aucs: 0.5275349690561021 0.9133924946348819\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.4546 - custom_metric: 1.4409\n",
      "Epoch 3/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4080val_aucs: 0.5560648465766093 0.9196450321907083\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.4080 - custom_metric: 1.4757\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3734val_aucs: 0.5632805232193262 0.9104460298126559\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3734 - custom_metric: 1.4737\n",
      "Epoch 5/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3181val_aucs: 0.5695575176032631 0.905747926454382\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3181 - custom_metric: 1.4753\n",
      "Epoch 6/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2789val_aucs: 0.5871595195757325 0.9126848790673394\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2789 - custom_metric: 1.4998\n",
      "Epoch 7/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2240val_aucs: 0.5781937715092788 0.9100284206252538\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2240 - custom_metric: 1.4882\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2040val_aucs: 0.5958478114529083 0.9081375790267386\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2040 - custom_metric: 1.5040\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1449val_aucs: 0.5703035542455791 0.90117742590337\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.1449 - custom_metric: 1.4715\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1245val_aucs: 0.5743360466296319 0.8935676584884868\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.1245 - custom_metric: 1.4679\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1158val_aucs: 0.5240579037850684 0.8921060263325793\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1158 - custom_metric: 1.4162\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1342val_aucs: 0.5691894389593996 0.9011194246273418\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1342 - custom_metric: 1.4703\n",
      "Epoch 13/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0979val_aucs: 0.5733922579795745 0.9065135432979526\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.0979 - custom_metric: 1.4799\n",
      "Epoch 14/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0852val_aucs: 0.5503980304166732 0.9088683951046922\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.0852 - custom_metric: 1.4593\n",
      "Epoch 15/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0707val_aucs: 0.5411232134963669 0.9062235369178122\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.0707 - custom_metric: 1.4473\n",
      "Epoch 16/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0315val_aucs: 0.5506998289762297 0.9081491792819443\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.0315 - custom_metric: 1.4588\n",
      "Epoch 17/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0350val_aucs: 0.5423147564909677 0.898555768226901\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.0350 - custom_metric: 1.4409\n",
      "Epoch 18/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0292val_aucs: 0.5439215833815045 0.8991009802215649\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.0292 - custom_metric: 1.4430\n",
      "Test res 0.8457278078626137 0.3790272726471662 0.4220272904483431\n",
      "[[0.8554508923228817, 0.4110018804236198, 0.4419512195121951], [0.8457278078626137, 0.3790272726471662, 0.4220272904483431]]\n",
      "Repeat 2 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "CLS/AVG/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_10ld.h5\n",
      "Epoch 1/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.5259val_aucs: 0.3993489261071602 0.8677452718676123\n",
      "115/115 [==============================] - 15s 69ms/step - loss: 0.5259 - custom_metric: 1.2671\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4323val_aucs: 0.4781124527078705 0.8830378250591016\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.4323 - custom_metric: 1.3612\n",
      "Epoch 3/1000\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.3827val_aucs: 0.48124057541184045 0.8726507092198582\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3825 - custom_metric: 1.3539\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3447val_aucs: 0.45438903959290905 0.8739804964539007\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.3447 - custom_metric: 1.3284\n",
      "Epoch 5/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2912val_aucs: 0.4214998537568692 0.8416371158392435\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.2912 - custom_metric: 1.2631\n",
      "Epoch 6/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2333val_aucs: 0.43123497150406187 0.8581412529550827\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2333 - custom_metric: 1.2894\n",
      "Epoch 7/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2320val_aucs: 0.40585999822597174 0.851315011820331\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2320 - custom_metric: 1.2572\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1879val_aucs: 0.39773050385984265 0.8228132387706857\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1879 - custom_metric: 1.2205\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1742val_aucs: 0.4037412364920791 0.8356235224586288\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1742 - custom_metric: 1.2394\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1760val_aucs: 0.39828820751732774 0.8395094562647754\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1760 - custom_metric: 1.2378\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1291val_aucs: 0.3462632480232848 0.8008421985815604\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1291 - custom_metric: 1.1471\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0822val_aucs: 0.3412526286139932 0.815056146572104\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.0822 - custom_metric: 1.1563\n",
      "Test res 0.8707969479266398 0.4405239881092402 0.46875\n",
      "[[0.8554508923228817, 0.4110018804236198, 0.4419512195121951], [0.8457278078626137, 0.3790272726471662, 0.4220272904483431], [0.8707969479266398, 0.4405239881092402, 0.46875]]\n",
      "Repeat 3 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "CLS/AVG/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_10ld.h5\n",
      "Epoch 1/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.5619val_aucs: 0.4955863778912175 0.8562041210166966\n",
      "115/115 [==============================] - 15s 68ms/step - loss: 0.5619 - custom_metric: 1.3518\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4238val_aucs: 0.5178765232857535 0.8611385926984476\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.4238 - custom_metric: 1.3790\n",
      "Epoch 3/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3816val_aucs: 0.4979144442804683 0.8610042382714693\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3816 - custom_metric: 1.3589\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3420val_aucs: 0.5228622067301925 0.8720213012836955\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3420 - custom_metric: 1.3949\n",
      "Epoch 5/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3248val_aucs: 0.4768039669441261 0.8675387490381444\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.3248 - custom_metric: 1.3443\n",
      "Epoch 6/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2867val_aucs: 0.4779585442582293 0.8714105993428847\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2867 - custom_metric: 1.3494\n",
      "Epoch 7/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2451val_aucs: 0.44448349321182207 0.8650715131972689\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2451 - custom_metric: 1.3096\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2231val_aucs: 0.4305786904378003 0.8561796929390642\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2231 - custom_metric: 1.2868\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1847val_aucs: 0.43132166287680884 0.8348539811659521\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.1847 - custom_metric: 1.2662\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1371val_aucs: 0.38928286608856094 0.8388235437812221\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1371 - custom_metric: 1.2281\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1743val_aucs: 0.4375082315409976 0.8654745764782041\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1743 - custom_metric: 1.3030\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1059val_aucs: 0.4386529130960264 0.8626042773563934\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1059 - custom_metric: 1.3013\n",
      "Epoch 13/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1151val_aucs: 0.4344570617246082 0.8569613914233019\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.1151 - custom_metric: 1.2914\n",
      "Epoch 14/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1194val_aucs: 0.4061310135572019 0.8455046230136919\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1194 - custom_metric: 1.2516\n",
      "Test res 0.8602058027166108 0.4177753501911591 0.44015444015444016\n",
      "[[0.8554508923228817, 0.4110018804236198, 0.4419512195121951], [0.8457278078626137, 0.3790272726471662, 0.4220272904483431], [0.8707969479266398, 0.4405239881092402, 0.46875], [0.8602058027166108, 0.4177753501911591, 0.44015444015444016]]\n",
      "Repeat 4 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "CLS/AVG/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_10ld.h5\n",
      "Epoch 1/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.5566val_aucs: 0.36578798226044495 0.8517192848331103\n",
      "115/115 [==============================] - 15s 70ms/step - loss: 0.5566 - custom_metric: 1.2175\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4150val_aucs: 0.3942485035114934 0.8617274512188765\n",
      "115/115 [==============================] - 6s 54ms/step - loss: 0.4150 - custom_metric: 1.2560\n",
      "Epoch 3/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3578val_aucs: 0.3816217829316507 0.8597292929994962\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.3578 - custom_metric: 1.2414\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3081val_aucs: 0.426710532743031 0.8624919639289004\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3081 - custom_metric: 1.2892\n",
      "Epoch 5/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2784val_aucs: 0.408971956100319 0.8649071290810211\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2784 - custom_metric: 1.2739\n",
      "Epoch 6/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2424val_aucs: 0.42720146598919523 0.8653067607248971\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.2424 - custom_metric: 1.2925\n",
      "Epoch 7/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1906val_aucs: 0.35416231824237465 0.8532830608308863\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1906 - custom_metric: 1.2074\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1473val_aucs: 0.3944711592303934 0.853561065452713\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1473 - custom_metric: 1.2480\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1436val_aucs: 0.37102552830791974 0.8527270515872326\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1436 - custom_metric: 1.2238\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1083val_aucs: 0.3499658483210836 0.8455510572863274\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1083 - custom_metric: 1.1955\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0642val_aucs: 0.31287986197826745 0.8372456692092506\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.0642 - custom_metric: 1.1501\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0642val_aucs: 0.35920010193768237 0.8501728841241986\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.0642 - custom_metric: 1.2094\n",
      "Epoch 13/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0586val_aucs: 0.34297140263327064 0.84327489444512\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.0586 - custom_metric: 1.1862\n",
      "Epoch 14/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0353val_aucs: 0.34976392357854624 0.8281410178444216\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.0353 - custom_metric: 1.1779\n",
      "Epoch 15/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1551val_aucs: 0.3825584817740635 0.8473754626170661\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1551 - custom_metric: 1.2299\n",
      "Epoch 16/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0855val_aucs: 0.39382632009059393 0.8404774729379875\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.0855 - custom_metric: 1.2343\n",
      "Test res 0.8578021219782191 0.4227788824232871 0.455078125\n",
      "[[0.8554508923228817, 0.4110018804236198, 0.4419512195121951], [0.8457278078626137, 0.3790272726471662, 0.4220272904483431], [0.8707969479266398, 0.4405239881092402, 0.46875], [0.8602058027166108, 0.4177753501911591, 0.44015444015444016], [0.8578021219782191, 0.4227788824232871, 0.455078125]]\n",
      "Repeat 5 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "CLS/AVG/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_10ld.h5\n",
      "Epoch 1/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.5490val_aucs: 0.4507809182709388 0.8811742088139604\n",
      "115/115 [==============================] - 15s 68ms/step - loss: 0.5490 - custom_metric: 1.3320\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4326val_aucs: 0.5114912428214485 0.8941388149462683\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.4326 - custom_metric: 1.4056\n",
      "Epoch 3/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3908val_aucs: 0.5121474494419536 0.8911811101252094\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3908 - custom_metric: 1.4033\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3425val_aucs: 0.49993082242525283 0.8797816227940451\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3425 - custom_metric: 1.3797\n",
      "Epoch 5/1000\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.2967val_aucs: 0.5106482470715428 0.8920314502612638\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2966 - custom_metric: 1.4027\n",
      "Epoch 6/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2408val_aucs: 0.46085749377081486 0.8798062703342207\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2408 - custom_metric: 1.3407\n",
      "Epoch 7/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2154val_aucs: 0.47434514130304606 0.8784876269348318\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2154 - custom_metric: 1.3528\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1843val_aucs: 0.4983084973608133 0.8815808932268558\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1843 - custom_metric: 1.3799\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1354val_aucs: 0.48479739558955487 0.8686655821748989\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1354 - custom_metric: 1.3535\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1282val_aucs: 0.44128673413115166 0.8752464754017549\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1282 - custom_metric: 1.3165\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1219val_aucs: 0.45548868672576603 0.870982450951395\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.1219 - custom_metric: 1.3265\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1085val_aucs: 0.45970919784358505 0.8871019422261657\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1085 - custom_metric: 1.3468\n",
      "Test res 0.8594622782282193 0.41334630188849497 0.43731778425655976\n",
      "[[0.8554508923228817, 0.4110018804236198, 0.4419512195121951], [0.8457278078626137, 0.3790272726471662, 0.4220272904483431], [0.8707969479266398, 0.4405239881092402, 0.46875], [0.8602058027166108, 0.4177753501911591, 0.44015444015444016], [0.8578021219782191, 0.4227788824232871, 0.455078125], [0.8594622782282193, 0.41334630188849497, 0.43731778425655976]]\n",
      "Repeat 6 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "CLS/AVG/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_10ld.h5\n",
      "Epoch 1/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2515val_aucs: 0.4752002107589571 0.8615616185723584\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2515 - custom_metric: 1.3368\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2096val_aucs: 0.509371875001167 0.8560967671946192\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2096 - custom_metric: 1.3655\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1793val_aucs: 0.4659725624728037 0.8468756780212627\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1793 - custom_metric: 1.3128\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1419val_aucs: 0.4778878941690124 0.8619819917552615\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1419 - custom_metric: 1.3399\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1259val_aucs: 0.44549784345263127 0.8438517031894119\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1259 - custom_metric: 1.2893\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1266val_aucs: 0.42781446196400785 0.8357290084617054\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1266 - custom_metric: 1.2635\n",
      "Epoch 13/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1292val_aucs: 0.44072779816143043 0.8478384682143632\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.1292 - custom_metric: 1.2886\n",
      "Epoch 14/1000\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.1547val_aucs: 0.4774128858509852 0.8530727923627686\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1544 - custom_metric: 1.3305\n",
      "Epoch 15/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0682val_aucs: 0.4790308654742945 0.8501166196571924\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.0682 - custom_metric: 1.3291\n",
      "Test res 0.8529165513553136 0.4078931764986517 0.4427767354596623\n",
      "[[0.8554508923228817, 0.4110018804236198, 0.4419512195121951], [0.8457278078626137, 0.3790272726471662, 0.4220272904483431], [0.8707969479266398, 0.4405239881092402, 0.46875], [0.8602058027166108, 0.4177753501911591, 0.44015444015444016], [0.8578021219782191, 0.4227788824232871, 0.455078125], [0.8594622782282193, 0.41334630188849497, 0.43731778425655976], [0.8554820731360699, 0.42250702187590444, 0.45120772946859905], [0.8529165513553136, 0.4078931764986517, 0.4427767354596623]]\n",
      "Repeat 8 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "CLS/AVG/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_10ld.h5\n",
      "Epoch 1/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4788val_aucs: 0.4293065168453829 0.8713473253379023\n",
      "115/115 [==============================] - 15s 69ms/step - loss: 0.4788 - custom_metric: 1.3007\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4002val_aucs: 0.4696768759397185 0.8838877784123358\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.4002 - custom_metric: 1.3536\n",
      "Epoch 3/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3593val_aucs: 0.46021005903257883 0.872120692937369\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.3593 - custom_metric: 1.3323\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3338val_aucs: 0.5097948067133197 0.8861483913953931\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3338 - custom_metric: 1.3959\n",
      "Epoch 5/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2799val_aucs: 0.4743493998438189 0.8794974300399772\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2799 - custom_metric: 1.3538\n",
      "Epoch 6/1000\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.2373val_aucs: 0.4938666474383873 0.8823529411764708\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2370 - custom_metric: 1.3762\n",
      "Epoch 7/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1972val_aucs: 0.51449594160349 0.8807110222729868\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1972 - custom_metric: 1.3952\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1756val_aucs: 0.4884379986287691 0.8560822387207312\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1756 - custom_metric: 1.3445\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1561val_aucs: 0.4637791780865988 0.8739053873976775\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1561 - custom_metric: 1.3377\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1216val_aucs: 0.46786938193853217 0.8586284028174377\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1216 - custom_metric: 1.3265\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1369val_aucs: 0.4947205681700144 0.8713592233009709\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1369 - custom_metric: 1.3661\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0878val_aucs: 0.4596982141608076 0.8699433656957929\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.0878 - custom_metric: 1.3296\n",
      "Epoch 13/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1409val_aucs: 0.4512929252944797 0.8670045688178184\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1409 - custom_metric: 1.3183\n",
      "Epoch 14/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0986val_aucs: 0.4377616798089515 0.847634684941938\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.0986 - custom_metric: 1.2854\n",
      "Test res 0.8587122090414073 0.401635434421495 0.4502923976608187\n",
      "[[0.8554508923228817, 0.4110018804236198, 0.4419512195121951], [0.8457278078626137, 0.3790272726471662, 0.4220272904483431], [0.8707969479266398, 0.4405239881092402, 0.46875], [0.8602058027166108, 0.4177753501911591, 0.44015444015444016], [0.8578021219782191, 0.4227788824232871, 0.455078125], [0.8594622782282193, 0.41334630188849497, 0.43731778425655976], [0.8554820731360699, 0.42250702187590444, 0.45120772946859905], [0.8529165513553136, 0.4078931764986517, 0.4427767354596623], [0.8587122090414073, 0.401635434421495, 0.4502923976608187]]\n",
      "Repeat 9 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "CLS/AVG/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_10ld.h5\n",
      "Epoch 1/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.5200val_aucs: 0.43299227969661114 0.8791161585652343\n",
      "115/115 [==============================] - 15s 74ms/step - loss: 0.5200 - custom_metric: 1.3121\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4361val_aucs: 0.4414590667496874 0.8822842414723531\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.4361 - custom_metric: 1.3237\n",
      "Epoch 3/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3974val_aucs: 0.46768972810795445 0.8865665230290094\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3974 - custom_metric: 1.3543\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3631val_aucs: 0.48392288555848534 0.8764581907024821\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.3631 - custom_metric: 1.3604\n",
      "Epoch 5/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3245val_aucs: 0.4777859064262513 0.885855046782919\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3245 - custom_metric: 1.3636\n",
      "Epoch 6/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2678val_aucs: 0.4776799223536895 0.8743237619642114\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.2678 - custom_metric: 1.3520\n",
      "Epoch 7/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2309val_aucs: 0.45583747493012977 0.8503886271193267\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.2309 - custom_metric: 1.3062\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2098val_aucs: 0.47515939513179983 0.8579195360637913\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.2098 - custom_metric: 1.3331\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1755val_aucs: 0.43329980843522586 0.8610339226504503\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1755 - custom_metric: 1.2943\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1575val_aucs: 0.4638811743365515 0.852281422415529\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1575 - custom_metric: 1.3162\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1852val_aucs: 0.36810094983246 0.8446699689903749\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1852 - custom_metric: 1.2128\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1524val_aucs: 0.39948341801093473 0.8421999382492313\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1524 - custom_metric: 1.2417\n",
      "Epoch 13/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1051val_aucs: 0.4090770929418385 0.8455291101177291\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1051 - custom_metric: 1.2546\n",
      "Epoch 14/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0826val_aucs: 0.4126645548895286 0.8529996107016765\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.0826 - custom_metric: 1.2657\n",
      "Epoch 15/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0831val_aucs: 0.4046232364244109 0.8405219282348678\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.0831 - custom_metric: 1.2451\n",
      "Test res 0.8544079478817614 0.3794484699225291 0.4298245614035088\n",
      "[[0.8554508923228817, 0.4110018804236198, 0.4419512195121951], [0.8457278078626137, 0.3790272726471662, 0.4220272904483431], [0.8707969479266398, 0.4405239881092402, 0.46875], [0.8602058027166108, 0.4177753501911591, 0.44015444015444016], [0.8578021219782191, 0.4227788824232871, 0.455078125], [0.8594622782282193, 0.41334630188849497, 0.43731778425655976], [0.8554820731360699, 0.42250702187590444, 0.45120772946859905], [0.8529165513553136, 0.4078931764986517, 0.4427767354596623], [0.8587122090414073, 0.401635434421495, 0.4502923976608187], [0.8544079478817614, 0.3794484699225291, 0.4298245614035088]]\n",
      "gen_res {10: [(0.8570964632449736, 0.006044313064969986), (0.40959377784015477, 0.018137136437409187), (0.44393802833641266, 0.012552576711153864)]}\n",
      "Repeat 0 ld 20\n",
      "Num train: 7310 Num valid: 1852\n",
      "CLS/AVG/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_20ld.h5\n",
      "Epoch 1/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.5072val_aucs: 0.43741102919167274 0.8656377396669213\n",
      "229/229 [==============================] - 20s 60ms/step - loss: 0.5072 - custom_metric: 1.3030\n",
      "Epoch 2/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4399val_aucs: 0.44670458966969634 0.8791275280954601\n",
      "229/229 [==============================] - 11s 50ms/step - loss: 0.4399 - custom_metric: 1.3258\n",
      "Epoch 3/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3959val_aucs: 0.43704330514140705 0.8788531034779187\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3959 - custom_metric: 1.3159\n",
      "Epoch 4/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3713val_aucs: 0.4674163704898051 0.8825661016164602\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3713 - custom_metric: 1.3500\n",
      "Epoch 5/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3456val_aucs: 0.44970790164858926 0.8766973823859071\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3456 - custom_metric: 1.3264\n",
      "Epoch 6/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3095val_aucs: 0.45839958056043467 0.8726306079331859\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3095 - custom_metric: 1.3310\n",
      "Epoch 7/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2905val_aucs: 0.4227173676142307 0.8663552112573607\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.2905 - custom_metric: 1.2891\n",
      "Epoch 8/1000\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.2606val_aucs: 0.4575223887644667 0.8650029260938136\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.2602 - custom_metric: 1.3225\n",
      "Epoch 9/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2427val_aucs: 0.43756206176913565 0.8681836066007386\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2427 - custom_metric: 1.3057\n",
      "Epoch 10/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2411val_aucs: 0.44909030770516645 0.8656608839117742\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2411 - custom_metric: 1.3148\n",
      "Epoch 11/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1925val_aucs: 0.42502132299917494 0.8579439314136836\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1925 - custom_metric: 1.2830\n",
      "Epoch 12/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1595val_aucs: 0.41894423548497967 0.8629497009432933\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.1595 - custom_metric: 1.2819\n",
      "Epoch 13/1000\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.1686val_aucs: 0.42158730700187186 0.8508419545645409\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.1683 - custom_metric: 1.2724\n",
      "Epoch 14/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1529val_aucs: 0.3879878054621261 0.8327001729205722\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.1529 - custom_metric: 1.2207\n",
      "Test res 0.8815639585327909 0.48102702424648835 0.48443579766536965\n",
      "[[0.8815639585327909, 0.48102702424648835, 0.48443579766536965]]\n",
      "Repeat 1 ld 20\n",
      "Num train: 7310 Num valid: 1852\n",
      "CLS/AVG/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_20ld.h5\n",
      "Epoch 1/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.5514val_aucs: 0.4103539253602208 0.8712336621974872\n",
      "229/229 [==============================] - 21s 59ms/step - loss: 0.5514 - custom_metric: 1.2816\n",
      "Epoch 2/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4584val_aucs: 0.4785181843453609 0.8872282654523991\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.4584 - custom_metric: 1.3657\n",
      "Epoch 3/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4238val_aucs: 0.49063546432459776 0.8885302302049077\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.4238 - custom_metric: 1.3792\n",
      "Epoch 4/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3956val_aucs: 0.46918313184497007 0.8845332658740197\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3956 - custom_metric: 1.3537\n",
      "Epoch 5/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3560val_aucs: 0.46907181893290617 0.8815110886246732\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3560 - custom_metric: 1.3506\n",
      "Epoch 6/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3308val_aucs: 0.4481898630660427 0.8724040812884728\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3308 - custom_metric: 1.3206\n",
      "Epoch 7/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3017val_aucs: 0.44422037372796763 0.8698338814402564\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3017 - custom_metric: 1.3141\n",
      "Epoch 8/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2641val_aucs: 0.43652804531059003 0.8671118981364364\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2641 - custom_metric: 1.3036\n",
      "Epoch 9/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2309val_aucs: 0.3679754133222513 0.8506686904460745\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2309 - custom_metric: 1.2186\n",
      "Epoch 10/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2320val_aucs: 0.41846840031284943 0.8558832953874695\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2320 - custom_metric: 1.2744\n",
      "Epoch 11/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1953val_aucs: 0.43315030524252646 0.8526047727464373\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.1953 - custom_metric: 1.2858\n",
      "Epoch 12/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1810val_aucs: 0.4113476115835076 0.8614385698625516\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.1810 - custom_metric: 1.2728\n",
      "Epoch 13/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1750val_aucs: 0.4025915543898266 0.8440172021249683\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.1750 - custom_metric: 1.2466\n",
      "Test res 0.8724841711793921 0.4391015224671847 0.4697265625\n",
      "[[0.8815639585327909, 0.48102702424648835, 0.48443579766536965], [0.8724841711793921, 0.4391015224671847, 0.4697265625]]\n",
      "Repeat 2 ld 20\n",
      "Num train: 7310 Num valid: 1852\n",
      "CLS/AVG/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_20ld.h5\n",
      "Epoch 1/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.5159val_aucs: 0.4931692950579203 0.8737539666623412\n",
      "229/229 [==============================] - 20s 60ms/step - loss: 0.5159 - custom_metric: 1.3669\n",
      "Epoch 2/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4468val_aucs: 0.5457631025010526 0.8897651264023405\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.4468 - custom_metric: 1.4355\n",
      "Epoch 3/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4203val_aucs: 0.5529372059526414 0.8951768924960776\n",
      "229/229 [==============================] - 11s 50ms/step - loss: 0.4203 - custom_metric: 1.4481\n",
      "Epoch 4/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3885val_aucs: 0.5339342930044866 0.8883052766931308\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3885 - custom_metric: 1.4222\n",
      "Epoch 5/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3566val_aucs: 0.5762154360932019 0.8886178909742949\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3566 - custom_metric: 1.4648\n",
      "Epoch 6/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3473val_aucs: 0.5622940397024991 0.8823508593943541\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3473 - custom_metric: 1.4446\n",
      "Epoch 7/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1939val_aucs: 0.5064318571357228 0.869106041123524\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1939 - custom_metric: 1.3755\n",
      "Epoch 14/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1617val_aucs: 0.4782877946648681 0.8615973999929218\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1617 - custom_metric: 1.3399\n",
      "Epoch 15/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1397val_aucs: 0.4687697377525011 0.8564186200143921\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.1397 - custom_metric: 1.3252\n",
      "Test res 0.8709881933640499 0.439715365499514 0.48046875\n",
      "[[0.8815639585327909, 0.48102702424648835, 0.48443579766536965], [0.8724841711793921, 0.4391015224671847, 0.4697265625], [0.8709881933640499, 0.439715365499514, 0.48046875]]\n",
      "Repeat 3 ld 20\n",
      "Num train: 7310 Num valid: 1852\n",
      "CLS/AVG/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_20ld.h5\n",
      "Epoch 1/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.5256val_aucs: 0.48590235922295844 0.8757892016100816\n",
      "229/229 [==============================] - 21s 60ms/step - loss: 0.5256 - custom_metric: 1.3617\n",
      "Epoch 2/1000\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.4439val_aucs: 0.5067407866377382 0.8832659313918632\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.4437 - custom_metric: 1.3900\n",
      "Epoch 3/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4062val_aucs: 0.514836326874663 0.8843975275097635\n",
      "229/229 [==============================] - 12s 50ms/step - loss: 0.4062 - custom_metric: 1.3992\n",
      "Epoch 4/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3753val_aucs: 0.5025750501368254 0.8829349631679648\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3753 - custom_metric: 1.3855\n",
      "Epoch 5/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3529val_aucs: 0.5121425140576675 0.878197389448733\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3529 - custom_metric: 1.3903\n",
      "Epoch 6/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3194val_aucs: 0.48907630451848294 0.8715212875609533\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3194 - custom_metric: 1.3606\n",
      "Epoch 7/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2967val_aucs: 0.46876088272653127 0.8657246155252465\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2967 - custom_metric: 1.3345\n",
      "Epoch 8/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2858val_aucs: 0.444896051055044 0.8622068961169547\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.2858 - custom_metric: 1.3071\n",
      "Epoch 9/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2443val_aucs: 0.47655941198496643 0.8633700130180835\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2443 - custom_metric: 1.3399\n",
      "Epoch 10/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2118val_aucs: 0.43585642157155186 0.8657183113686009\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2118 - custom_metric: 1.3016\n",
      "Epoch 11/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1808val_aucs: 0.420461813367815 0.8523787159063329\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.1808 - custom_metric: 1.2728\n",
      "Epoch 12/1000\n",
      " 19/229 [=>............................] - ETA: 9s - loss: 0.1485"
     ]
    }
   ],
   "source": [
    "repeats = {k:10 for k in [10,20,30,40,50,60,70,80,90,100]}\n",
    "lds = [10,20,30,40,50,60]\n",
    "batch_size, lr, patience = 32, 0.0005, 10\n",
    "d, N, he, dropout = 50,2,4,0.2\n",
    "\n",
    "# best val model\n",
    "fore_savepath = 'Exp0/M_Q/models/forecasting/forecasting_101_epochs.h5'\n",
    "\n",
    "train_inds = np.arange(len(train_op))\n",
    "valid_inds = np.arange(len(valid_op))\n",
    "gen_res = {}\n",
    "\n",
    "np.random.seed(2023)\n",
    "\n",
    "for ld in lds:\n",
    "    np.random.shuffle(train_inds)\n",
    "    np.random.shuffle(valid_inds)\n",
    "    train_starts = [int(i) for i in np.linspace(0, len(train_inds)-int(ld*len(train_inds)/100), repeats[ld])]\n",
    "    valid_starts = [int(i) for i in np.linspace(0, len(valid_inds)-int(ld*len(valid_inds)/100), repeats[ld])]\n",
    "    all_test_res = []\n",
    "    for i in range(repeats[ld]):\n",
    "        print ('Repeat', i, 'ld', ld)\n",
    "        # Get train and validation data.\n",
    "        curr_train_ind = train_inds[np.arange(train_starts[i], train_starts[i]+int(ld*len(train_inds)/100))]\n",
    "        curr_valid_ind = valid_inds[np.arange(valid_starts[i], valid_starts[i]+int(ld*len(valid_inds)/100))]\n",
    "        curr_train_ip = [ip[curr_train_ind] for ip in train_ip]\n",
    "        curr_valid_ip = [ip[curr_valid_ind] for ip in valid_ip]\n",
    "        curr_train_op = train_op[curr_train_ind]\n",
    "        curr_valid_op = valid_op[curr_valid_ind]\n",
    "        print ('Num train:',len(curr_train_op),'Num valid:',len(curr_valid_op))\n",
    "        # Construct save_path.\n",
    "        savepath = 'CLS/AVG/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat'+str(i)+'_'+str(ld)+'ld'+'.h5'\n",
    "        print (savepath)\n",
    "        # Build and compile model.\n",
    "        model, fore_model =  build_strats(D, max_len, V, d, N, he, dropout, forecast=True)\n",
    "        model.compile(loss=mortality_loss, optimizer=Adam(lr))\n",
    "        fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "        # Load pretrained weights here.\n",
    "        fore_model.load_weights(fore_savepath)\n",
    "        # Train model.\n",
    "        es = EarlyStopping(monitor='custom_metric', patience=patience, mode='max', \n",
    "                           restore_best_weights=True)\n",
    "        cus = CustomCallback(validation_data=(curr_valid_ip, curr_valid_op), batch_size=batch_size)\n",
    "        his = model.fit(curr_train_ip, curr_train_op, batch_size=batch_size, epochs=1000,\n",
    "                        verbose=1, callbacks=[cus, es]).history\n",
    "        model.save_weights(savepath)\n",
    "        # Test and write to log.\n",
    "        rocauc, prauc, minrp = get_res(test_op, model.predict(test_ip, verbose=0, batch_size=batch_size))\n",
    "\n",
    "        print ('Test res', rocauc, prauc, minrp)\n",
    "        all_test_res.append([rocauc, prauc, minrp])\n",
    "        \n",
    "        # in case of unexpected disconnection\n",
    "        print(all_test_res)\n",
    "        \n",
    "    gen_res[ld] = []\n",
    "    for i in range(len(all_test_res[0])):\n",
    "        nums = [test_res[i] for test_res in all_test_res]\n",
    "        gen_res[ld].append((np.mean(nums), np.std(nums)))\n",
    "    print ('gen_res', gen_res)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
