{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECKAJiLXiTlN"
   },
   "source": [
    "## Hardware check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "e7odgm5VsOsb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 14 17:38:47 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  |   00000000:3A:00.0 Off |                    0 |\n",
      "| N/A   32C    P0             41W /  300W |      17MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-32GB           On  |   00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   35C    P0             41W /  300W |      17MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2-32GB           On  |   00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   34C    P0             41W /  300W |      17MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2-32GB           On  |   00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   37C    P0             43W /  300W |      17MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1918      G   /usr/libexec/Xorg                              17MiB |\n",
      "|    1   N/A  N/A      1918      G   /usr/libexec/Xorg                              17MiB |\n",
      "|    2   N/A  N/A      1918      G   /usr/libexec/Xorg                              17MiB |\n",
      "|    3   N/A  N/A      1918      G   /usr/libexec/Xorg                              17MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# gpu check\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oEEUeIW3sOsc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of cores\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count() \n",
    "cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY9I5eXWeOom"
   },
   "source": [
    "## Environment Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis\n"
     ]
    }
   ],
   "source": [
    "cd /pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 17:38:49.511052: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-14 17:38:49.955267: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-14 17:38:54.140129: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Lambda, GlobalAveragePooling1D\n",
    "# from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "import pandas as pd\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, pipeline, AutoModel\n",
    "import resources.smart_cond as sc\n",
    "# from google.colab import files\n",
    "from keras.utils import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36551it [00:00, 73355.10it/s]\n"
     ]
    }
   ],
   "source": [
    "train_path = 'CLS/GloVe/Data/classification_train.txt'\n",
    "train_text = []\n",
    "\n",
    "with open(train_path) as file:\n",
    "    for line in tqdm(file):\n",
    "        train_text.append(line.rstrip())\n",
    "\n",
    "# train_text = np.array(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9262it [00:00, 53078.09it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_path = 'CLS/GloVe/Data/classification_valid.txt'\n",
    "valid_text = []\n",
    "\n",
    "with open(valid_path) as file:\n",
    "    for line in tqdm(file):\n",
    "        valid_text.append(line.rstrip())\n",
    "\n",
    "# train_text = np.array(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11469it [00:00, 63687.62it/s]\n"
     ]
    }
   ],
   "source": [
    "test_path = 'CLS/GloVe/Data/classification_test.txt'\n",
    "test_text = []\n",
    "\n",
    "with open(test_path) as file:\n",
    "    for line in tqdm(file):\n",
    "        test_text.append(line.rstrip())\n",
    "\n",
    "# train_text = np.array(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 297321\n"
     ]
    }
   ],
   "source": [
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "train_val_ip = train_text+valid_text\n",
    "t.fit_on_texts(train_val_ip)\n",
    "# vocab_size = len(t.word_index) + 1\n",
    "vocab_size = 297321\n",
    "print(f'vocabulary size: {vocab_size}')\n",
    "del train_val_ip\n",
    "\n",
    "# encode\n",
    "encoded_train = t.texts_to_sequences(train_text)\n",
    "encoded_valid = t.texts_to_sequences(valid_text)\n",
    "encoded_test = t.texts_to_sequences(test_text)\n",
    "\n",
    "\n",
    "# pad to max_len\n",
    "max_length = 24135\n",
    "padded_train = pad_sequences(encoded_train, maxlen=max_length, padding='post')\n",
    "padded_valid = pad_sequences(encoded_valid, maxlen=max_length, padding='post')\n",
    "padded_test = pad_sequences(encoded_test, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Data/CLS/cls_data.pkl'\n",
    "train_ip, valid_ip, test_ip, train_op, valid_op, test_op = pickle.load(open(data_path, 'rb'))\n",
    "train_ip = train_ip[:4]\n",
    "valid_ip = valid_ip[:4]\n",
    "test_ip = test_ip[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ip.append(padded_train)\n",
    "valid_ip.append(padded_valid)\n",
    "test_ip.append(padded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [01:30, 24295.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array, asarray, zeros\n",
    "\n",
    "# GloVe\n",
    "glove_path = 'resources/glove.840B.300d.txt'\n",
    "\n",
    "embedding_model = {}\n",
    "f = open('resources/glove.840B.300d.txt', 'r', encoding=\"utf8\")\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = ''.join(values[:-300])\n",
    "    coefs = np.asarray(values[-300:], dtype='float32')\n",
    "    embedding_model[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289274/289274 [00:00<00:00, 537301.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size, 300))\n",
    "for word, i in tqdm(t.word_index.items()):\n",
    "    embedding_vector = embedding_model.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_res(y_true, y_pred):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    minrp = np.minimum(precision, recall).max()\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    return [roc_auc, pr_auc, minrp]\n",
    "\n",
    "######################################################################################################## \n",
    "######################################################################################################## \n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=[0,1], y=train_op)\n",
    "def mortality_loss(y_true, y_pred):\n",
    "    sample_weights = (1-y_true)*class_weights[0] + y_true*class_weights[1]\n",
    "    bce = K.binary_crossentropy(y_true, y_pred)\n",
    "    return K.mean(sample_weights*bce, axis=-1)\n",
    "######################################################################################################## \n",
    "######################################################################################################## \n",
    "\n",
    "# var_weights = np.sum(fore_train_op[:, V:], axis=0)\n",
    "# var_weights[var_weights==0] = var_weights.max()\n",
    "# var_weights = var_weights.max()/var_weights\n",
    "# var_weights = var_weights.reshape((1, V))\n",
    "def forecast_loss(y_true, y_pred):\n",
    "    return K.sum(y_true[:,V:]*(y_true[:,:V]-y_pred)**2, axis=-1)\n",
    "\n",
    "def get_min_loss(weight):\n",
    "    def min_loss(y_true, y_pred):\n",
    "        return weight*y_pred\n",
    "    return min_loss\n",
    "\n",
    "class CustomCallback(Callback):\n",
    "    def __init__(self, validation_data, batch_size):\n",
    "        self.val_x, self.val_y = validation_data\n",
    "        self.batch_size = batch_size\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.val_x, verbose=0, batch_size=self.batch_size)\n",
    "        if type(y_pred)==type([]):\n",
    "            y_pred = y_pred[0]\n",
    "        precision, recall, thresholds = precision_recall_curve(self.val_y, y_pred)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        roc_auc = roc_auc_score(self.val_y, y_pred)\n",
    "        logs['custom_metric'] = pr_auc + roc_auc\n",
    "        print ('val_aucs:', pr_auc, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Embedding, Activation, Dropout, Softmax, Layer, InputSpec, Input, Dense, Lambda, TimeDistributed, Concatenate, Add\n",
    "from tensorflow.keras import initializers, regularizers, constraints, Model\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow import nn\n",
    "\n",
    "    \n",
    "class CVE(Layer):\n",
    "    def __init__(self, hid_units, output_dim):\n",
    "        self.hid_units = hid_units\n",
    "        self.output_dim = output_dim\n",
    "        super(CVE, self).__init__()\n",
    "        \n",
    "    def build(self, input_shape): \n",
    "        self.W1 = self.add_weight(name='CVE_W1',\n",
    "                            shape=(1, self.hid_units),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        self.b1 = self.add_weight(name='CVE_b1',\n",
    "                            shape=(self.hid_units,),\n",
    "                            initializer='zeros',\n",
    "                            trainable=True)\n",
    "        self.W2 = self.add_weight(name='CVE_W2',\n",
    "                            shape=(self.hid_units, self.output_dim),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        super(CVE, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = K.expand_dims(x, axis=-1)\n",
    "        x = K.dot(K.tanh(K.bias_add(K.dot(x, self.W1), self.b1)), self.W2)\n",
    "        return x\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape + (self.output_dim,)\n",
    "    \n",
    "    \n",
    "class Attention(Layer):\n",
    "    \n",
    "    def __init__(self, hid_dim):\n",
    "        self.hid_dim = hid_dim\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        self.W = self.add_weight(shape=(d, self.hid_dim), name='Att_W',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.hid_dim,), name='Att_b',\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        self.u = self.add_weight(shape=(self.hid_dim,1), name='Att_u',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask, mask_value=-1e30):\n",
    "        attn_weights = K.dot(K.tanh(K.bias_add(K.dot(x,self.W), self.b)), self.u)\n",
    "        mask = K.expand_dims(mask, axis=-1)\n",
    "        attn_weights = mask*attn_weights + (1-mask)*mask_value\n",
    "        attn_weights = K.softmax(attn_weights, axis=-2)\n",
    "        return attn_weights\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1] + (1,)\n",
    "    \n",
    "    \n",
    "class Transformer(Layer):\n",
    "    \n",
    "    def __init__(self, N=2, h=8, dk=None, dv=None, dff=None, dropout=0):\n",
    "        self.N, self.h, self.dk, self.dv, self.dff, self.dropout = N, h, dk, dv, dff, dropout\n",
    "        self.epsilon = K.epsilon() * K.epsilon()\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        if self.dk==None:\n",
    "            self.dk = d//self.h\n",
    "        if self.dv==None:\n",
    "            self.dv = d//self.h\n",
    "        if self.dff==None:\n",
    "            self.dff = 2*d\n",
    "        self.Wq = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wq',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wk = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wk',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wv = self.add_weight(shape=(self.N, self.h, d, self.dv), name='Wv',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wo = self.add_weight(shape=(self.N, self.dv*self.h, d), name='Wo',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.W1 = self.add_weight(shape=(self.N, d, self.dff), name='W1',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b1 = self.add_weight(shape=(self.N, self.dff), name='b1',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.W2 = self.add_weight(shape=(self.N, self.dff, d), name='W2',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b2 = self.add_weight(shape=(self.N, d), name='b2',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.gamma = self.add_weight(shape=(2*self.N,), name='gamma',\n",
    "                                 initializer='ones', trainable=True)\n",
    "        self.beta = self.add_weight(shape=(2*self.N,), name='beta',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        super(Transformer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask, mask_value=-1e-30):\n",
    "        mask = K.expand_dims(mask, axis=-2)\n",
    "        for i in range(self.N):\n",
    "            # MHA\n",
    "            mha_ops = []\n",
    "            for j in range(self.h):\n",
    "                q = K.dot(x, self.Wq[i,j,:,:])\n",
    "                k = K.permute_dimensions(K.dot(x, self.Wk[i,j,:,:]), (0,2,1))\n",
    "                v = K.dot(x, self.Wv[i,j,:,:])\n",
    "                A = K.batch_dot(q,k)\n",
    "                # Mask unobserved steps.\n",
    "                A = mask*A + (1-mask)*mask_value\n",
    "                # Mask for attention dropout.\n",
    "                def dropped_A():\n",
    "                    dp_mask = K.cast((K.random_uniform(shape=array_ops.shape(A))>=self.dropout), K.floatx())\n",
    "                    return A*dp_mask + (1-dp_mask)*mask_value\n",
    "                A = sc.smart_cond(K.learning_phase(), dropped_A, lambda: array_ops.identity(A))\n",
    "                A = K.softmax(A, axis=-1)\n",
    "                mha_ops.append(K.batch_dot(A,v))\n",
    "            conc = K.concatenate(mha_ops, axis=-1)\n",
    "            proj = K.dot(conc, self.Wo[i,:,:])\n",
    "            # Dropout.\n",
    "            proj = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(proj, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(proj))\n",
    "            # Add & LN\n",
    "            x = x+proj\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i] + self.beta[2*i]\n",
    "            # FFN\n",
    "            ffn_op = K.bias_add(K.dot(K.relu(K.bias_add(K.dot(x, self.W1[i,:,:]), self.b1[i,:])), \n",
    "                           self.W2[i,:,:]), self.b2[i,:,])\n",
    "            # Dropout.\n",
    "            ffn_op = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(ffn_op, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(ffn_op))\n",
    "            # Add & LN\n",
    "            x = x+ffn_op\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i+1] + self.beta[2*i+1]            \n",
    "        return x\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "def build_strats(D, max_len, V, d, N, he, dropout, forecast=False):\n",
    "    demo = Input(shape=(D,))\n",
    "    demo_enc = Dense(2*d, activation='tanh')(demo)\n",
    "    demo_enc = Dense(d, activation='tanh')(demo_enc)\n",
    "    varis = Input(shape=(max_len,))\n",
    "    values = Input(shape=(max_len,))\n",
    "    times = Input(shape=(max_len,))\n",
    "    varis_emb = Embedding(V+1, d)(varis)\n",
    "    cve_units = int(np.sqrt(d))\n",
    "    values_emb = CVE(cve_units, d)(values)\n",
    "    times_emb = CVE(cve_units, d)(times)\n",
    "    comb_emb = Add()([varis_emb, values_emb, times_emb]) # b, L, d\n",
    "#     demo_enc = Lambda(lambda x:K.expand_dims(x, axis=-2))(demo_enc) # b, 1, d\n",
    "#     comb_emb = Concatenate(axis=-2)([demo_enc, comb_emb]) # b, L+1, d\n",
    "    mask = Lambda(lambda x:K.clip(x,0,1))(varis) # b, L\n",
    "#     mask = Lambda(lambda x:K.concatenate((K.ones_like(x)[:,0:1], x), axis=-1))(mask) # b, L+1\n",
    "    cont_emb = Transformer(N, he, dk=None, dv=None, dff=None, dropout=dropout)(comb_emb, mask=mask)\n",
    "    attn_weights = Attention(2*d)(cont_emb, mask=mask)\n",
    "    fused_emb = Lambda(lambda x:K.sum(x[0]*x[1], axis=-2))([cont_emb, attn_weights])\n",
    "    \n",
    "    \n",
    "    ## GloVe text embedding starts here\n",
    "    max_length = 24135\n",
    "    # embed text input\n",
    "    texts = Input(shape=(max_length,))\n",
    "    embedded_text = Embedding(vocab_size, 300, weights=[\n",
    "    embedding_matrix], input_length=max_length, trainable=False)(texts)\n",
    "    pooled = GlobalAveragePooling1D()(embedded_text)\n",
    "    # flattened = Flatten()(embedded_text)\n",
    "    \n",
    "    text_0 = Dense(100, activation='relu')(pooled)\n",
    "    \n",
    "    \n",
    "    # hidden_states = LSTM(64, return_sequences=True, name='lstm_layer')(embedded_text)\n",
    "    # pooled = AveragePooling1D()(hidden_states)\n",
    "    # text_0 = Dense(100, activation='relu')(hidden_states)\n",
    "    \n",
    "    # text_1 = Flatten()(hidden_states)\n",
    "    \n",
    "    # text_enc = Dense(22528, activation='relu')(texts)\n",
    "    # text_enc = Dense(10000, activation='relu')(texts)\n",
    "    # text_enc = Dense(5000, activation='relu')(texts)\n",
    "    # text_enc = Dense(1000, activation='relu')(texts)\n",
    "    \n",
    "    # text_enc = Dense(d, activation='relu')(text_1)\n",
    "    \n",
    "    text_enc = Dense(d, activation='relu')(text_0)\n",
    "    \n",
    "    # text_enc = Dense(d * max_length, activation='relu')(text_0)\n",
    "    # reshaped_text_enc = Reshape((max_length, d))(text_enc)\n",
    "    \n",
    "    # reshaped_text_enc = Reshape((d,))(text_enc)\n",
    "    \n",
    "    # conc = Concatenate(axis=-1)([fused_emb, text_enc, demo_enc])\n",
    "    conc = Concatenate(axis=-1)([fused_emb, text_enc, demo_enc])\n",
    "    fore_op = Dense(V)(conc)\n",
    "    op = Dense(1, activation='sigmoid')(fore_op)\n",
    "    model = Model([demo, times, values, varis, texts], op)\n",
    "    if forecast:\n",
    "        fore_model = Model([demo, times, values, varis, texts], fore_op)\n",
    "        return [model, fore_model]\n",
    "    return model\n",
    "\n",
    "# To tune:\n",
    "# 1. Transformer parameters. (N, h, dropout)\n",
    "# 2. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "D = 2\n",
    "max_len = 880\n",
    "V = 134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 0 ld 10\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_10ld.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 17:46:23.305222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31117 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3a:00.0, compute capability: 7.0\n",
      "2024-06-14 17:46:23.305880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 31117 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-06-14 17:46:23.306359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 31117 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b2:00.0, compute capability: 7.0\n",
      "2024-06-14 17:46:23.306847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 31117 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b3:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test res 0.8476867295955004 0.3943939066575073 0.41926070038910507\n",
      "[[0.8476867295955004, 0.3943939066575073, 0.41926070038910507]]\n",
      "Repeat 1 ld 10\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_10ld.h5\n",
      "Test res 0.845084978234203 0.3850068274996663 0.4142581888246628\n",
      "[[0.8476867295955004, 0.3943939066575073, 0.41926070038910507], [0.845084978234203, 0.3850068274996663, 0.4142581888246628]]\n",
      "Repeat 2 ld 10\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_10ld.h5\n",
      "Test res 0.8548578491503113 0.3951993465111125 0.431640625\n",
      "[[0.8476867295955004, 0.3943939066575073, 0.41926070038910507], [0.845084978234203, 0.3850068274996663, 0.4142581888246628], [0.8548578491503113, 0.3951993465111125, 0.431640625]]\n",
      "Repeat 3 ld 10\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_10ld.h5\n",
      "Test res 0.8585576606629967 0.40807372634464045 0.42775665399239543\n",
      "[[0.8476867295955004, 0.3943939066575073, 0.41926070038910507], [0.845084978234203, 0.3850068274996663, 0.4142581888246628], [0.8548578491503113, 0.3951993465111125, 0.431640625], [0.8585576606629967, 0.40807372634464045, 0.42775665399239543]]\n",
      "Repeat 4 ld 10\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_10ld.h5\n",
      "Test res 0.8708405636668263 0.4511344194551806 0.474609375\n",
      "[[0.8476867295955004, 0.3943939066575073, 0.41926070038910507], [0.845084978234203, 0.3850068274996663, 0.4142581888246628], [0.8548578491503113, 0.3951993465111125, 0.431640625], [0.8585576606629967, 0.40807372634464045, 0.42775665399239543], [0.8708405636668263, 0.4511344194551806, 0.474609375]]\n",
      "Repeat 5 ld 10\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_10ld.h5\n",
      "Test res 0.8561063906175204 0.43425668401967377 0.4521484375\n",
      "[[0.8476867295955004, 0.3943939066575073, 0.41926070038910507], [0.845084978234203, 0.3850068274996663, 0.4142581888246628], [0.8548578491503113, 0.3951993465111125, 0.431640625], [0.8585576606629967, 0.40807372634464045, 0.42775665399239543], [0.8708405636668263, 0.4511344194551806, 0.474609375], [0.8561063906175204, 0.43425668401967377, 0.4521484375]]\n",
      "Repeat 6 ld 10\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_10ld.h5\n",
      "Test res 0.8396808805050262 0.4086426600112052 0.42829268292682926\n",
      "[[0.8476867295955004, 0.3943939066575073, 0.41926070038910507], [0.845084978234203, 0.3850068274996663, 0.4142581888246628], [0.8548578491503113, 0.3951993465111125, 0.431640625], [0.8585576606629967, 0.40807372634464045, 0.42775665399239543], [0.8708405636668263, 0.4511344194551806, 0.474609375], [0.8561063906175204, 0.43425668401967377, 0.4521484375], [0.8396808805050262, 0.4086426600112052, 0.42829268292682926]]\n",
      "Repeat 7 ld 10\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_10ld.h5\n",
      "Test res 0.8524610870931068 0.4273385347536563 0.4501953125\n",
      "[[0.8476867295955004, 0.3943939066575073, 0.41926070038910507], [0.845084978234203, 0.3850068274996663, 0.4142581888246628], [0.8548578491503113, 0.3951993465111125, 0.431640625], [0.8585576606629967, 0.40807372634464045, 0.42775665399239543], [0.8708405636668263, 0.4511344194551806, 0.474609375], [0.8561063906175204, 0.43425668401967377, 0.4521484375], [0.8396808805050262, 0.4086426600112052, 0.42829268292682926], [0.8524610870931068, 0.4273385347536563, 0.4501953125]]\n",
      "Repeat 8 ld 10\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_10ld.h5\n",
      "Test res 0.8509351906564145 0.4149060343127502 0.4443359375\n",
      "[[0.8476867295955004, 0.3943939066575073, 0.41926070038910507], [0.845084978234203, 0.3850068274996663, 0.4142581888246628], [0.8548578491503113, 0.3951993465111125, 0.431640625], [0.8585576606629967, 0.40807372634464045, 0.42775665399239543], [0.8708405636668263, 0.4511344194551806, 0.474609375], [0.8561063906175204, 0.43425668401967377, 0.4521484375], [0.8396808805050262, 0.4086426600112052, 0.42829268292682926], [0.8524610870931068, 0.4273385347536563, 0.4501953125], [0.8509351906564145, 0.4149060343127502, 0.4443359375]]\n",
      "Repeat 9 ld 10\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_10ld.h5\n",
      "Test res 0.8498691060315939 0.41221921382569804 0.4482421875\n",
      "[[0.8476867295955004, 0.3943939066575073, 0.41926070038910507], [0.845084978234203, 0.3850068274996663, 0.4142581888246628], [0.8548578491503113, 0.3951993465111125, 0.431640625], [0.8585576606629967, 0.40807372634464045, 0.42775665399239543], [0.8708405636668263, 0.4511344194551806, 0.474609375], [0.8561063906175204, 0.43425668401967377, 0.4521484375], [0.8396808805050262, 0.4086426600112052, 0.42829268292682926], [0.8524610870931068, 0.4273385347536563, 0.4501953125], [0.8509351906564145, 0.4149060343127502, 0.4443359375], [0.8498691060315939, 0.41221921382569804, 0.4482421875]]\n",
      "gen_res {10: [(0.8526080436213499, 0.00802104725054731), (0.4131171353391091, 0.018988685560597067), (0.4390740101132993, 0.017254264807526624)]}\n",
      "Repeat 0 ld 20\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_20ld.h5\n",
      "Test res 0.8656838555379369 0.4453695416650166 0.4560546875\n",
      "[[0.8656838555379369, 0.4453695416650166, 0.4560546875]]\n",
      "Repeat 1 ld 20\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_20ld.h5\n",
      "Test res 0.8682275460746769 0.4473318106254164 0.4599609375\n",
      "[[0.8656838555379369, 0.4453695416650166, 0.4560546875], [0.8682275460746769, 0.4473318106254164, 0.4599609375]]\n",
      "Repeat 2 ld 20\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_20ld.h5\n",
      "Test res 0.8694706647917664 0.45204151842487394 0.462890625\n",
      "[[0.8656838555379369, 0.4453695416650166, 0.4560546875], [0.8682275460746769, 0.4473318106254164, 0.4599609375], [0.8694706647917664, 0.45204151842487394, 0.462890625]]\n",
      "Repeat 3 ld 20\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_20ld.h5\n",
      "Test res 0.8656534226902826 0.42663391347765267 0.4462890625\n",
      "[[0.8656838555379369, 0.4453695416650166, 0.4560546875], [0.8682275460746769, 0.4473318106254164, 0.4599609375], [0.8694706647917664, 0.45204151842487394, 0.462890625], [0.8656534226902826, 0.42663391347765267, 0.4462890625]]\n",
      "Repeat 4 ld 20\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_20ld.h5\n",
      "Test res 0.8696550850436813 0.43128827177477325 0.4609375\n",
      "[[0.8656838555379369, 0.4453695416650166, 0.4560546875], [0.8682275460746769, 0.4473318106254164, 0.4599609375], [0.8694706647917664, 0.45204151842487394, 0.462890625], [0.8656534226902826, 0.42663391347765267, 0.4462890625], [0.8696550850436813, 0.43128827177477325, 0.4609375]]\n",
      "Repeat 5 ld 20\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_20ld.h5\n",
      "Test res 0.8610312761787936 0.4341215639561085 0.45321637426900585\n",
      "[[0.8656838555379369, 0.4453695416650166, 0.4560546875], [0.8682275460746769, 0.4473318106254164, 0.4599609375], [0.8694706647917664, 0.45204151842487394, 0.462890625], [0.8656534226902826, 0.42663391347765267, 0.4462890625], [0.8696550850436813, 0.43128827177477325, 0.4609375], [0.8610312761787936, 0.4341215639561085, 0.45321637426900585]]\n",
      "Repeat 6 ld 20\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_20ld.h5\n",
      "Test res 0.8727684915779081 0.45373440326456876 0.47609756097560973\n",
      "[[0.8656838555379369, 0.4453695416650166, 0.4560546875], [0.8682275460746769, 0.4473318106254164, 0.4599609375], [0.8694706647917664, 0.45204151842487394, 0.462890625], [0.8656534226902826, 0.42663391347765267, 0.4462890625], [0.8696550850436813, 0.43128827177477325, 0.4609375], [0.8610312761787936, 0.4341215639561085, 0.45321637426900585], [0.8727684915779081, 0.45373440326456876, 0.47609756097560973]]\n",
      "Repeat 7 ld 20\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_20ld.h5\n",
      "Test res 0.8784611170117281 0.46586194298484984 0.4775390625\n",
      "[[0.8656838555379369, 0.4453695416650166, 0.4560546875], [0.8682275460746769, 0.4473318106254164, 0.4599609375], [0.8694706647917664, 0.45204151842487394, 0.462890625], [0.8656534226902826, 0.42663391347765267, 0.4462890625], [0.8696550850436813, 0.43128827177477325, 0.4609375], [0.8610312761787936, 0.4341215639561085, 0.45321637426900585], [0.8727684915779081, 0.45373440326456876, 0.47609756097560973], [0.8784611170117281, 0.46586194298484984, 0.4775390625]]\n",
      "Repeat 8 ld 20\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_20ld.h5\n",
      "Test res 0.8744535176819053 0.45585589784733666 0.45966958211856174\n",
      "[[0.8656838555379369, 0.4453695416650166, 0.4560546875], [0.8682275460746769, 0.4473318106254164, 0.4599609375], [0.8694706647917664, 0.45204151842487394, 0.462890625], [0.8656534226902826, 0.42663391347765267, 0.4462890625], [0.8696550850436813, 0.43128827177477325, 0.4609375], [0.8610312761787936, 0.4341215639561085, 0.45321637426900585], [0.8727684915779081, 0.45373440326456876, 0.47609756097560973], [0.8784611170117281, 0.46586194298484984, 0.4775390625], [0.8744535176819053, 0.45585589784733666, 0.45966958211856174]]\n",
      "Repeat 9 ld 20\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_20ld.h5\n",
      "Test res 0.866908134873145 0.46283119519185456 0.4786407766990291\n",
      "[[0.8656838555379369, 0.4453695416650166, 0.4560546875], [0.8682275460746769, 0.4473318106254164, 0.4599609375], [0.8694706647917664, 0.45204151842487394, 0.462890625], [0.8656534226902826, 0.42663391347765267, 0.4462890625], [0.8696550850436813, 0.43128827177477325, 0.4609375], [0.8610312761787936, 0.4341215639561085, 0.45321637426900585], [0.8727684915779081, 0.45373440326456876, 0.47609756097560973], [0.8784611170117281, 0.46586194298484984, 0.4775390625], [0.8744535176819053, 0.45585589784733666, 0.45966958211856174], [0.866908134873145, 0.46283119519185456, 0.4786407766990291]]\n",
      "gen_res {10: [(0.8526080436213499, 0.00802104725054731), (0.4131171353391091, 0.018988685560597067), (0.4390740101132993, 0.017254264807526624)], 20: [(0.8692313111461824, 0.004735401463275942), (0.44750700592124504, 0.01258285976252685), (0.4631296169062207, 0.010369194355368691)]}\n",
      "Repeat 0 ld 30\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_30ld.h5\n",
      "Test res 0.8859537215025133 0.4869552312577687 0.48209099709583736\n",
      "[[0.8859537215025133, 0.4869552312577687, 0.48209099709583736]]\n",
      "Repeat 1 ld 30\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_30ld.h5\n",
      "Test res 0.8778659234382481 0.45784555804571575 0.46264367816091956\n",
      "[[0.8859537215025133, 0.4869552312577687, 0.48209099709583736], [0.8778659234382481, 0.45784555804571575, 0.46264367816091956]]\n",
      "Repeat 2 ld 30\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_30ld.h5\n",
      "Test res 0.8723502853488512 0.44485609810715615 0.458984375\n",
      "[[0.8859537215025133, 0.4869552312577687, 0.48209099709583736], [0.8778659234382481, 0.45784555804571575, 0.46264367816091956], [0.8723502853488512, 0.44485609810715615, 0.458984375]]\n",
      "Repeat 3 ld 30\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_30ld.h5\n",
      "Test res 0.8744026560256104 0.45355196918195334 0.474609375\n",
      "[[0.8859537215025133, 0.4869552312577687, 0.48209099709583736], [0.8778659234382481, 0.45784555804571575, 0.46264367816091956], [0.8723502853488512, 0.44485609810715615, 0.458984375], [0.8744026560256104, 0.45355196918195334, 0.474609375]]\n",
      "Repeat 4 ld 30\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_30ld.h5\n",
      "Test res 0.8744676355313548 0.4685818154638887 0.482421875\n",
      "[[0.8859537215025133, 0.4869552312577687, 0.48209099709583736], [0.8778659234382481, 0.45784555804571575, 0.46264367816091956], [0.8723502853488512, 0.44485609810715615, 0.458984375], [0.8744026560256104, 0.45355196918195334, 0.474609375], [0.8744676355313548, 0.4685818154638887, 0.482421875]]\n",
      "Repeat 5 ld 30\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_30ld.h5\n",
      "Test res 0.8796250916257778 0.488698165227726 0.4990234375\n",
      "[[0.8859537215025133, 0.4869552312577687, 0.48209099709583736], [0.8778659234382481, 0.45784555804571575, 0.46264367816091956], [0.8723502853488512, 0.44485609810715615, 0.458984375], [0.8744026560256104, 0.45355196918195334, 0.474609375], [0.8744676355313548, 0.4685818154638887, 0.482421875], [0.8796250916257778, 0.488698165227726, 0.4990234375]]\n",
      "Repeat 6 ld 30\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_30ld.h5\n",
      "Test res 0.8779032282192436 0.4586141426030817 0.47265625\n",
      "[[0.8859537215025133, 0.4869552312577687, 0.48209099709583736], [0.8778659234382481, 0.45784555804571575, 0.46264367816091956], [0.8723502853488512, 0.44485609810715615, 0.458984375], [0.8744026560256104, 0.45355196918195334, 0.474609375], [0.8744676355313548, 0.4685818154638887, 0.482421875], [0.8796250916257778, 0.488698165227726, 0.4990234375], [0.8779032282192436, 0.4586141426030817, 0.47265625]]\n",
      "Repeat 7 ld 30\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_30ld.h5\n",
      "Test res 0.8810011144686453 0.4707764047995266 0.4761441090555015\n",
      "[[0.8859537215025133, 0.4869552312577687, 0.48209099709583736], [0.8778659234382481, 0.45784555804571575, 0.46264367816091956], [0.8723502853488512, 0.44485609810715615, 0.458984375], [0.8744026560256104, 0.45355196918195334, 0.474609375], [0.8744676355313548, 0.4685818154638887, 0.482421875], [0.8796250916257778, 0.488698165227726, 0.4990234375], [0.8779032282192436, 0.4586141426030817, 0.47265625], [0.8810011144686453, 0.4707764047995266, 0.4761441090555015]]\n",
      "Repeat 8 ld 30\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_30ld.h5\n",
      "Test res 0.8796982520045477 0.4708179959083872 0.4766081871345029\n",
      "[[0.8859537215025133, 0.4869552312577687, 0.48209099709583736], [0.8778659234382481, 0.45784555804571575, 0.46264367816091956], [0.8723502853488512, 0.44485609810715615, 0.458984375], [0.8744026560256104, 0.45355196918195334, 0.474609375], [0.8744676355313548, 0.4685818154638887, 0.482421875], [0.8796250916257778, 0.488698165227726, 0.4990234375], [0.8779032282192436, 0.4586141426030817, 0.47265625], [0.8810011144686453, 0.4707764047995266, 0.4761441090555015], [0.8796982520045477, 0.4708179959083872, 0.4766081871345029]]\n",
      "Repeat 9 ld 30\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_30ld.h5\n",
      "Test res 0.8757963028063666 0.45896536502268226 0.4692682926829268\n",
      "[[0.8859537215025133, 0.4869552312577687, 0.48209099709583736], [0.8778659234382481, 0.45784555804571575, 0.46264367816091956], [0.8723502853488512, 0.44485609810715615, 0.458984375], [0.8744026560256104, 0.45355196918195334, 0.474609375], [0.8744676355313548, 0.4685818154638887, 0.482421875], [0.8796250916257778, 0.488698165227726, 0.4990234375], [0.8779032282192436, 0.4586141426030817, 0.47265625], [0.8810011144686453, 0.4707764047995266, 0.4761441090555015], [0.8796982520045477, 0.4708179959083872, 0.4766081871345029], [0.8757963028063666, 0.45896536502268226, 0.4692682926829268]]\n",
      "gen_res {10: [(0.8526080436213499, 0.00802104725054731), (0.4131171353391091, 0.018988685560597067), (0.4390740101132993, 0.017254264807526624)], 20: [(0.8692313111461824, 0.004735401463275942), (0.44750700592124504, 0.01258285976252685), (0.4631296169062207, 0.010369194355368691)], 30: [(0.8779064210971159, 0.003740683988496591), (0.46596627456178863, 0.013340014644033917), (0.47544505766296885, 0.010639942011379903)]}\n",
      "Repeat 0 ld 40\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_40ld.h5\n",
      "Test res 0.8842143276537817 0.48155861940513184 0.49235181644359466\n",
      "[[0.8842143276537817, 0.48155861940513184, 0.49235181644359466]]\n",
      "Repeat 1 ld 40\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_40ld.h5\n",
      "Test res 0.8844854184119195 0.4637419655666838 0.484375\n",
      "[[0.8842143276537817, 0.48155861940513184, 0.49235181644359466], [0.8844854184119195, 0.4637419655666838, 0.484375]]\n",
      "Repeat 2 ld 40\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_40ld.h5\n",
      "Test res 0.8817511369076112 0.4740372784942206 0.484375\n",
      "[[0.8842143276537817, 0.48155861940513184, 0.49235181644359466], [0.8844854184119195, 0.4637419655666838, 0.484375], [0.8817511369076112, 0.4740372784942206, 0.484375]]\n",
      "Repeat 3 ld 40\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_40ld.h5\n",
      "Test res 0.877460993597415 0.4796167365160819 0.4936831875607386\n",
      "[[0.8842143276537817, 0.48155861940513184, 0.49235181644359466], [0.8844854184119195, 0.4637419655666838, 0.484375], [0.8817511369076112, 0.4740372784942206, 0.484375], [0.877460993597415, 0.4796167365160819, 0.4936831875607386]]\n",
      "Repeat 4 ld 40\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_40ld.h5\n",
      "Test res 0.8810519761249401 0.4911572438241449 0.4902534113060429\n",
      "[[0.8842143276537817, 0.48155861940513184, 0.49235181644359466], [0.8844854184119195, 0.4637419655666838, 0.484375], [0.8817511369076112, 0.4740372784942206, 0.484375], [0.877460993597415, 0.4796167365160819, 0.4936831875607386], [0.8810519761249401, 0.4911572438241449, 0.4902534113060429]]\n",
      "Repeat 5 ld 40\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_40ld.h5\n",
      "Test res 0.8808087003350884 0.4915332940869637 0.49415204678362573\n",
      "[[0.8842143276537817, 0.48155861940513184, 0.49235181644359466], [0.8844854184119195, 0.4637419655666838, 0.484375], [0.8817511369076112, 0.4740372784942206, 0.484375], [0.877460993597415, 0.4796167365160819, 0.4936831875607386], [0.8810519761249401, 0.4911572438241449, 0.4902534113060429], [0.8808087003350884, 0.4915332940869637, 0.49415204678362573]]\n",
      "Repeat 6 ld 40\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_40ld.h5\n",
      "Test res 0.884398233679392 0.47981243614860286 0.47953216374269003\n",
      "[[0.8842143276537817, 0.48155861940513184, 0.49235181644359466], [0.8844854184119195, 0.4637419655666838, 0.484375], [0.8817511369076112, 0.4740372784942206, 0.484375], [0.877460993597415, 0.4796167365160819, 0.4936831875607386], [0.8810519761249401, 0.4911572438241449, 0.4902534113060429], [0.8808087003350884, 0.4915332940869637, 0.49415204678362573], [0.884398233679392, 0.47981243614860286, 0.47953216374269003]]\n",
      "Repeat 7 ld 40\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_40ld.h5\n",
      "Test res 0.8883753066658688 0.4940390923976594 0.4980506822612086\n",
      "[[0.8842143276537817, 0.48155861940513184, 0.49235181644359466], [0.8844854184119195, 0.4637419655666838, 0.484375], [0.8817511369076112, 0.4740372784942206, 0.484375], [0.877460993597415, 0.4796167365160819, 0.4936831875607386], [0.8810519761249401, 0.4911572438241449, 0.4902534113060429], [0.8808087003350884, 0.4915332940869637, 0.49415204678362573], [0.884398233679392, 0.47981243614860286, 0.47953216374269003], [0.8883753066658688, 0.4940390923976594, 0.4980506822612086]]\n",
      "Repeat 8 ld 40\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_40ld.h5\n",
      "Test res 0.886869278063667 0.49793897007418697 0.5\n",
      "[[0.8842143276537817, 0.48155861940513184, 0.49235181644359466], [0.8844854184119195, 0.4637419655666838, 0.484375], [0.8817511369076112, 0.4740372784942206, 0.484375], [0.877460993597415, 0.4796167365160819, 0.4936831875607386], [0.8810519761249401, 0.4911572438241449, 0.4902534113060429], [0.8808087003350884, 0.4915332940869637, 0.49415204678362573], [0.884398233679392, 0.47981243614860286, 0.47953216374269003], [0.8883753066658688, 0.4940390923976594, 0.4980506822612086], [0.886869278063667, 0.49793897007418697, 0.5]]\n",
      "Repeat 9 ld 40\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_40ld.h5\n",
      "Test res 0.8879542020703686 0.4875925572546179 0.49073170731707316\n",
      "[[0.8842143276537817, 0.48155861940513184, 0.49235181644359466], [0.8844854184119195, 0.4637419655666838, 0.484375], [0.8817511369076112, 0.4740372784942206, 0.484375], [0.877460993597415, 0.4796167365160819, 0.4936831875607386], [0.8810519761249401, 0.4911572438241449, 0.4902534113060429], [0.8808087003350884, 0.4915332940869637, 0.49415204678362573], [0.884398233679392, 0.47981243614860286, 0.47953216374269003], [0.8883753066658688, 0.4940390923976594, 0.4980506822612086], [0.886869278063667, 0.49793897007418697, 0.5], [0.8879542020703686, 0.4875925572546179, 0.49073170731707316]]\n",
      "gen_res {10: [(0.8526080436213499, 0.00802104725054731), (0.4131171353391091, 0.018988685560597067), (0.4390740101132993, 0.017254264807526624)], 20: [(0.8692313111461824, 0.004735401463275942), (0.44750700592124504, 0.01258285976252685), (0.4631296169062207, 0.010369194355368691)], 30: [(0.8779064210971159, 0.003740683988496591), (0.46596627456178863, 0.013340014644033917), (0.47544505766296885, 0.010639942011379903)], 40: [(0.8837369573510052, 0.0033083417355254273), (0.48410281937682936, 0.009839758529217467), (0.4907505015414973, 0.0060743215400251875)]}\n",
      "Repeat 0 ld 50\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_50ld.h5\n",
      "Test res 0.8911863481330781 0.49822279076445797 0.4913294797687861\n",
      "[[0.8911863481330781, 0.49822279076445797, 0.4913294797687861]]\n",
      "Repeat 1 ld 50\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_50ld.h5\n",
      "Test res 0.8910765841910004 0.49444094057111954 0.4975609756097561\n",
      "[[0.8911863481330781, 0.49822279076445797, 0.4913294797687861], [0.8910765841910004, 0.49444094057111954, 0.4975609756097561]]\n",
      "Repeat 2 ld 50\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_50ld.h5\n",
      "Test res 0.8875042073061273 0.4924361177322055 0.4892578125\n",
      "[[0.8911863481330781, 0.49822279076445797, 0.4913294797687861], [0.8910765841910004, 0.49444094057111954, 0.4975609756097561], [0.8875042073061273, 0.4924361177322055, 0.4892578125]]\n",
      "Repeat 3 ld 50\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_50ld.h5\n",
      "Test res 0.8881264678823599 0.49197187102625234 0.4853515625\n",
      "[[0.8911863481330781, 0.49822279076445797, 0.4913294797687861], [0.8910765841910004, 0.49444094057111954, 0.4975609756097561], [0.8875042073061273, 0.4924361177322055, 0.4892578125], [0.8881264678823599, 0.49197187102625234, 0.4853515625]]\n",
      "Repeat 4 ld 50\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_50ld.h5\n",
      "Test res 0.87756299739708 0.4735309908933757 0.4736328125\n",
      "[[0.8911863481330781, 0.49822279076445797, 0.4913294797687861], [0.8910765841910004, 0.49444094057111954, 0.4975609756097561], [0.8875042073061273, 0.4924361177322055, 0.4892578125], [0.8881264678823599, 0.49197187102625234, 0.4853515625], [0.87756299739708, 0.4735309908933757, 0.4736328125]]\n",
      "Repeat 5 ld 50\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_50ld.h5\n",
      "Test res 0.879818393968406 0.4858324677797839 0.49609375\n",
      "[[0.8911863481330781, 0.49822279076445797, 0.4913294797687861], [0.8910765841910004, 0.49444094057111954, 0.4975609756097561], [0.8875042073061273, 0.4924361177322055, 0.4892578125], [0.8881264678823599, 0.49197187102625234, 0.4853515625], [0.87756299739708, 0.4735309908933757, 0.4736328125], [0.879818393968406, 0.4858324677797839, 0.49609375]]\n",
      "Repeat 6 ld 50\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_50ld.h5\n",
      "Test res 0.8854893284017471 0.49578023745441957 0.5087040618955513\n",
      "[[0.8911863481330781, 0.49822279076445797, 0.4913294797687861], [0.8910765841910004, 0.49444094057111954, 0.4975609756097561], [0.8875042073061273, 0.4924361177322055, 0.4892578125], [0.8881264678823599, 0.49197187102625234, 0.4853515625], [0.87756299739708, 0.4735309908933757, 0.4736328125], [0.879818393968406, 0.4858324677797839, 0.49609375], [0.8854893284017471, 0.49578023745441957, 0.5087040618955513]]\n",
      "Repeat 7 ld 50\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_50ld.h5\n",
      "Test res 0.8834125553494494 0.4903965057819397 0.49224806201550386\n",
      "[[0.8911863481330781, 0.49822279076445797, 0.4913294797687861], [0.8910765841910004, 0.49444094057111954, 0.4975609756097561], [0.8875042073061273, 0.4924361177322055, 0.4892578125], [0.8881264678823599, 0.49197187102625234, 0.4853515625], [0.87756299739708, 0.4735309908933757, 0.4736328125], [0.879818393968406, 0.4858324677797839, 0.49609375], [0.8854893284017471, 0.49578023745441957, 0.5087040618955513], [0.8834125553494494, 0.4903965057819397, 0.49224806201550386]]\n",
      "Repeat 8 ld 50\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_50ld.h5\n",
      "Test res 0.8834222789013881 0.5052170435784322 0.50390625\n",
      "[[0.8911863481330781, 0.49822279076445797, 0.4913294797687861], [0.8910765841910004, 0.49444094057111954, 0.4975609756097561], [0.8875042073061273, 0.4924361177322055, 0.4892578125], [0.8881264678823599, 0.49197187102625234, 0.4853515625], [0.87756299739708, 0.4735309908933757, 0.4736328125], [0.879818393968406, 0.4858324677797839, 0.49609375], [0.8854893284017471, 0.49578023745441957, 0.5087040618955513], [0.8834125553494494, 0.4903965057819397, 0.49224806201550386], [0.8834222789013881, 0.5052170435784322, 0.50390625]]\n",
      "Repeat 9 ld 50\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_50ld.h5\n",
      "Test res 0.8838890093944473 0.4904007096602853 0.4975704567541302\n",
      "[[0.8911863481330781, 0.49822279076445797, 0.4913294797687861], [0.8910765841910004, 0.49444094057111954, 0.4975609756097561], [0.8875042073061273, 0.4924361177322055, 0.4892578125], [0.8881264678823599, 0.49197187102625234, 0.4853515625], [0.87756299739708, 0.4735309908933757, 0.4736328125], [0.879818393968406, 0.4858324677797839, 0.49609375], [0.8854893284017471, 0.49578023745441957, 0.5087040618955513], [0.8834125553494494, 0.4903965057819397, 0.49224806201550386], [0.8834222789013881, 0.5052170435784322, 0.50390625], [0.8838890093944473, 0.4904007096602853, 0.4975704567541302]]\n",
      "gen_res {10: [(0.8526080436213499, 0.00802104725054731), (0.4131171353391091, 0.018988685560597067), (0.4390740101132993, 0.017254264807526624)], 20: [(0.8692313111461824, 0.004735401463275942), (0.44750700592124504, 0.01258285976252685), (0.4631296169062207, 0.010369194355368691)], 30: [(0.8779064210971159, 0.003740683988496591), (0.46596627456178863, 0.013340014644033917), (0.47544505766296885, 0.010639942011379903)], 40: [(0.8837369573510052, 0.0033083417355254273), (0.48410281937682936, 0.009839758529217467), (0.4907505015414973, 0.0060743215400251875)], 50: [(0.8851488170925086, 0.004238645356852331), (0.4918229675242272, 0.00786009549078567), (0.49356552235437273, 0.009298253169158489)]}\n",
      "Repeat 0 ld 60\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_60ld.h5\n",
      "Test res 0.8844194572014122 0.4938843648569775 0.5087890625\n",
      "[[0.8844194572014122, 0.4938843648569775, 0.5087890625]]\n",
      "Repeat 1 ld 60\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_60ld.h5\n",
      "Test res 0.8876126623085208 0.5011491681667292 0.49951876804619827\n",
      "[[0.8844194572014122, 0.4938843648569775, 0.5087890625], [0.8876126623085208, 0.5011491681667292, 0.49951876804619827]]\n",
      "Repeat 2 ld 60\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_60ld.h5\n",
      "Test res 0.89191575477202 0.5018730505857567 0.49271137026239065\n",
      "[[0.8844194572014122, 0.4938843648569775, 0.5087890625], [0.8876126623085208, 0.5011491681667292, 0.49951876804619827], [0.89191575477202, 0.5018730505857567, 0.49271137026239065]]\n",
      "Repeat 3 ld 60\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_60ld.h5\n",
      "Test res 0.8825954964995211 0.4940337803507012 0.49514563106796117\n",
      "[[0.8844194572014122, 0.4938843648569775, 0.5087890625], [0.8876126623085208, 0.5011491681667292, 0.49951876804619827], [0.89191575477202, 0.5018730505857567, 0.49271137026239065], [0.8825954964995211, 0.4940337803507012, 0.49514563106796117]]\n",
      "Repeat 4 ld 60\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_60ld.h5\n",
      "Test res 0.892670124760651 0.5003044306841653 0.5082926829268293\n",
      "[[0.8844194572014122, 0.4938843648569775, 0.5087890625], [0.8876126623085208, 0.5011491681667292, 0.49951876804619827], [0.89191575477202, 0.5018730505857567, 0.49271137026239065], [0.8825954964995211, 0.4940337803507012, 0.49514563106796117], [0.892670124760651, 0.5003044306841653, 0.5082926829268293]]\n",
      "Repeat 5 ld 60\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_60ld.h5\n",
      "Test res 0.8876876458532791 0.5033733318707317 0.5019493177387915\n",
      "[[0.8844194572014122, 0.4938843648569775, 0.5087890625], [0.8876126623085208, 0.5011491681667292, 0.49951876804619827], [0.89191575477202, 0.5018730505857567, 0.49271137026239065], [0.8825954964995211, 0.4940337803507012, 0.49514563106796117], [0.892670124760651, 0.5003044306841653, 0.5082926829268293], [0.8876876458532791, 0.5033733318707317, 0.5019493177387915]]\n",
      "Repeat 6 ld 60\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_60ld.h5\n",
      "Test res 0.8930593473252753 0.504530998276536 0.4931640625\n",
      "[[0.8844194572014122, 0.4938843648569775, 0.5087890625], [0.8876126623085208, 0.5011491681667292, 0.49951876804619827], [0.89191575477202, 0.5018730505857567, 0.49271137026239065], [0.8825954964995211, 0.4940337803507012, 0.49514563106796117], [0.892670124760651, 0.5003044306841653, 0.5082926829268293], [0.8876876458532791, 0.5033733318707317, 0.5019493177387915], [0.8930593473252753, 0.504530998276536, 0.4931640625]]\n",
      "Repeat 7 ld 60\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_60ld.h5\n",
      "Test res 0.8880975309657732 0.487185918307587 0.5009765625\n",
      "[[0.8844194572014122, 0.4938843648569775, 0.5087890625], [0.8876126623085208, 0.5011491681667292, 0.49951876804619827], [0.89191575477202, 0.5018730505857567, 0.49271137026239065], [0.8825954964995211, 0.4940337803507012, 0.49514563106796117], [0.892670124760651, 0.5003044306841653, 0.5082926829268293], [0.8876876458532791, 0.5033733318707317, 0.5019493177387915], [0.8930593473252753, 0.504530998276536, 0.4931640625], [0.8880975309657732, 0.487185918307587, 0.5009765625]]\n",
      "Repeat 8 ld 60\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_60ld.h5\n",
      "Test res 0.8903716266754427 0.49305061856527016 0.498046875\n",
      "[[0.8844194572014122, 0.4938843648569775, 0.5087890625], [0.8876126623085208, 0.5011491681667292, 0.49951876804619827], [0.89191575477202, 0.5018730505857567, 0.49271137026239065], [0.8825954964995211, 0.4940337803507012, 0.49514563106796117], [0.892670124760651, 0.5003044306841653, 0.5082926829268293], [0.8876876458532791, 0.5033733318707317, 0.5019493177387915], [0.8930593473252753, 0.504530998276536, 0.4931640625], [0.8880975309657732, 0.487185918307587, 0.5009765625], [0.8903716266754427, 0.49305061856527016, 0.498046875]]\n",
      "Repeat 9 ld 60\n",
      "CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_60ld.h5\n",
      "Test res 0.8914516889061753 0.5136153217930792 0.5111976630963972\n",
      "[[0.8844194572014122, 0.4938843648569775, 0.5087890625], [0.8876126623085208, 0.5011491681667292, 0.49951876804619827], [0.89191575477202, 0.5018730505857567, 0.49271137026239065], [0.8825954964995211, 0.4940337803507012, 0.49514563106796117], [0.892670124760651, 0.5003044306841653, 0.5082926829268293], [0.8876876458532791, 0.5033733318707317, 0.5019493177387915], [0.8930593473252753, 0.504530998276536, 0.4931640625], [0.8880975309657732, 0.487185918307587, 0.5009765625], [0.8903716266754427, 0.49305061856527016, 0.498046875], [0.8914516889061753, 0.5136153217930792, 0.5111976630963972]]\n",
      "gen_res {10: [(0.8526080436213499, 0.00802104725054731), (0.4131171353391091, 0.018988685560597067), (0.4390740101132993, 0.017254264807526624)], 20: [(0.8692313111461824, 0.004735401463275942), (0.44750700592124504, 0.01258285976252685), (0.4631296169062207, 0.010369194355368691)], 30: [(0.8779064210971159, 0.003740683988496591), (0.46596627456178863, 0.013340014644033917), (0.47544505766296885, 0.010639942011379903)], 40: [(0.8837369573510052, 0.0033083417355254273), (0.48410281937682936, 0.009839758529217467), (0.4907505015414973, 0.0060743215400251875)], 50: [(0.8851488170925086, 0.004238645356852331), (0.4918229675242272, 0.00786009549078567), (0.49356552235437273, 0.009298253169158489)], 60: [(0.8889881335268071, 0.003358585111409311), (0.49930009834575345, 0.007090843557928313), (0.5009791995638568, 0.006277216013664393)]}\n"
     ]
    }
   ],
   "source": [
    "repeats = {k:10 for k in [10,20,30,40,50,60]}\n",
    "lds = [10, 20, 30, 40, 50, 60]\n",
    "batch_size, lr, patience = 32, 0.0005, 10\n",
    "d, N, he, dropout = 50,2,4,0.2\n",
    "fore_savepath = 'Exp_GloVe/M/models/forecasting/forecasting_109_epochs.h5'\n",
    "\n",
    "gen_res = {}\n",
    "\n",
    "np.random.seed(2023)\n",
    "for ld in lds:\n",
    "\n",
    "    all_test_res = []\n",
    "    for i in range(repeats[ld]):\n",
    "        print ('Repeat', i, 'ld', ld)\n",
    "        savepath = 'CLS/GloVe/M/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat'+str(i)+'_'+str(ld)+'ld'+'.h5'\n",
    "        print (savepath)\n",
    "        # Build and compile model.\n",
    "        model, fore_model =  build_strats(D, max_len, V, d, N, he, dropout, forecast=True)\n",
    "        model.compile(loss=mortality_loss, optimizer=Adam(lr))\n",
    "        fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "        # Load pretrained weights here.\n",
    "        fore_model.load_weights(fore_savepath)\n",
    "        model.load_weights(savepath)\n",
    "        # Test and write to log.\n",
    "        rocauc, prauc, minrp = get_res(test_op, model.predict(test_ip, verbose=0, batch_size=batch_size))\n",
    "\n",
    "        print ('Test res', rocauc, prauc, minrp)\n",
    "        all_test_res.append([rocauc, prauc, minrp])\n",
    "        \n",
    "        # in case of unexpected disconnection\n",
    "        print(all_test_res)\n",
    "        \n",
    "    gen_res[ld] = []\n",
    "    for i in range(len(all_test_res[0])):\n",
    "        nums = [test_res[i] for test_res in all_test_res]\n",
    "        gen_res[ld].append((np.mean(nums), np.std(nums)))\n",
    "    print ('gen_res', gen_res)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
