{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "e7odgm5VsOsb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 16 09:01:46 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000000:3A:00.0 Off |                    0 |\n",
      "| N/A   30C    P0              40W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-32GB           On  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   31C    P0              40W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2-32GB           On  | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   32C    P0              41W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2-32GB           On  | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   31C    P0              41W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1876      G   /usr/libexec/Xorg                             8MiB |\n",
      "|    1   N/A  N/A      1876      G   /usr/libexec/Xorg                             8MiB |\n",
      "|    2   N/A  N/A      1876      G   /usr/libexec/Xorg                             8MiB |\n",
      "|    3   N/A  N/A      1876      G   /usr/libexec/Xorg                             8MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# gpu check\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oEEUeIW3sOsc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of cores\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count() \n",
    "cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY9I5eXWeOom"
   },
   "source": [
    "## Environment Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis\n"
     ]
    }
   ],
   "source": [
    "cd /pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 09:01:50.805231: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-16 09:01:51.534919: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-16 09:02:11.996853: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Lambda\n",
    "# from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "import pandas as pd\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, pipeline, AutoModel\n",
    "import resources.smart_cond as sc\n",
    "# from google.colab import files\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Data/CLS/cls_data.pkl'\n",
    "train_ip, valid_ip, test_ip, train_op, valid_op, test_op = pickle.load(open(data_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ip[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "train_ip[-1] = pad_sequences(train_ip[-1], maxlen=768*50, padding='post', dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_ip[-1] = pad_sequences(valid_ip[-1], maxlen=768*50, padding='post', dtype='float32')\n",
    "test_ip[-1] = pad_sequences(test_ip[-1], maxlen=768*50, padding='post', dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path ='Data/CLS/cls_text_times.pkl'\n",
    "train_times, valid_times, test_times, train_varis, valid_varis, test_varis = pickle.load(open(data_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ip.append(train_times)\n",
    "valid_ip.append(valid_times)\n",
    "test_ip.append(test_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ip.append(train_varis)\n",
    "valid_ip.append(valid_varis)\n",
    "test_ip.append(test_varis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_res(y_true, y_pred):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    minrp = np.minimum(precision, recall).max()\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    return [roc_auc, pr_auc, minrp]\n",
    "\n",
    "######################################################################################################## \n",
    "######################################################################################################## \n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=[0,1], y=train_op)\n",
    "def mortality_loss(y_true, y_pred):\n",
    "    sample_weights = (1-y_true)*class_weights[0] + y_true*class_weights[1]\n",
    "    bce = K.binary_crossentropy(y_true, y_pred)\n",
    "    return K.mean(sample_weights*bce, axis=-1)\n",
    "######################################################################################################## \n",
    "######################################################################################################## \n",
    "\n",
    "# var_weights = np.sum(fore_train_op[:, V:], axis=0)\n",
    "# var_weights[var_weights==0] = var_weights.max()\n",
    "# var_weights = var_weights.max()/var_weights\n",
    "# var_weights = var_weights.reshape((1, V))\n",
    "def forecast_loss(y_true, y_pred):\n",
    "    return K.sum(y_true[:,V:]*(y_true[:,:V]-y_pred)**2, axis=-1)\n",
    "\n",
    "def get_min_loss(weight):\n",
    "    def min_loss(y_true, y_pred):\n",
    "        return weight*y_pred\n",
    "    return min_loss\n",
    "\n",
    "class CustomCallback(Callback):\n",
    "    def __init__(self, validation_data, batch_size):\n",
    "        self.val_x, self.val_y = validation_data\n",
    "        self.batch_size = batch_size\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.val_x, verbose=0, batch_size=self.batch_size)\n",
    "        if type(y_pred)==type([]):\n",
    "            y_pred = y_pred[0]\n",
    "        precision, recall, thresholds = precision_recall_curve(self.val_y, y_pred)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        roc_auc = roc_auc_score(self.val_y, y_pred)\n",
    "        logs['custom_metric'] = pr_auc + roc_auc\n",
    "        print ('val_aucs:', pr_auc, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Embedding, Activation, Dropout, Softmax, Layer, InputSpec, Input, Dense, Lambda, TimeDistributed, Concatenate, Add\n",
    "from tensorflow.keras import initializers, regularizers, constraints, Model\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "  \n",
    "class CVE(Layer):\n",
    "    def __init__(self, hid_units, output_dim):\n",
    "        self.hid_units = hid_units\n",
    "        self.output_dim = output_dim\n",
    "        super(CVE, self).__init__()\n",
    "        \n",
    "    def build(self, input_shape): \n",
    "        self.W1 = self.add_weight(name='CVE_W1',\n",
    "                            shape=(1, self.hid_units),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        self.b1 = self.add_weight(name='CVE_b1',\n",
    "                            shape=(self.hid_units,),\n",
    "                            initializer='zeros',\n",
    "                            trainable=True)\n",
    "        self.W2 = self.add_weight(name='CVE_W2',\n",
    "                            shape=(self.hid_units, self.output_dim),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        super(CVE, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = K.expand_dims(x, axis=-1)\n",
    "        x = K.dot(K.tanh(K.bias_add(K.dot(x, self.W1), self.b1)), self.W2)\n",
    "        return x\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape + (self.output_dim,)\n",
    "    \n",
    "    \n",
    "class Attention(Layer):\n",
    "    \n",
    "    def __init__(self, hid_dim):\n",
    "        self.hid_dim = hid_dim\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        self.W = self.add_weight(shape=(d, self.hid_dim), name='Att_W',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.hid_dim,), name='Att_b',\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        self.u = self.add_weight(shape=(self.hid_dim,1), name='Att_u',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask, mask_value=-1e30):\n",
    "        attn_weights = K.dot(K.tanh(K.bias_add(K.dot(x,self.W), self.b)), self.u)\n",
    "        mask = K.expand_dims(mask, axis=-1)\n",
    "        attn_weights = mask*attn_weights + (1-mask)*mask_value\n",
    "        attn_weights = K.softmax(attn_weights, axis=-2)\n",
    "        return attn_weights\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1] + (1,)\n",
    "    \n",
    "    \n",
    "class Transformer(Layer):\n",
    "    \n",
    "    def __init__(self, N=2, h=8, dk=None, dv=None, dff=None, dropout=0):\n",
    "        self.N, self.h, self.dk, self.dv, self.dff, self.dropout = N, h, dk, dv, dff, dropout\n",
    "        self.epsilon = K.epsilon() * K.epsilon()\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        if self.dk==None:\n",
    "            self.dk = d//self.h\n",
    "        if self.dv==None:\n",
    "            self.dv = d//self.h\n",
    "        if self.dff==None:\n",
    "            self.dff = 2*d\n",
    "        self.Wq = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wq',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wk = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wk',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wv = self.add_weight(shape=(self.N, self.h, d, self.dv), name='Wv',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wo = self.add_weight(shape=(self.N, self.dv*self.h, d), name='Wo',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.W1 = self.add_weight(shape=(self.N, d, self.dff), name='W1',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b1 = self.add_weight(shape=(self.N, self.dff), name='b1',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.W2 = self.add_weight(shape=(self.N, self.dff, d), name='W2',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b2 = self.add_weight(shape=(self.N, d), name='b2',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.gamma = self.add_weight(shape=(2*self.N,), name='gamma',\n",
    "                                 initializer='ones', trainable=True)\n",
    "        self.beta = self.add_weight(shape=(2*self.N,), name='beta',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        super(Transformer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask, mask_value=-1e-30):\n",
    "        mask = K.expand_dims(mask, axis=-2)\n",
    "        for i in range(self.N):\n",
    "            # MHA\n",
    "            mha_ops = []\n",
    "            for j in range(self.h):\n",
    "                q = K.dot(x, self.Wq[i,j,:,:])\n",
    "                k = K.permute_dimensions(K.dot(x, self.Wk[i,j,:,:]), (0,2,1))\n",
    "                v = K.dot(x, self.Wv[i,j,:,:])\n",
    "                A = K.batch_dot(q,k)\n",
    "                # Mask unobserved steps.\n",
    "                A = mask*A + (1-mask)*mask_value\n",
    "                # Mask for attention dropout.\n",
    "                def dropped_A():\n",
    "                    dp_mask = K.cast((K.random_uniform(shape=array_ops.shape(A))>=self.dropout), K.floatx())\n",
    "                    return A*dp_mask + (1-dp_mask)*mask_value\n",
    "                A = sc.smart_cond(K.learning_phase(), dropped_A, lambda: array_ops.identity(A))\n",
    "                A = K.softmax(A, axis=-1)\n",
    "                mha_ops.append(K.batch_dot(A,v))\n",
    "            conc = K.concatenate(mha_ops, axis=-1)\n",
    "            proj = K.dot(conc, self.Wo[i,:,:])\n",
    "            # Dropout.\n",
    "            proj = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(proj, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(proj))\n",
    "            # Add & LN\n",
    "            x = x+proj\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i] + self.beta[2*i]\n",
    "            # FFN\n",
    "            ffn_op = K.bias_add(K.dot(K.relu(K.bias_add(K.dot(x, self.W1[i,:,:]), self.b1[i,:])), \n",
    "                           self.W2[i,:,:]), self.b2[i,:,])\n",
    "            # Dropout.\n",
    "            ffn_op = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(ffn_op, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(ffn_op))\n",
    "            # Add & LN\n",
    "            x = x+ffn_op\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i+1] + self.beta[2*i+1]            \n",
    "        return x\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "def build_strats(D, max_len, V, d, N, he, dropout, forecast=False):\n",
    "    # demo\n",
    "    demo = Input(shape=(D,))\n",
    "    demo_enc = Dense(2*d, activation='tanh')(demo)\n",
    "    demo_enc = Dense(d, activation='tanh')(demo_enc)\n",
    "    \n",
    "    ## text\n",
    "    # text\n",
    "    texts = Input(shape=(768*50,))\n",
    "    text_enc = Dense(1000, activation='relu')(texts)\n",
    "    text_enc = Dense(d, activation='relu')(text_enc)\n",
    "\n",
    "    text_2d = Lambda(lambda x: K.reshape(x, (-1, 50, 768)), input_shape=(None, 50*768))(texts)\n",
    "    \n",
    "    # Q \n",
    "    text_enc = Dense(1000, activation='relu')(texts)\n",
    "    text_d = Dense(50, activation='relu')(text_enc)\n",
    "    \n",
    "    \n",
    "    # text time\n",
    "    text_times = Input(shape=(50,))\n",
    "    cve_units = int(np.sqrt(d))\n",
    "    text_times_emb = CVE(cve_units, 768)(text_times)\n",
    "    \n",
    "    # text varis\n",
    "    text_varis = Input(shape=(50,))\n",
    "    # text_varis_emb = Embedding(1+1, d)(text_varis)\n",
    "    \n",
    "    text_comb_emb = Add()([text_2d, text_times_emb])\n",
    "    text_mask = Lambda(lambda x:K.clip(x,0,1))(text_varis)\n",
    "    # text_mask =  Lambda(lambda x: K.reshape(x, (-1, 50, 768)), input_shape=(None, 50*768))(text_varis)\n",
    "    text_cont_emb = Transformer(N, he, dk=None, dv=None, dff=None, dropout=dropout)(text_comb_emb, mask=text_mask)\n",
    "    text_attn_weights = Attention(2*d)(text_cont_emb, mask=text_mask)\n",
    "    text_fused_emb = Lambda(lambda x:K.sum(x[0]*x[1], axis=-2))([text_cont_emb, text_attn_weights])\n",
    "    \n",
    "    text_dense_0 = Dense(200, activation='relu')(text_fused_emb)\n",
    "    text_dense = Dense(50, activation='relu')(text_dense_0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## physio\n",
    "    # triplet\n",
    "    varis = Input(shape=(max_len,))\n",
    "    values = Input(shape=(max_len,))\n",
    "    times = Input(shape=(max_len,))\n",
    "    \n",
    "    \n",
    "    varis_emb = Embedding(V+1, d)(varis)\n",
    "    cve_units = int(np.sqrt(d))\n",
    "    values_emb = CVE(cve_units, d)(values)\n",
    "    times_emb = CVE(cve_units, d)(times)\n",
    "    \n",
    "    \n",
    "    # comb_emb = Add()([varis_emb, values_emb, times_emb]) # b, L, d\n",
    "    \n",
    "    # comb_emb = Add()([varis_emb, values_emb, times_emb]) # b, L, d\n",
    "    \n",
    "    # Q\n",
    "    comb_emb = Add()([varis_emb, values_emb, times_emb, text_d])\n",
    "#     demo_enc = Lambda(lambda x:K.expand_dims(x, axis=-2))(demo_enc) # b, 1, d\n",
    "#     comb_emb = Concatenate(axis=-2)([demo_enc, comb_emb]) # b, L+1, d\n",
    "    mask = Lambda(lambda x:K.clip(x,0,1))(varis) # b, L\n",
    "#     mask = Lambda(lambda x:K.concatenate((K.ones_like(x)[:,0:1], x), axis=-1))(mask) # b, L+1\n",
    "    cont_emb = Transformer(N, he, dk=None, dv=None, dff=None, dropout=dropout)(comb_emb, mask=mask)\n",
    "    attn_weights = Attention(2*d)(cont_emb, mask=mask)\n",
    "    fused_emb = Lambda(lambda x:K.sum(x[0]*x[1], axis=-2))([cont_emb, attn_weights])\n",
    "    \n",
    "#     # embed text input\n",
    "#     texts = Input(shape=(33792,))\n",
    "#     text_enc = Dense(1000, activation='relu')(texts)\n",
    "#     text_enc = Dense(d, activation='relu')(text_enc)\n",
    "\n",
    "\n",
    "    # conc = Concatenate(axis=-1)([fused_emb, text_fused_emb, demo_enc])\n",
    "    conc = Concatenate(axis=-1)([fused_emb, text_dense, demo_enc])\n",
    "    \n",
    "    \n",
    "#     fore_op = Dense(V)(conc)\n",
    "#     op = Dense(1, activation='sigmoid')(fore_op)\n",
    "#     model = Model([demo, times, values, varis, texts, text_times, text_varis], op)\n",
    "#     if forecast:\n",
    "#         fore_model = Model([demo, times, values, varis, texts, text_times, text_varis], fore_op)\n",
    "#         return [model, fore_model]\n",
    "#     return model\n",
    "\n",
    "    \n",
    "    fore_op = Dense(V)(conc)\n",
    "    op = Dense(1, activation='sigmoid')(fore_op)\n",
    "    model = Model([demo, times, values, varis, texts, text_times, text_varis], op)\n",
    "    if forecast:\n",
    "        fore_model = Model([demo, times, values, varis, texts, text_times, text_varis], fore_op)\n",
    "        return [model, fore_model]\n",
    "    return model\n",
    "\n",
    "# To tune:\n",
    "# 1. Transformer parameters. (N, h, dropout)\n",
    "# 2. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "D = 2\n",
    "max_len = 880\n",
    "V = 134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats = {k:10 for k in [10,20,30,40,50,60,70,80,90,100]}\n",
    "lds = [50]\n",
    "batch_size, lr, patience = 32, 0.0005, 10\n",
    "d, N, he, dropout = 50,2,4,0.2\n",
    "\n",
    "# best val model\n",
    "fore_savepath = 'hierar/Pro/models/forecasting/forecasting_102_epochs.h5'\n",
    "\n",
    "train_inds = np.arange(len(train_op))\n",
    "valid_inds = np.arange(len(valid_op))\n",
    "gen_res = {}\n",
    "\n",
    "np.random.seed(2023)\n",
    "\n",
    "for ld in lds:\n",
    "    np.random.shuffle(train_inds)\n",
    "    np.random.shuffle(valid_inds)\n",
    "    train_starts = [int(i) for i in np.linspace(0, len(train_inds)-int(ld*len(train_inds)/100), repeats[ld])]\n",
    "    valid_starts = [int(i) for i in np.linspace(0, len(valid_inds)-int(ld*len(valid_inds)/100), repeats[ld])]\n",
    "    all_test_res = []\n",
    "    for i in range(2, 10):\n",
    "        print ('Repeat', i, 'ld', ld)\n",
    "        # Get train and validation data.\n",
    "        curr_train_ind = train_inds[np.arange(train_starts[i], train_starts[i]+int(ld*len(train_inds)/100))]\n",
    "        curr_valid_ind = valid_inds[np.arange(valid_starts[i], valid_starts[i]+int(ld*len(valid_inds)/100))]\n",
    "        curr_train_ip = [ip[curr_train_ind] for ip in train_ip]\n",
    "        curr_valid_ip = [ip[curr_valid_ind] for ip in valid_ip]\n",
    "        curr_train_op = train_op[curr_train_ind]\n",
    "        curr_valid_op = valid_op[curr_valid_ind]\n",
    "        print ('Num train:',len(curr_train_op),'Num valid:',len(curr_valid_op))\n",
    "        # Construct save_path.\n",
    "        savepath = 'CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat'+str(i)+'_'+str(ld)+'ld'+'.h5'\n",
    "        print (savepath)\n",
    "        # Build and compile model.\n",
    "        model, fore_model =  build_strats(D, max_len, V, d, N, he, dropout, forecast=True)\n",
    "        model.compile(loss=mortality_loss, optimizer=Adam(lr))\n",
    "        fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "        # Load pretrained weights here.\n",
    "        fore_model.load_weights(fore_savepath)\n",
    "        # Train model.\n",
    "        es = EarlyStopping(monitor='custom_metric', patience=patience, mode='max', \n",
    "                           restore_best_weights=True)\n",
    "        cus = CustomCallback(validation_data=(curr_valid_ip, curr_valid_op), batch_size=batch_size)\n",
    "        his = model.fit(curr_train_ip, curr_train_op, batch_size=batch_size, epochs=1000,\n",
    "                        verbose=1, callbacks=[cus, es]).history\n",
    "        model.save_weights(savepath)\n",
    "        # Test and write to log.\n",
    "        rocauc, prauc, minrp = get_res(test_op, model.predict(test_ip, verbose=0, batch_size=batch_size))\n",
    "\n",
    "        print ('Test res', rocauc, prauc, minrp)\n",
    "        all_test_res.append([rocauc, prauc, minrp])\n",
    "        \n",
    "        # in case of unexpected disconnection\n",
    "        print(all_test_res)\n",
    "        \n",
    "    gen_res[ld] = []\n",
    "    for i in range(len(all_test_res[0])):\n",
    "        nums = [test_res[i] for test_res in all_test_res]\n",
    "        gen_res[ld].append((np.mean(nums), np.std(nums)))\n",
    "    print ('gen_res', gen_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 0 ld 10\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_10ld.h5\n",
      "Test res 0.840758465099928 0.3897537654879259 0.4169921875\n",
      "[[0.840758465099928, 0.3897537654879259, 0.4169921875]]\n",
      "Repeat 1 ld 10\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_10ld.h5\n",
      "Test res 0.8441529664313069 0.3952892205852778 0.423828125\n",
      "[[0.840758465099928, 0.3897537654879259, 0.4169921875], [0.8441529664313069, 0.3952892205852778, 0.423828125]]\n",
      "Repeat 2 ld 10\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_10ld.h5\n",
      "Test res 0.8704874304392053 0.43473553632436507 0.4513018322082932\n",
      "[[0.840758465099928, 0.3897537654879259, 0.4169921875], [0.8441529664313069, 0.3952892205852778, 0.423828125], [0.8704874304392053, 0.43473553632436507, 0.4513018322082932]]\n",
      "Repeat 3 ld 10\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_10ld.h5\n",
      "Test res 0.8519910842508378 0.40584163925156563 0.4248046875\n",
      "[[0.840758465099928, 0.3897537654879259, 0.4169921875], [0.8441529664313069, 0.3952892205852778, 0.423828125], [0.8704874304392053, 0.43473553632436507, 0.4513018322082932], [0.8519910842508378, 0.40584163925156563, 0.4248046875]]\n",
      "Repeat 4 ld 10\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_10ld.h5\n",
      "Test res 0.8467014252483247 0.4325093170654361 0.4419512195121951\n",
      "[[0.840758465099928, 0.3897537654879259, 0.4169921875], [0.8441529664313069, 0.3952892205852778, 0.423828125], [0.8704874304392053, 0.43473553632436507, 0.4513018322082932], [0.8519910842508378, 0.40584163925156563, 0.4248046875], [0.8467014252483247, 0.4325093170654361, 0.4419512195121951]]\n",
      "Repeat 5 ld 10\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_10ld.h5\n",
      "Test res 0.8627758122905697 0.4117012155749999 0.4267578125\n",
      "[[0.840758465099928, 0.3897537654879259, 0.4169921875], [0.8441529664313069, 0.3952892205852778, 0.423828125], [0.8704874304392053, 0.43473553632436507, 0.4513018322082932], [0.8519910842508378, 0.40584163925156563, 0.4248046875], [0.8467014252483247, 0.4325093170654361, 0.4419512195121951], [0.8627758122905697, 0.4117012155749999, 0.4267578125]]\n",
      "Repeat 6 ld 10\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_10ld.h5\n",
      "Test res 0.8619454770524174 0.44342572073823616 0.4595910418695229\n",
      "[[0.840758465099928, 0.3897537654879259, 0.4169921875], [0.8441529664313069, 0.3952892205852778, 0.423828125], [0.8704874304392053, 0.43473553632436507, 0.4513018322082932], [0.8519910842508378, 0.40584163925156563, 0.4248046875], [0.8467014252483247, 0.4325093170654361, 0.4419512195121951], [0.8627758122905697, 0.4117012155749999, 0.4267578125], [0.8619454770524174, 0.44342572073823616, 0.4595910418695229]]\n",
      "Repeat 7 ld 10\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_10ld.h5\n",
      "Test res 0.8616697582575396 0.40795995052826145 0.4541015625\n",
      "[[0.840758465099928, 0.3897537654879259, 0.4169921875], [0.8441529664313069, 0.3952892205852778, 0.423828125], [0.8704874304392053, 0.43473553632436507, 0.4513018322082932], [0.8519910842508378, 0.40584163925156563, 0.4248046875], [0.8467014252483247, 0.4325093170654361, 0.4419512195121951], [0.8627758122905697, 0.4117012155749999, 0.4267578125], [0.8619454770524174, 0.44342572073823616, 0.4595910418695229], [0.8616697582575396, 0.40795995052826145, 0.4541015625]]\n",
      "Repeat 8 ld 10\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_10ld.h5\n",
      "Test res 0.8457541736476784 0.4070211112585576 0.43008678881388623\n",
      "[[0.840758465099928, 0.3897537654879259, 0.4169921875], [0.8441529664313069, 0.3952892205852778, 0.423828125], [0.8704874304392053, 0.43473553632436507, 0.4513018322082932], [0.8519910842508378, 0.40584163925156563, 0.4248046875], [0.8467014252483247, 0.4325093170654361, 0.4419512195121951], [0.8627758122905697, 0.4117012155749999, 0.4267578125], [0.8619454770524174, 0.44342572073823616, 0.4595910418695229], [0.8616697582575396, 0.40795995052826145, 0.4541015625], [0.8457541736476784, 0.4070211112585576, 0.43008678881388623]]\n",
      "Repeat 9 ld 10\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_10ld.h5\n",
      "Test res 0.8505574213140259 0.4165132852089176 0.442495126705653\n",
      "[[0.840758465099928, 0.3897537654879259, 0.4169921875], [0.8441529664313069, 0.3952892205852778, 0.423828125], [0.8704874304392053, 0.43473553632436507, 0.4513018322082932], [0.8519910842508378, 0.40584163925156563, 0.4248046875], [0.8467014252483247, 0.4325093170654361, 0.4419512195121951], [0.8627758122905697, 0.4117012155749999, 0.4267578125], [0.8619454770524174, 0.44342572073823616, 0.4595910418695229], [0.8616697582575396, 0.40795995052826145, 0.4541015625], [0.8457541736476784, 0.4070211112585576, 0.43008678881388623], [0.8505574213140259, 0.4165132852089176, 0.442495126705653]]\n",
      "gen_res {10: [(0.8536794014031834, 0.009376728956898077), (0.4144750762023544, 0.01654537232689274), (0.437191038410955, 0.013917393597017498)]}\n",
      "Repeat 0 ld 20\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_20ld.h5\n",
      "Test res 0.8761236779709191 0.4636858492495198 0.4736328125\n",
      "[[0.8761236779709191, 0.4636858492495198, 0.4736328125]]\n",
      "Repeat 1 ld 20\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_20ld.h5\n",
      "Test res 0.8677236510441597 0.4509493832110102 0.466796875\n",
      "[[0.8761236779709191, 0.4636858492495198, 0.4736328125], [0.8677236510441597, 0.4509493832110102, 0.466796875]]\n",
      "Repeat 2 ld 20\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_20ld.h5\n",
      "Test res 0.8782445342418623 0.4622472866974564 0.48097560975609754\n",
      "[[0.8761236779709191, 0.4636858492495198, 0.4736328125], [0.8677236510441597, 0.4509493832110102, 0.466796875], [0.8782445342418623, 0.4622472866974564, 0.48097560975609754]]\n",
      "Repeat 3 ld 20\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_20ld.h5\n",
      "Test res 0.8621413505265676 0.44622924243046314 0.46071774975751695\n",
      "[[0.8761236779709191, 0.4636858492495198, 0.4736328125], [0.8677236510441597, 0.4509493832110102, 0.466796875], [0.8782445342418623, 0.4622472866974564, 0.48097560975609754], [0.8621413505265676, 0.44622924243046314, 0.46071774975751695]]\n",
      "Repeat 4 ld 20\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_20ld.h5\n",
      "Test res 0.8734469430648636 0.4336810834222446 0.4560546875\n",
      "[[0.8761236779709191, 0.4636858492495198, 0.4736328125], [0.8677236510441597, 0.4509493832110102, 0.466796875], [0.8782445342418623, 0.4622472866974564, 0.48097560975609754], [0.8621413505265676, 0.44622924243046314, 0.46071774975751695], [0.8734469430648636, 0.4336810834222446, 0.4560546875]]\n",
      "Repeat 5 ld 20\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_20ld.h5\n",
      "Test res 0.8750941501615606 0.447522871652971 0.4649805447470817\n",
      "[[0.8761236779709191, 0.4636858492495198, 0.4736328125], [0.8677236510441597, 0.4509493832110102, 0.466796875], [0.8782445342418623, 0.4622472866974564, 0.48097560975609754], [0.8621413505265676, 0.44622924243046314, 0.46071774975751695], [0.8734469430648636, 0.4336810834222446, 0.4560546875], [0.8750941501615606, 0.447522871652971, 0.4649805447470817]]\n",
      "Repeat 6 ld 20\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_20ld.h5\n",
      "Test res 0.8728702616383436 0.4515942428155513 0.4658203125\n",
      "[[0.8761236779709191, 0.4636858492495198, 0.4736328125], [0.8677236510441597, 0.4509493832110102, 0.466796875], [0.8782445342418623, 0.4622472866974564, 0.48097560975609754], [0.8621413505265676, 0.44622924243046314, 0.46071774975751695], [0.8734469430648636, 0.4336810834222446, 0.4560546875], [0.8750941501615606, 0.447522871652971, 0.4649805447470817], [0.8728702616383436, 0.4515942428155513, 0.4658203125]]\n",
      "Repeat 7 ld 20\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_20ld.h5\n",
      "Test res 0.8764276792125419 0.4476676051314843 0.46634146341463417\n",
      "[[0.8761236779709191, 0.4636858492495198, 0.4736328125], [0.8677236510441597, 0.4509493832110102, 0.466796875], [0.8782445342418623, 0.4622472866974564, 0.48097560975609754], [0.8621413505265676, 0.44622924243046314, 0.46071774975751695], [0.8734469430648636, 0.4336810834222446, 0.4560546875], [0.8750941501615606, 0.447522871652971, 0.4649805447470817], [0.8728702616383436, 0.4515942428155513, 0.4658203125], [0.8764276792125419, 0.4476676051314843, 0.46634146341463417]]\n",
      "Repeat 8 ld 20\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_20ld.h5\n",
      "Test res 0.8700148564654142 0.42613796741068094 0.4451988360814743\n",
      "[[0.8761236779709191, 0.4636858492495198, 0.4736328125], [0.8677236510441597, 0.4509493832110102, 0.466796875], [0.8782445342418623, 0.4622472866974564, 0.48097560975609754], [0.8621413505265676, 0.44622924243046314, 0.46071774975751695], [0.8734469430648636, 0.4336810834222446, 0.4560546875], [0.8750941501615606, 0.447522871652971, 0.4649805447470817], [0.8728702616383436, 0.4515942428155513, 0.4658203125], [0.8764276792125419, 0.4476676051314843, 0.46634146341463417], [0.8700148564654142, 0.42613796741068094, 0.4451988360814743]]\n",
      "Repeat 9 ld 20\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_20ld.h5\n",
      "Test res 0.8638282932922451 0.4248748327055107 0.45233463035019456\n",
      "[[0.8761236779709191, 0.4636858492495198, 0.4736328125], [0.8677236510441597, 0.4509493832110102, 0.466796875], [0.8782445342418623, 0.4622472866974564, 0.48097560975609754], [0.8621413505265676, 0.44622924243046314, 0.46071774975751695], [0.8734469430648636, 0.4336810834222446, 0.4560546875], [0.8750941501615606, 0.447522871652971, 0.4649805447470817], [0.8728702616383436, 0.4515942428155513, 0.4658203125], [0.8764276792125419, 0.4476676051314843, 0.46634146341463417], [0.8700148564654142, 0.42613796741068094, 0.4451988360814743], [0.8638282932922451, 0.4248748327055107, 0.45233463035019456]]\n",
      "gen_res {10: [(0.8536794014031834, 0.009376728956898077), (0.4144750762023544, 0.01654537232689274), (0.437191038410955, 0.013917393597017498)], 20: [(0.8715915397618478, 0.005220702571783904), (0.44545903647268925, 0.012756607913795051), (0.4632853521607, 0.009782131287866154)]}\n",
      "Repeat 0 ld 30\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_30ld.h5\n",
      "Test res 0.8791526111476782 0.46217537377889567 0.4853515625\n",
      "[[0.8791526111476782, 0.46217537377889567, 0.4853515625]]\n",
      "Repeat 1 ld 30\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_30ld.h5\n",
      "Test res 0.8816970963977979 0.4737258069827578 0.485024154589372\n",
      "[[0.8791526111476782, 0.46217537377889567, 0.4853515625], [0.8816970963977979, 0.4737258069827578, 0.485024154589372]]\n",
      "Repeat 2 ld 30\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_30ld.h5\n",
      "Test res 0.8770762120781473 0.463444620249509 0.4806201550387597\n",
      "[[0.8791526111476782, 0.46217537377889567, 0.4853515625], [0.8816970963977979, 0.4737258069827578, 0.485024154589372], [0.8770762120781473, 0.463444620249509, 0.4806201550387597]]\n",
      "Repeat 3 ld 30\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_30ld.h5\n",
      "Test res 0.8788034047391096 0.4684750454088815 0.4765625\n",
      "[[0.8791526111476782, 0.46217537377889567, 0.4853515625], [0.8816970963977979, 0.4737258069827578, 0.485024154589372], [0.8770762120781473, 0.463444620249509, 0.4806201550387597], [0.8788034047391096, 0.4684750454088815, 0.4765625]]\n",
      "Repeat 4 ld 30\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_30ld.h5\n",
      "Test res 0.8831254768280279 0.4841813952195178 0.5009765625\n",
      "[[0.8791526111476782, 0.46217537377889567, 0.4853515625], [0.8816970963977979, 0.4737258069827578, 0.485024154589372], [0.8770762120781473, 0.463444620249509, 0.4806201550387597], [0.8788034047391096, 0.4684750454088815, 0.4765625], [0.8831254768280279, 0.4841813952195178, 0.5009765625]]\n",
      "Repeat 5 ld 30\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_30ld.h5\n",
      "Test res 0.874229034526089 0.4676556488650565 0.4814453125\n",
      "[[0.8791526111476782, 0.46217537377889567, 0.4853515625], [0.8816970963977979, 0.4737258069827578, 0.485024154589372], [0.8770762120781473, 0.463444620249509, 0.4806201550387597], [0.8788034047391096, 0.4684750454088815, 0.4765625], [0.8831254768280279, 0.4841813952195178, 0.5009765625], [0.874229034526089, 0.4676556488650565, 0.4814453125]]\n",
      "Repeat 6 ld 30\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_30ld.h5\n",
      "Test res 0.8756999087482048 0.46506729029218014 0.47953216374269003\n",
      "[[0.8791526111476782, 0.46217537377889567, 0.4853515625], [0.8816970963977979, 0.4737258069827578, 0.485024154589372], [0.8770762120781473, 0.463444620249509, 0.4806201550387597], [0.8788034047391096, 0.4684750454088815, 0.4765625], [0.8831254768280279, 0.4841813952195178, 0.5009765625], [0.874229034526089, 0.4676556488650565, 0.4814453125], [0.8756999087482048, 0.46506729029218014, 0.47953216374269003]]\n",
      "Repeat 7 ld 30\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_30ld.h5\n",
      "Test res 0.8778299275969363 0.46448896635167697 0.467444120505345\n",
      "[[0.8791526111476782, 0.46217537377889567, 0.4853515625], [0.8816970963977979, 0.4737258069827578, 0.485024154589372], [0.8770762120781473, 0.463444620249509, 0.4806201550387597], [0.8788034047391096, 0.4684750454088815, 0.4765625], [0.8831254768280279, 0.4841813952195178, 0.5009765625], [0.874229034526089, 0.4676556488650565, 0.4814453125], [0.8756999087482048, 0.46506729029218014, 0.47953216374269003], [0.8778299275969363, 0.46448896635167697, 0.467444120505345]]\n",
      "Repeat 8 ld 30\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_30ld.h5\n",
      "Test res 0.8815783101214697 0.4788409164944271 0.4820754716981132\n",
      "[[0.8791526111476782, 0.46217537377889567, 0.4853515625], [0.8816970963977979, 0.4737258069827578, 0.485024154589372], [0.8770762120781473, 0.463444620249509, 0.4806201550387597], [0.8788034047391096, 0.4684750454088815, 0.4765625], [0.8831254768280279, 0.4841813952195178, 0.5009765625], [0.874229034526089, 0.4676556488650565, 0.4814453125], [0.8756999087482048, 0.46506729029218014, 0.47953216374269003], [0.8778299275969363, 0.46448896635167697, 0.467444120505345], [0.8815783101214697, 0.4788409164944271, 0.4820754716981132]]\n",
      "Repeat 9 ld 30\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_30ld.h5\n",
      "Test res 0.8792953323210866 0.46683500727346894 0.4814453125\n",
      "[[0.8791526111476782, 0.46217537377889567, 0.4853515625], [0.8816970963977979, 0.4737258069827578, 0.485024154589372], [0.8770762120781473, 0.463444620249509, 0.4806201550387597], [0.8788034047391096, 0.4684750454088815, 0.4765625], [0.8831254768280279, 0.4841813952195178, 0.5009765625], [0.874229034526089, 0.4676556488650565, 0.4814453125], [0.8756999087482048, 0.46506729029218014, 0.47953216374269003], [0.8778299275969363, 0.46448896635167697, 0.467444120505345], [0.8815783101214697, 0.4788409164944271, 0.4820754716981132], [0.8792953323210866, 0.46683500727346894, 0.4814453125]]\n",
      "gen_res {10: [(0.8536794014031834, 0.009376728956898077), (0.4144750762023544, 0.01654537232689274), (0.437191038410955, 0.013917393597017498)], 20: [(0.8715915397618478, 0.005220702571783904), (0.44545903647268925, 0.012756607913795051), (0.4632853521607, 0.009782131287866154)], 30: [(0.8788487314504547, 0.0026378903244496177), (0.46948900709163716, 0.006835816109273128), (0.48204773155742797, 0.007940534603651616)]}\n",
      "Repeat 0 ld 40\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_40ld.h5\n",
      "Test res 0.8906360324916228 0.48633432972995494 0.4980506822612086\n",
      "[[0.8906360324916228, 0.48633432972995494, 0.4980506822612086]]\n",
      "Repeat 1 ld 40\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_40ld.h5\n",
      "Test res 0.8771457261249402 0.4833170845583637 0.4873046875\n",
      "[[0.8906360324916228, 0.48633432972995494, 0.4980506822612086], [0.8771457261249402, 0.4833170845583637, 0.4873046875]]\n",
      "Repeat 2 ld 40\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_40ld.h5\n",
      "Test res 0.8881990672869795 0.49607165807459364 0.5\n",
      "[[0.8906360324916228, 0.48633432972995494, 0.4980506822612086], [0.8771457261249402, 0.4833170845583637, 0.4873046875], [0.8881990672869795, 0.49607165807459364, 0.5]]\n",
      "Repeat 3 ld 40\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_40ld.h5\n",
      "Test res 0.8889092605612734 0.48289455467882675 0.49514563106796117\n",
      "[[0.8906360324916228, 0.48633432972995494, 0.4980506822612086], [0.8771457261249402, 0.4833170845583637, 0.4873046875], [0.8881990672869795, 0.49607165807459364, 0.5], [0.8889092605612734, 0.48289455467882675, 0.49514563106796117]]\n",
      "Repeat 4 ld 40\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_40ld.h5\n",
      "Test res 0.8890883048109144 0.48059736478419496 0.49365853658536585\n",
      "[[0.8906360324916228, 0.48633432972995494, 0.4980506822612086], [0.8771457261249402, 0.4833170845583637, 0.4873046875], [0.8881990672869795, 0.49607165807459364, 0.5], [0.8889092605612734, 0.48289455467882675, 0.49514563106796117], [0.8890883048109144, 0.48059736478419496, 0.49365853658536585]]\n",
      "Repeat 5 ld 40\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_40ld.h5\n",
      "Test res 0.880433548872068 0.4813549912224154 0.49369544131910764\n",
      "[[0.8906360324916228, 0.48633432972995494, 0.4980506822612086], [0.8771457261249402, 0.4833170845583637, 0.4873046875], [0.8881990672869795, 0.49607165807459364, 0.5], [0.8889092605612734, 0.48289455467882675, 0.49514563106796117], [0.8890883048109144, 0.48059736478419496, 0.49365853658536585], [0.880433548872068, 0.4813549912224154, 0.49369544131910764]]\n",
      "Repeat 6 ld 40\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_40ld.h5\n",
      "Test res 0.8845905075694113 0.4774343877567337 0.48097560975609754\n",
      "[[0.8906360324916228, 0.48633432972995494, 0.4980506822612086], [0.8771457261249402, 0.4833170845583637, 0.4873046875], [0.8881990672869795, 0.49607165807459364, 0.5], [0.8889092605612734, 0.48289455467882675, 0.49514563106796117], [0.8890883048109144, 0.48059736478419496, 0.49365853658536585], [0.880433548872068, 0.4813549912224154, 0.49369544131910764], [0.8845905075694113, 0.4774343877567337, 0.48097560975609754]]\n",
      "Repeat 7 ld 40\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_40ld.h5\n",
      "Test res 0.8847209340593585 0.4843502909150328 0.4892578125\n",
      "[[0.8906360324916228, 0.48633432972995494, 0.4980506822612086], [0.8771457261249402, 0.4833170845583637, 0.4873046875], [0.8881990672869795, 0.49607165807459364, 0.5], [0.8889092605612734, 0.48289455467882675, 0.49514563106796117], [0.8890883048109144, 0.48059736478419496, 0.49365853658536585], [0.880433548872068, 0.4813549912224154, 0.49369544131910764], [0.8845905075694113, 0.4774343877567337, 0.48097560975609754], [0.8847209340593585, 0.4843502909150328, 0.4892578125]]\n",
      "Repeat 8 ld 40\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_40ld.h5\n",
      "Test res 0.8839148142053614 0.48116952242119165 0.486328125\n",
      "[[0.8906360324916228, 0.48633432972995494, 0.4980506822612086], [0.8771457261249402, 0.4833170845583637, 0.4873046875], [0.8881990672869795, 0.49607165807459364, 0.5], [0.8889092605612734, 0.48289455467882675, 0.49514563106796117], [0.8890883048109144, 0.48059736478419496, 0.49365853658536585], [0.880433548872068, 0.4813549912224154, 0.49369544131910764], [0.8845905075694113, 0.4774343877567337, 0.48097560975609754], [0.8847209340593585, 0.4843502909150328, 0.4892578125], [0.8839148142053614, 0.48116952242119165, 0.486328125]]\n",
      "Repeat 9 ld 40\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_40ld.h5\n",
      "Test res 0.880236272962542 0.47597363703835416 0.48249027237354086\n",
      "[[0.8906360324916228, 0.48633432972995494, 0.4980506822612086], [0.8771457261249402, 0.4833170845583637, 0.4873046875], [0.8881990672869795, 0.49607165807459364, 0.5], [0.8889092605612734, 0.48289455467882675, 0.49514563106796117], [0.8890883048109144, 0.48059736478419496, 0.49365853658536585], [0.880433548872068, 0.4813549912224154, 0.49369544131910764], [0.8845905075694113, 0.4774343877567337, 0.48097560975609754], [0.8847209340593585, 0.4843502909150328, 0.4892578125], [0.8839148142053614, 0.48116952242119165, 0.486328125], [0.880236272962542, 0.47597363703835416, 0.48249027237354086]]\n",
      "gen_res {10: [(0.8536794014031834, 0.009376728956898077), (0.4144750762023544, 0.01654537232689274), (0.437191038410955, 0.013917393597017498)], 20: [(0.8715915397618478, 0.005220702571783904), (0.44545903647268925, 0.012756607913795051), (0.4632853521607, 0.009782131287866154)], 30: [(0.8788487314504547, 0.0026378903244496177), (0.46948900709163716, 0.006835816109273128), (0.48204773155742797, 0.007940534603651616)], 40: [(0.8847874468944472, 0.004245021074668401), (0.4829497821179662, 0.005254244971780268), (0.49069067983632814, 0.006104880344086311)]}\n",
      "Repeat 0 ld 50\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_50ld.h5\n",
      "Test res 0.8908572432982289 0.4987146855015596 0.505859375\n",
      "[[0.8908572432982289, 0.4987146855015596, 0.505859375]]\n",
      "Repeat 1 ld 50\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_50ld.h5\n",
      "Test res 0.8800397450185495 0.47180063600383365 0.48830409356725146\n",
      "[[0.8908572432982289, 0.4987146855015596, 0.505859375], [0.8800397450185495, 0.47180063600383365, 0.48830409356725146]]\n",
      "Repeat 2 ld 50\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_50ld.h5\n",
      "Test res 0.8898346809179034 0.4961584953839882 0.49609375\n",
      "[[0.8908572432982289, 0.4987146855015596, 0.505859375], [0.8800397450185495, 0.47180063600383365, 0.48830409356725146], [0.8898346809179034, 0.4961584953839882, 0.49609375]]\n",
      "Repeat 3 ld 50\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_50ld.h5\n",
      "Test res 0.8841465900251316 0.47648778240228107 0.48830409356725146\n",
      "[[0.8908572432982289, 0.4987146855015596, 0.505859375], [0.8800397450185495, 0.47180063600383365, 0.48830409356725146], [0.8898346809179034, 0.4961584953839882, 0.49609375], [0.8841465900251316, 0.47648778240228107, 0.48830409356725146]]\n",
      "Repeat 4 ld 50\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_50ld.h5\n",
      "Test res 0.8811098499581138 0.4753672788169719 0.4892578125\n",
      "[[0.8908572432982289, 0.4987146855015596, 0.505859375], [0.8800397450185495, 0.47180063600383365, 0.48830409356725146], [0.8898346809179034, 0.4961584953839882, 0.49609375], [0.8841465900251316, 0.47648778240228107, 0.48830409356725146], [0.8811098499581138, 0.4753672788169719, 0.4892578125]]\n",
      "Repeat 5 ld 50\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_50ld.h5\n",
      "Test res 0.885181867819531 0.47838575260839655 0.48884578079534435\n",
      "[[0.8908572432982289, 0.4987146855015596, 0.505859375], [0.8800397450185495, 0.47180063600383365, 0.48830409356725146], [0.8898346809179034, 0.4961584953839882, 0.49609375], [0.8841465900251316, 0.47648778240228107, 0.48830409356725146], [0.8811098499581138, 0.4753672788169719, 0.4892578125], [0.885181867819531, 0.47838575260839655, 0.48884578079534435]]\n",
      "Repeat 6 ld 50\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_50ld.h5\n",
      "Test res 0.8820419085088559 0.4867617750804458 0.48927875243664715\n",
      "[[0.8908572432982289, 0.4987146855015596, 0.505859375], [0.8800397450185495, 0.47180063600383365, 0.48830409356725146], [0.8898346809179034, 0.4961584953839882, 0.49609375], [0.8841465900251316, 0.47648778240228107, 0.48830409356725146], [0.8811098499581138, 0.4753672788169719, 0.4892578125], [0.885181867819531, 0.47838575260839655, 0.48884578079534435], [0.8820419085088559, 0.4867617750804458, 0.48927875243664715]]\n",
      "Repeat 7 ld 50\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_50ld.h5\n",
      "Test res 0.8885527614887505 0.4846336709802886 0.5048449612403101\n",
      "[[0.8908572432982289, 0.4987146855015596, 0.505859375], [0.8800397450185495, 0.47180063600383365, 0.48830409356725146], [0.8898346809179034, 0.4961584953839882, 0.49609375], [0.8841465900251316, 0.47648778240228107, 0.48830409356725146], [0.8811098499581138, 0.4753672788169719, 0.4892578125], [0.885181867819531, 0.47838575260839655, 0.48884578079534435], [0.8820419085088559, 0.4867617750804458, 0.48927875243664715], [0.8885527614887505, 0.4846336709802886, 0.5048449612403101]]\n",
      "Repeat 8 ld 50\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_50ld.h5\n",
      "Test res 0.881917979969483 0.48393628823504087 0.5019493177387915\n",
      "[[0.8908572432982289, 0.4987146855015596, 0.505859375], [0.8800397450185495, 0.47180063600383365, 0.48830409356725146], [0.8898346809179034, 0.4961584953839882, 0.49609375], [0.8841465900251316, 0.47648778240228107, 0.48830409356725146], [0.8811098499581138, 0.4753672788169719, 0.4892578125], [0.885181867819531, 0.47838575260839655, 0.48884578079534435], [0.8820419085088559, 0.4867617750804458, 0.48927875243664715], [0.8885527614887505, 0.4846336709802886, 0.5048449612403101], [0.881917979969483, 0.48393628823504087, 0.5019493177387915]]\n",
      "Repeat 9 ld 50\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_50ld.h5\n",
      "Test res 0.8821830870033509 0.4826560134994163 0.48828125\n",
      "[[0.8908572432982289, 0.4987146855015596, 0.505859375], [0.8800397450185495, 0.47180063600383365, 0.48830409356725146], [0.8898346809179034, 0.4961584953839882, 0.49609375], [0.8841465900251316, 0.47648778240228107, 0.48830409356725146], [0.8811098499581138, 0.4753672788169719, 0.4892578125], [0.885181867819531, 0.47838575260839655, 0.48884578079534435], [0.8820419085088559, 0.4867617750804458, 0.48927875243664715], [0.8885527614887505, 0.4846336709802886, 0.5048449612403101], [0.881917979969483, 0.48393628823504087, 0.5019493177387915], [0.8821830870033509, 0.4826560134994163, 0.48828125]]\n",
      "gen_res {10: [(0.8536794014031834, 0.009376728956898077), (0.4144750762023544, 0.01654537232689274), (0.437191038410955, 0.013917393597017498)], 20: [(0.8715915397618478, 0.005220702571783904), (0.44545903647268925, 0.012756607913795051), (0.4632853521607, 0.009782131287866154)], 30: [(0.8788487314504547, 0.0026378903244496177), (0.46948900709163716, 0.006835816109273128), (0.48204773155742797, 0.007940534603651616)], 40: [(0.8847874468944472, 0.004245021074668401), (0.4829497821179662, 0.005254244971780268), (0.49069067983632814, 0.006104880344086311)], 50: [(0.8845865714007898, 0.0036780056232915415), (0.4834902378512222, 0.00826373552506643), (0.49410191868455955, 0.007033241253359715)]}\n"
     ]
    }
   ],
   "source": [
    "repeats = {k:10 for k in [10,20,30,40,50,60,70,80,90,100]}\n",
    "lds = [10,20,30,40,50]\n",
    "batch_size, lr, patience = 32, 0.0005, 10\n",
    "d, N, he, dropout = 50,2,4,0.2\n",
    "\n",
    "# best val model\n",
    "fore_savepath = 'hierar/Pro/models/forecasting/forecasting_102_epochs.h5'\n",
    "gen_res = {}\n",
    "\n",
    "np.random.seed(2023)\n",
    "\n",
    "for ld in lds:\n",
    "    all_test_res = []\n",
    "    for i in range(repeats[ld]):\n",
    "        print ('Repeat', i, 'ld', ld)\n",
    "        savepath = 'CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat'+str(i)+'_'+str(ld)+'ld'+'.h5'\n",
    "        print (savepath)\n",
    "        # Build and compile model.\n",
    "        model, fore_model =  build_strats(D, max_len, V, d, N, he, dropout, forecast=True)\n",
    "        model.compile(loss=mortality_loss, optimizer=Adam(lr))\n",
    "        fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "        # Load pretrained weights here.\n",
    "        fore_model.load_weights(fore_savepath)\n",
    "        model.load_weights(savepath)\n",
    "        # Test and write to log.\n",
    "        rocauc, prauc, minrp = get_res(test_op, model.predict(test_ip, verbose=0, batch_size=batch_size))\n",
    "\n",
    "        print ('Test res', rocauc, prauc, minrp)\n",
    "        all_test_res.append([rocauc, prauc, minrp])\n",
    "        \n",
    "        # in case of unexpected disconnection\n",
    "        print(all_test_res)\n",
    "        \n",
    "    gen_res[ld] = []\n",
    "    for i in range(len(all_test_res[0])):\n",
    "        nums = [test_res[i] for test_res in all_test_res]\n",
    "        gen_res[ld].append((np.mean(nums), np.std(nums)))\n",
    "    print ('gen_res', gen_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 0 ld 100\n",
      "Num train: 36551 Num valid: 9262\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_100ld.h5\n",
      "Epoch 1/1000\n",
      "1143/1143 [==============================] - ETA: 0s - loss: 0.4531val_aucs: 0.5263230984641378 0.8991216088872513\n",
      "1143/1143 [==============================] - 88s 67ms/step - loss: 0.4531 - custom_metric: 1.4254\n",
      "Epoch 2/1000\n",
      "1143/1143 [==============================] - ETA: 0s - loss: 0.4057val_aucs: 0.5367655354716958 0.9029692023116\n",
      "1143/1143 [==============================] - 74s 65ms/step - loss: 0.4057 - custom_metric: 1.4397\n",
      "Epoch 3/1000\n",
      "1143/1143 [==============================] - ETA: 0s - loss: 0.3884val_aucs: 0.5327780102412163 0.9006134761460061\n",
      "1143/1143 [==============================] - 74s 64ms/step - loss: 0.3884 - custom_metric: 1.4334\n",
      "Epoch 4/1000\n",
      "1143/1143 [==============================] - ETA: 0s - loss: 0.3739val_aucs: 0.5303541011203013 0.893769574801949\n",
      "1143/1143 [==============================] - 74s 64ms/step - loss: 0.3739 - custom_metric: 1.4241\n",
      "Epoch 5/1000\n",
      "1143/1143 [==============================] - ETA: 0s - loss: 0.3616val_aucs: 0.543583248262018 0.9012304331391471\n",
      "1143/1143 [==============================] - 74s 64ms/step - loss: 0.3616 - custom_metric: 1.4448\n",
      "Epoch 6/1000\n",
      "1143/1143 [==============================] - ETA: 0s - loss: 0.3497val_aucs: 0.5302910908053068 0.8984988945994193\n",
      "1143/1143 [==============================] - 74s 65ms/step - loss: 0.3497 - custom_metric: 1.4288\n",
      "Epoch 7/1000\n",
      "1143/1143 [==============================] - ETA: 0s - loss: 0.3329val_aucs: 0.509464920209959 0.8916173392245678\n",
      "1143/1143 [==============================] - 74s 65ms/step - loss: 0.3329 - custom_metric: 1.4011\n",
      "Epoch 8/1000\n",
      "1143/1143 [==============================] - ETA: 0s - loss: 0.3231val_aucs: 0.5084894006810289 0.8935189008675912\n",
      "1143/1143 [==============================] - 74s 64ms/step - loss: 0.3231 - custom_metric: 1.4020\n",
      "Epoch 9/1000\n",
      "1143/1143 [==============================] - ETA: 0s - loss: 0.2858val_aucs: 0.5013002310504473 0.8863708555419322\n",
      "1143/1143 [==============================] - 73s 64ms/step - loss: 0.2858 - custom_metric: 1.3877\n",
      "Epoch 12/1000\n",
      "1143/1143 [==============================] - ETA: 0s - loss: 0.2796val_aucs: 0.4799147846104356 0.8815115664712097\n",
      "1143/1143 [==============================] - 73s 64ms/step - loss: 0.2796 - custom_metric: 1.3614\n",
      "Epoch 13/1000\n",
      " 929/1143 [=======================>......] - ETA: 12s - loss: 0.2588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1143/1143 [==============================] - ETA: 0s - loss: 0.3451val_aucs: 0.5276339232138774 0.8973597443602335\n",
      "1143/1143 [==============================] - 74s 64ms/step - loss: 0.3451 - custom_metric: 1.4250\n",
      "Epoch 7/1000\n",
      "1143/1143 [==============================] - ETA: 0s - loss: 0.3084val_aucs: 0.515222932835272 0.896284519944857\n",
      "1143/1143 [==============================] - 73s 64ms/step - loss: 0.3084 - custom_metric: 1.4115\n",
      "Epoch 10/1000\n",
      "1143/1143 [==============================] - ETA: 0s - loss: 0.2977val_aucs: 0.4961944249979966 0.8904074470540652\n",
      "1143/1143 [==============================] - 74s 65ms/step - loss: 0.2977 - custom_metric: 1.3866\n",
      "Epoch 11/1000\n",
      "1143/1143 [==============================] - ETA: 0s - loss: 0.2856val_aucs: 0.4903206252608161 0.8851991468086322\n",
      "1143/1143 [==============================] - 73s 64ms/step - loss: 0.2856 - custom_metric: 1.3755\n",
      "Epoch 12/1000\n",
      "1142/1143 [============================>.] - ETA: 0s - loss: 0.2726val_aucs: 0.49622086125114134 0.884773702583715\n",
      "1143/1143 [==============================] - 73s 64ms/step - loss: 0.2726 - custom_metric: 1.3810\n",
      "Epoch 13/1000\n",
      "1142/1143 [============================>.] - ETA: 0s - loss: 0.2561val_aucs: 0.48260804488068676 0.8796560631857135\n",
      "1143/1143 [==============================] - 73s 64ms/step - loss: 0.2564 - custom_metric: 1.3623\n",
      "Test res 0.8938089490336286 0.4923513801275049 0.5205078125\n",
      "[[0.8913961057174487, 0.5029513988654266, 0.52734375], [0.8938089490336286, 0.4923513801275049, 0.5205078125]]\n",
      "Repeat 2 ld 100\n",
      "Num train: 36551 Num valid: 9262\n",
      "CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_100ld.h5\n",
      "Epoch 1/1000\n",
      "1134/1143 [============================>.] - ETA: 0s - loss: 0.4482"
     ]
    }
   ],
   "source": [
    "repeats = {k:5 for k in [10,20,30,40,50,60,70,80,90,100]}\n",
    "lds = [100]\n",
    "batch_size, lr, patience = 32, 0.0005, 10\n",
    "d, N, he, dropout = 50,2,4,0.2\n",
    "\n",
    "# best val model\n",
    "fore_savepath = 'hierar/Pro/models/forecasting/forecasting_102_epochs.h5'\n",
    "\n",
    "train_inds = np.arange(len(train_op))\n",
    "valid_inds = np.arange(len(valid_op))\n",
    "gen_res = {}\n",
    "\n",
    "np.random.seed(2023)\n",
    "\n",
    "for ld in lds:\n",
    "    np.random.shuffle(train_inds)\n",
    "    np.random.shuffle(valid_inds)\n",
    "    train_starts = [int(i) for i in np.linspace(0, len(train_inds)-int(ld*len(train_inds)/100), repeats[ld])]\n",
    "    valid_starts = [int(i) for i in np.linspace(0, len(valid_inds)-int(ld*len(valid_inds)/100), repeats[ld])]\n",
    "    all_test_res = []\n",
    "    for i in range(repeats[ld]):\n",
    "        print ('Repeat', i, 'ld', ld)\n",
    "        # Get train and validation data.\n",
    "        curr_train_ind = train_inds[np.arange(train_starts[i], train_starts[i]+int(ld*len(train_inds)/100))]\n",
    "        curr_valid_ind = valid_inds[np.arange(valid_starts[i], valid_starts[i]+int(ld*len(valid_inds)/100))]\n",
    "        curr_train_ip = [ip[curr_train_ind] for ip in train_ip]\n",
    "        curr_valid_ip = [ip[curr_valid_ind] for ip in valid_ip]\n",
    "        curr_train_op = train_op[curr_train_ind]\n",
    "        curr_valid_op = valid_op[curr_valid_ind]\n",
    "        print ('Num train:',len(curr_train_op),'Num valid:',len(curr_valid_op))\n",
    "        # Construct save_path.\n",
    "        savepath = 'CLS/hierar_pro/models/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat'+str(i)+'_'+str(ld)+'ld'+'.h5'\n",
    "        print (savepath)\n",
    "        # Build and compile model.\n",
    "        model, fore_model =  build_strats(D, max_len, V, d, N, he, dropout, forecast=True)\n",
    "        model.compile(loss=mortality_loss, optimizer=Adam(lr))\n",
    "        fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "        # Load pretrained weights here.\n",
    "        fore_model.load_weights(fore_savepath)\n",
    "        # Train model.\n",
    "        es = EarlyStopping(monitor='custom_metric', patience=patience, mode='max', \n",
    "                           restore_best_weights=True)\n",
    "        cus = CustomCallback(validation_data=(curr_valid_ip, curr_valid_op), batch_size=batch_size)\n",
    "        his = model.fit(curr_train_ip, curr_train_op, batch_size=batch_size, epochs=1000,\n",
    "                        verbose=1, callbacks=[cus, es]).history\n",
    "        model.save_weights(savepath)\n",
    "        # Test and write to log.\n",
    "        rocauc, prauc, minrp = get_res(test_op, model.predict(test_ip, verbose=0, batch_size=batch_size))\n",
    "\n",
    "        print ('Test res', rocauc, prauc, minrp)\n",
    "        all_test_res.append([rocauc, prauc, minrp])\n",
    "        \n",
    "        # in case of unexpected disconnection\n",
    "        print(all_test_res)\n",
    "        \n",
    "    gen_res[ld] = []\n",
    "    for i in range(len(all_test_res[0])):\n",
    "        nums = [test_res[i] for test_res in all_test_res]\n",
    "        gen_res[ld].append((np.mean(nums), np.std(nums)))\n",
    "    print ('gen_res', gen_res)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
