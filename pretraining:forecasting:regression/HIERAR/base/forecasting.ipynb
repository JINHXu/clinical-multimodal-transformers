{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! export TF_CPP_MIN_LOG_LEVEL=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "e7odgm5VsOsb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 11 16:16:52 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000000:3A:00.0 Off |                    0 |\n",
      "| N/A   29C    P0              40W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-32GB           On  | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   31C    P0              41W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1876      G   /usr/libexec/Xorg                             8MiB |\n",
      "|    1   N/A  N/A      1876      G   /usr/libexec/Xorg                             8MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# gpu check \n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oEEUeIW3sOsc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of cores\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count() \n",
    "cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY9I5eXWeOom"
   },
   "source": [
    "## Environment Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis\n"
     ]
    }
   ],
   "source": [
    "cd /pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RpTg0QzPqqKv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Lambda\n",
    "# from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "import pandas as pd\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, pipeline, AutoModel\n",
    "import resources.smart_cond as sc\n",
    "# from google.colab import files\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AeG1PfTVsOsd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf. __version__)\n",
    "\n",
    "pickle.format_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfKWDkwoeSGU"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = 'Data/sepsis_removed_0.pkl'\n",
    "pkl = pickle.load(open(data_path, 'rb'))\n",
    "data = pkl[0]\n",
    "oc = pkl[1]\n",
    "train_ind = pkl[2]\n",
    "valid_ind = pkl[3]\n",
    "test_ind = pkl[4]\n",
    "del pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_ind</th>\n",
       "      <th>hour</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>TABLE</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10223</td>\n",
       "      <td>467.816667</td>\n",
       "      <td>Text</td>\n",
       "      <td>Admission Date:  [**2119-5-4**]              D...</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18407</td>\n",
       "      <td>28.016667</td>\n",
       "      <td>Text</td>\n",
       "      <td>Admission Date:  [**2112-12-8**]              ...</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40300</td>\n",
       "      <td>155.166667</td>\n",
       "      <td>Text</td>\n",
       "      <td>Admission Date:  [**2194-7-18**]              ...</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23747</td>\n",
       "      <td>52.383333</td>\n",
       "      <td>Text</td>\n",
       "      <td>Admission Date:  [**2194-1-7**]              D...</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2357</td>\n",
       "      <td>73.133333</td>\n",
       "      <td>Text</td>\n",
       "      <td>Admission Date:  [**2186-6-7**]     Discharge ...</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886223</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>MBP</td>\n",
       "      <td>0.195381</td>\n",
       "      <td>chart</td>\n",
       "      <td>78.552377</td>\n",
       "      <td>17.645628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886224</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>O2 Saturation</td>\n",
       "      <td>-0.678068</td>\n",
       "      <td>chart</td>\n",
       "      <td>96.820961</td>\n",
       "      <td>4.160290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886225</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>RR</td>\n",
       "      <td>0.179866</td>\n",
       "      <td>chart</td>\n",
       "      <td>26.278501</td>\n",
       "      <td>15.130729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886226</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>SBP</td>\n",
       "      <td>-0.404061</td>\n",
       "      <td>chart</td>\n",
       "      <td>120.239648</td>\n",
       "      <td>25.341836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886227</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>Urine</td>\n",
       "      <td>-0.24296</td>\n",
       "      <td>output</td>\n",
       "      <td>123.393012</td>\n",
       "      <td>137.442433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82447326 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ts_ind        hour       variable  \\\n",
       "0          10223  467.816667           Text   \n",
       "1          18407   28.016667           Text   \n",
       "2          40300  155.166667           Text   \n",
       "3          23747   52.383333           Text   \n",
       "4           2357   73.133333           Text   \n",
       "...          ...         ...            ...   \n",
       "82886223   57281   20.400000            MBP   \n",
       "82886224   57281   20.400000  O2 Saturation   \n",
       "82886225   57281   20.400000             RR   \n",
       "82886226   57281   20.400000            SBP   \n",
       "82886227   57281   20.400000          Urine   \n",
       "\n",
       "                                                      value       TABLE  \\\n",
       "0         Admission Date:  [**2119-5-4**]              D...  noteevents   \n",
       "1         Admission Date:  [**2112-12-8**]              ...  noteevents   \n",
       "2         Admission Date:  [**2194-7-18**]              ...  noteevents   \n",
       "3         Admission Date:  [**2194-1-7**]              D...  noteevents   \n",
       "4         Admission Date:  [**2186-6-7**]     Discharge ...  noteevents   \n",
       "...                                                     ...         ...   \n",
       "82886223                                           0.195381       chart   \n",
       "82886224                                          -0.678068       chart   \n",
       "82886225                                           0.179866       chart   \n",
       "82886226                                          -0.404061       chart   \n",
       "82886227                                           -0.24296      output   \n",
       "\n",
       "                mean         std  \n",
       "0           1.000000    1.000000  \n",
       "1           1.000000    1.000000  \n",
       "2           1.000000    1.000000  \n",
       "3           1.000000    1.000000  \n",
       "4           1.000000    1.000000  \n",
       "...              ...         ...  \n",
       "82886223   78.552377   17.645628  \n",
       "82886224   96.820961    4.160290  \n",
       "82886225   26.278501   15.130729  \n",
       "82886226  120.239648   25.341836  \n",
       "82886227  123.393012  137.442433  \n",
       "\n",
       "[82447326 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_ind</th>\n",
       "      <th>hour</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>TABLE</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10223</td>\n",
       "      <td>467.816667</td>\n",
       "      <td>Text</td>\n",
       "      <td>1.0</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18407</td>\n",
       "      <td>28.016667</td>\n",
       "      <td>Text</td>\n",
       "      <td>1.0</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40300</td>\n",
       "      <td>155.166667</td>\n",
       "      <td>Text</td>\n",
       "      <td>1.0</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23747</td>\n",
       "      <td>52.383333</td>\n",
       "      <td>Text</td>\n",
       "      <td>1.0</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2357</td>\n",
       "      <td>73.133333</td>\n",
       "      <td>Text</td>\n",
       "      <td>1.0</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886223</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>MBP</td>\n",
       "      <td>0.195381</td>\n",
       "      <td>chart</td>\n",
       "      <td>78.552377</td>\n",
       "      <td>17.645628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886224</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>O2 Saturation</td>\n",
       "      <td>-0.678068</td>\n",
       "      <td>chart</td>\n",
       "      <td>96.820961</td>\n",
       "      <td>4.160290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886225</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>RR</td>\n",
       "      <td>0.179866</td>\n",
       "      <td>chart</td>\n",
       "      <td>26.278501</td>\n",
       "      <td>15.130729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886226</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>SBP</td>\n",
       "      <td>-0.404061</td>\n",
       "      <td>chart</td>\n",
       "      <td>120.239648</td>\n",
       "      <td>25.341836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886227</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>Urine</td>\n",
       "      <td>-0.24296</td>\n",
       "      <td>output</td>\n",
       "      <td>123.393012</td>\n",
       "      <td>137.442433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82447326 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ts_ind        hour       variable     value       TABLE        mean  \\\n",
       "0          10223  467.816667           Text       1.0  noteevents    1.000000   \n",
       "1          18407   28.016667           Text       1.0  noteevents    1.000000   \n",
       "2          40300  155.166667           Text       1.0  noteevents    1.000000   \n",
       "3          23747   52.383333           Text       1.0  noteevents    1.000000   \n",
       "4           2357   73.133333           Text       1.0  noteevents    1.000000   \n",
       "...          ...         ...            ...       ...         ...         ...   \n",
       "82886223   57281   20.400000            MBP  0.195381       chart   78.552377   \n",
       "82886224   57281   20.400000  O2 Saturation -0.678068       chart   96.820961   \n",
       "82886225   57281   20.400000             RR  0.179866       chart   26.278501   \n",
       "82886226   57281   20.400000            SBP -0.404061       chart  120.239648   \n",
       "82886227   57281   20.400000          Urine  -0.24296      output  123.393012   \n",
       "\n",
       "                 std  \n",
       "0           1.000000  \n",
       "1           1.000000  \n",
       "2           1.000000  \n",
       "3           1.000000  \n",
       "4           1.000000  \n",
       "...              ...  \n",
       "82886223   17.645628  \n",
       "82886224    4.160290  \n",
       "82886225   15.130729  \n",
       "82886226   25.341836  \n",
       "82886227  137.442433  \n",
       "\n",
       "[82447326 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['variable'] == 'Text', 'value'] = 1.0\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_window = 2 # hours\n",
    "obs_windows = range(20, 124, 4)\n",
    "# Remove test patients.\n",
    "data = data.merge(oc[['ts_ind', 'SUBJECT_ID']], on='ts_ind', how='left')\n",
    "test_sub = oc.loc[oc.ts_ind.isin(test_ind)].SUBJECT_ID.unique()\n",
    "data = data.loc[~data.SUBJECT_ID.isin(test_sub)]\n",
    "oc = oc.loc[~oc.SUBJECT_ID.isin(test_sub)]\n",
    "data.drop(columns=['SUBJECT_ID', 'TABLE'], inplace=True)\n",
    "# Fix age.\n",
    "data.loc[(data.variable=='Age')&(data.value>200), 'value'] = 91.4\n",
    "# data[data.variable=='Age'][data.value>200]['value'] = 91.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91626it [00:00, 800957.25it/s]\n",
      "100%|██████████| 26/26 [05:06<00:00, 11.79s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get static data with mean fill and missingness indicator.\n",
    "static_varis = ['Age', 'Gender']\n",
    "ii = data.variable.isin(static_varis)\n",
    "static_data = data.loc[ii]\n",
    "data = data.loc[~ii]\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "static_var_to_ind = inv_list(static_varis)\n",
    "D = len(static_varis)\n",
    "N = data.ts_ind.max()+1\n",
    "demo = np.zeros((N, D))\n",
    "for row in tqdm(static_data.itertuples()):\n",
    "    demo[row.ts_ind, static_var_to_ind[row.variable]] = row.value\n",
    "# Normalize static data.\n",
    "means = demo.mean(axis=0, keepdims=True)\n",
    "stds = demo.std(axis=0, keepdims=True)\n",
    "stds = (stds==0)*1 + (stds!=0)*stds\n",
    "demo = (demo-means)/stds\n",
    "# Get variable indices.\n",
    "varis = sorted(list(set(data.variable)))\n",
    "V = len(varis)\n",
    "var_to_ind = inv_list(varis, start=1)\n",
    "data['vind'] = data.variable.map(var_to_ind)\n",
    "data = data[['ts_ind', 'vind', 'hour', 'value']].sort_values(by=['ts_ind', 'vind', 'hour'])\n",
    "# Find max_len.\n",
    "fore_max_len = 880\n",
    "# Get forecast inputs and outputs.\n",
    "fore_times_ip = []\n",
    "fore_values_ip = []\n",
    "fore_varis_ip = []\n",
    "fore_op = []\n",
    "fore_inds = []\n",
    "def f(x):\n",
    "    mask = [0 for i in range(V)]\n",
    "    values = [0 for i in range(V)]\n",
    "    for vv in x:\n",
    "        v = int(vv[0])-1\n",
    "        mask[v] = 1\n",
    "        values[v] = vv[1]\n",
    "    return values+mask\n",
    "def pad(x):\n",
    "    return x+[0]*(fore_max_len-len(x))\n",
    "for w in tqdm(obs_windows):\n",
    "    pred_data = data.loc[(data.hour>=w)&(data.hour<=w+pred_window)]\n",
    "    pred_data = pred_data.groupby(['ts_ind', 'vind']).agg({'value':'first'}).reset_index()\n",
    "    pred_data['vind_value'] = pred_data[['vind', 'value']].values.tolist()\n",
    "    pred_data = pred_data.groupby('ts_ind').agg({'vind_value':list}).reset_index()\n",
    "    pred_data['vind_value'] = pred_data['vind_value'].apply(f)    \n",
    "    obs_data = data.loc[(data.hour<w)&(data.hour>=w-24)]\n",
    "    obs_data = obs_data.loc[obs_data.ts_ind.isin(pred_data.ts_ind)]\n",
    "    obs_data = obs_data.groupby('ts_ind').head(fore_max_len)\n",
    "    obs_data = obs_data.groupby('ts_ind').agg({'vind':list, 'hour':list, 'value':list}).reset_index()\n",
    "    obs_data = obs_data.merge(pred_data, on='ts_ind')\n",
    "    for col in ['vind', 'hour', 'value']:\n",
    "        obs_data[col] = obs_data[col].apply(pad)\n",
    "    fore_op.append(np.array(list(obs_data.vind_value)))\n",
    "    fore_inds.append(np.array(list(obs_data.ts_ind)))\n",
    "    fore_times_ip.append(np.array(list(obs_data.hour)))\n",
    "    fore_values_ip.append(np.array(list(obs_data.value)))\n",
    "    fore_varis_ip.append(np.array(list(obs_data.vind)))\n",
    "del data\n",
    "fore_times_ip = np.concatenate(fore_times_ip, axis=0)\n",
    "fore_values_ip = np.concatenate(fore_values_ip, axis=0)\n",
    "fore_varis_ip = np.concatenate(fore_varis_ip, axis=0)\n",
    "fore_op = np.concatenate(fore_op, axis=0)\n",
    "fore_inds = np.concatenate(fore_inds, axis=0)\n",
    "fore_demo = demo[fore_inds]\n",
    "# Get train and valid ts_ind for forecast task.\n",
    "train_sub = oc.loc[oc.ts_ind.isin(train_ind)].SUBJECT_ID.unique()\n",
    "valid_sub = oc.loc[oc.ts_ind.isin(valid_ind)].SUBJECT_ID.unique()\n",
    "rem_sub = oc.loc[~oc.SUBJECT_ID.isin(np.concatenate((train_ind, valid_ind)))].SUBJECT_ID.unique()\n",
    "bp = int(0.8*len(rem_sub))\n",
    "train_sub = np.concatenate((train_sub, rem_sub[:bp]))\n",
    "valid_sub = np.concatenate((valid_sub, rem_sub[bp:]))\n",
    "train_ind = oc.loc[oc.SUBJECT_ID.isin(train_sub)].ts_ind.unique() # Add remaining ts_ind s of train subjects.\n",
    "valid_ind = oc.loc[oc.SUBJECT_ID.isin(valid_sub)].ts_ind.unique() # Add remaining ts_ind s of train subjects.\n",
    "# Generate 3 sets of inputs and outputs.\n",
    "train_ind = np.argwhere(np.in1d(fore_inds, train_ind)).flatten()\n",
    "valid_ind = np.argwhere(np.in1d(fore_inds, valid_ind)).flatten()\n",
    "fore_train_ip = [ip[train_ind] for ip in [fore_demo, fore_times_ip, fore_values_ip, fore_varis_ip]]\n",
    "fore_valid_ip = [ip[valid_ind] for ip in [fore_demo, fore_times_ip, fore_values_ip, fore_varis_ip]]\n",
    "del fore_times_ip, fore_values_ip, fore_varis_ip, demo, fore_demo\n",
    "fore_train_op = fore_op[train_ind]\n",
    "fore_valid_op = fore_op[valid_ind]\n",
    "del fore_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add text features\n",
    "text_ip = pickle.load(open('Data/hierar/text_emb_input_train_val_1.pkl', 'rb'))\n",
    "\n",
    "train_text_ip = text_ip[0]\n",
    "# valid_text_ip = text_ip[1]\n",
    "\n",
    "fore_train_ip.append(train_text_ip)\n",
    "# fore_valid_ip.append(valid_text_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449482/449482 [02:16<00:00, 3288.56it/s]\n",
      "/scratch/slurm_tmpdir/job_23365184/ipykernel_562684/1196284020.py:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_text_times = np.array(train_text_times)\n",
      "/scratch/slurm_tmpdir/job_23365184/ipykernel_562684/1196284020.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_text_varis = np.array(train_text_varis)\n"
     ]
    }
   ],
   "source": [
    "# train text times\n",
    "train_text_times = []\n",
    "train_text_varis = []\n",
    "\n",
    "train_times = fore_train_ip[1]\n",
    "train_varis = fore_train_ip[3]\n",
    "\n",
    "for i in tqdm(range(len(fore_train_ip[0]))):\n",
    "    times = []\n",
    "    varis = []\n",
    "    for j in range(880):\n",
    "        if train_varis[i][j] == 124:\n",
    "            # times += [train_times[i][j]] * 768\n",
    "            times.append(train_times[i][j])\n",
    "            varis.append(135)\n",
    "    train_text_times.append(np.array(times))\n",
    "    train_text_varis.append(np.array(varis))\n",
    "\n",
    "train_text_times = np.array(train_text_times)\n",
    "train_text_varis = np.array(train_text_varis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# padding\n",
    "padded_train_text_times = pad_sequences(train_text_times, maxlen=50, padding='post', dtype='float32')\n",
    "padded_train_text_varis = pad_sequences(train_text_varis, maxlen=50, padding='post')\n",
    "\n",
    "del train_text_times, train_text_varis, train_times, train_varis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # valid text times\n",
    "# valid_text_times = []\n",
    "# valid_text_varis = []\n",
    "\n",
    "# valid_times = fore_valid_ip[1]\n",
    "# valid_varis = fore_valid_ip[3]\n",
    "\n",
    "# for i in tqdm(range(len(fore_valid_ip[0]))):\n",
    "#     times = []\n",
    "#     varis = []\n",
    "#     for j in range(880):\n",
    "#         if valid_varis[i][j] == 124:\n",
    "#             # times += [valid_times[i][j]] * 768\n",
    "#             times.append(valid_times[i][j])\n",
    "#             varis.append(135)\n",
    "#     valid_text_times.append(np.array(times))\n",
    "#     valid_text_varis.append(np.array(varis))\n",
    "\n",
    "# valid_text_times = np.array(valid_text_times)\n",
    "# valid_text_varis = np.array(valid_text_varis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # padding\n",
    "# padded_valid_text_times = pad_sequences(valid_text_times, maxlen=50, padding='post', dtype='float32')\n",
    "# padded_valid_text_varis = pad_sequences(valid_text_varis, maxlen=50, padding='post')\n",
    "\n",
    "# del valid_text_times, valid_text_varis, valid_times, valid_varis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fore_train_ip.append(padded_train_text_times)\n",
    "fore_train_ip.append(padded_train_text_varis)\n",
    "# fore_valid_ip.append(padded_valid_text_times)\n",
    "# fore_valid_ip.append(padded_valid_text_varis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res(y_true, y_pred):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    minrp = np.minimum(precision, recall).max()\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    return [roc_auc, pr_auc, minrp]\n",
    "\n",
    "# ######################################################################################################## \n",
    "# ######################################################################################################## \n",
    "# class_weights = compute_class_weight(class_weight='balanced', classes=[0,1], y=train_op)\n",
    "# def mortality_loss(y_true, y_pred):\n",
    "#     sample_weights = (1-y_true)*class_weights[0] + y_true*class_weights[1]\n",
    "#     bce = K.binary_crossentropy(y_true, y_pred)\n",
    "#     return K.mean(sample_weights*bce, axis=-1)\n",
    "# ######################################################################################################## \n",
    "# ######################################################################################################## \n",
    "\n",
    "# var_weights = np.sum(fore_train_op[:, V:], axis=0)\n",
    "# var_weights[var_weights==0] = var_weights.max()\n",
    "# var_weights = var_weights.max()/var_weights\n",
    "# var_weights = var_weights.reshape((1, V))\n",
    "def forecast_loss(y_true, y_pred):\n",
    "    return K.sum(y_true[:,V:]*(y_true[:,:V]-y_pred)**2, axis=-1)\n",
    "\n",
    "def get_min_loss(weight):\n",
    "    def min_loss(y_true, y_pred):\n",
    "        return weight*y_pred\n",
    "    return min_loss\n",
    "\n",
    "class CustomCallback(Callback):\n",
    "    def __init__(self, validation_data, batch_size):\n",
    "        self.val_x, self.val_y = validation_data\n",
    "        self.batch_size = batch_size\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.val_x, verbose=0, batch_size=self.batch_size)\n",
    "        if type(y_pred)==type([]):\n",
    "            y_pred = y_pred[0]\n",
    "        precision, recall, thresholds = precision_recall_curve(self.val_y, y_pred)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        roc_auc = roc_auc_score(self.val_y, y_pred)\n",
    "        logs['custom_metric'] = pr_auc + roc_auc\n",
    "        print ('val_aucs:', pr_auc, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Embedding, Activation, Dropout, Softmax, Layer, InputSpec, Input, Dense, Lambda, TimeDistributed, Concatenate, Add\n",
    "from tensorflow.keras import initializers, regularizers, constraints, Model\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # SEFT positional encoding\n",
    "# class PositionalEncoding(tf.keras.layers.Layer):\n",
    "#     def __init__(self, max_time=20000, n_dim=10, **kwargs):\n",
    "#         self.max_time = max_time\n",
    "#         self.n_dim = n_dim\n",
    "#         self._num_timescales = self.n_dim // 2\n",
    "#         super().__init__(**kwargs)\n",
    "\n",
    "#     def get_timescales(self):\n",
    "#         # This is a bit hacky, but works\n",
    "#         timescales = self.max_time ** np.linspace(0, 1, self._num_timescales)\n",
    "#         return timescales\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         assert len(input_shape) == 3\n",
    "#         self.timescales = self.add_weight(\n",
    "#             'timescales',\n",
    "#             (self._num_timescales, ),\n",
    "#             trainable=False,\n",
    "#             initializer=tf.keras.initializers.Constant(self.get_timescales())\n",
    "#         )\n",
    "\n",
    "#     def __call__(self, times):\n",
    "#         scaled_time = times / self.timescales[None, None, :]\n",
    "#         signal = tf.concat(\n",
    "#             [\n",
    "#                 tf.sin(scaled_time),\n",
    "#                 tf.cos(scaled_time)\n",
    "#             ],\n",
    "#             axis=-1)\n",
    "#         return signal\n",
    "\n",
    "#     def compute_output_shape(self, input_shape):\n",
    "#         return (input_shape[0], input_shape[1], self.n_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "  \n",
    "class CVE(Layer):\n",
    "    def __init__(self, hid_units, output_dim):\n",
    "        self.hid_units = hid_units\n",
    "        self.output_dim = output_dim\n",
    "        super(CVE, self).__init__()\n",
    "        \n",
    "    def build(self, input_shape): \n",
    "        self.W1 = self.add_weight(name='CVE_W1',\n",
    "                            shape=(1, self.hid_units),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        self.b1 = self.add_weight(name='CVE_b1',\n",
    "                            shape=(self.hid_units,),\n",
    "                            initializer='zeros',\n",
    "                            trainable=True)\n",
    "        self.W2 = self.add_weight(name='CVE_W2',\n",
    "                            shape=(self.hid_units, self.output_dim),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        super(CVE, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = K.expand_dims(x, axis=-1)\n",
    "        x = K.dot(K.tanh(K.bias_add(K.dot(x, self.W1), self.b1)), self.W2)\n",
    "        return x\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape + (self.output_dim,)\n",
    "    \n",
    "    \n",
    "class Attention(Layer):\n",
    "    \n",
    "    def __init__(self, hid_dim):\n",
    "        self.hid_dim = hid_dim\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        self.W = self.add_weight(shape=(d, self.hid_dim), name='Att_W',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.hid_dim,), name='Att_b',\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        self.u = self.add_weight(shape=(self.hid_dim,1), name='Att_u',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask, mask_value=-1e30):\n",
    "        attn_weights = K.dot(K.tanh(K.bias_add(K.dot(x,self.W), self.b)), self.u)\n",
    "        mask = K.expand_dims(mask, axis=-1)\n",
    "        attn_weights = mask*attn_weights + (1-mask)*mask_value\n",
    "        attn_weights = K.softmax(attn_weights, axis=-2)\n",
    "        return attn_weights\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1] + (1,)\n",
    "    \n",
    "    \n",
    "class Transformer(Layer):\n",
    "    \n",
    "    def __init__(self, N=2, h=8, dk=None, dv=None, dff=None, dropout=0):\n",
    "        self.N, self.h, self.dk, self.dv, self.dff, self.dropout = N, h, dk, dv, dff, dropout\n",
    "        self.epsilon = K.epsilon() * K.epsilon()\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        if self.dk==None:\n",
    "            self.dk = d//self.h\n",
    "        if self.dv==None:\n",
    "            self.dv = d//self.h\n",
    "        if self.dff==None:\n",
    "            self.dff = 2*d\n",
    "        self.Wq = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wq',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wk = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wk',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wv = self.add_weight(shape=(self.N, self.h, d, self.dv), name='Wv',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wo = self.add_weight(shape=(self.N, self.dv*self.h, d), name='Wo',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.W1 = self.add_weight(shape=(self.N, d, self.dff), name='W1',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b1 = self.add_weight(shape=(self.N, self.dff), name='b1',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.W2 = self.add_weight(shape=(self.N, self.dff, d), name='W2',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b2 = self.add_weight(shape=(self.N, d), name='b2',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.gamma = self.add_weight(shape=(2*self.N,), name='gamma',\n",
    "                                 initializer='ones', trainable=True)\n",
    "        self.beta = self.add_weight(shape=(2*self.N,), name='beta',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        super(Transformer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask, mask_value=-1e-30):\n",
    "        mask = K.expand_dims(mask, axis=-2)\n",
    "        for i in range(self.N):\n",
    "            # MHA\n",
    "            mha_ops = []\n",
    "            for j in range(self.h):\n",
    "                q = K.dot(x, self.Wq[i,j,:,:])\n",
    "                k = K.permute_dimensions(K.dot(x, self.Wk[i,j,:,:]), (0,2,1))\n",
    "                v = K.dot(x, self.Wv[i,j,:,:])\n",
    "                A = K.batch_dot(q,k)\n",
    "                # Mask unobserved steps.\n",
    "                A = mask*A + (1-mask)*mask_value\n",
    "                # Mask for attention dropout.\n",
    "                def dropped_A():\n",
    "                    dp_mask = K.cast((K.random_uniform(shape=array_ops.shape(A))>=self.dropout), K.floatx())\n",
    "                    return A*dp_mask + (1-dp_mask)*mask_value\n",
    "                A = sc.smart_cond(K.learning_phase(), dropped_A, lambda: array_ops.identity(A))\n",
    "                A = K.softmax(A, axis=-1)\n",
    "                mha_ops.append(K.batch_dot(A,v))\n",
    "            conc = K.concatenate(mha_ops, axis=-1)\n",
    "            proj = K.dot(conc, self.Wo[i,:,:])\n",
    "            # Dropout.\n",
    "            proj = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(proj, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(proj))\n",
    "            # Add & LN\n",
    "            x = x+proj\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i] + self.beta[2*i]\n",
    "            # FFN\n",
    "            ffn_op = K.bias_add(K.dot(K.relu(K.bias_add(K.dot(x, self.W1[i,:,:]), self.b1[i,:])), \n",
    "                           self.W2[i,:,:]), self.b2[i,:,])\n",
    "            # Dropout.\n",
    "            ffn_op = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(ffn_op, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(ffn_op))\n",
    "            # Add & LN\n",
    "            x = x+ffn_op\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i+1] + self.beta[2*i+1]            \n",
    "        return x\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "def build_strats(D, max_len, V, d, N, he, dropout, forecast=False):\n",
    "    # demo\n",
    "    demo = Input(shape=(D,))\n",
    "    demo_enc = Dense(2*d, activation='tanh')(demo)\n",
    "    demo_enc = Dense(d, activation='tanh')(demo_enc)\n",
    "    \n",
    "    ## text\n",
    "    # text\n",
    "    texts = Input(shape=(768*50,))\n",
    "#     text_enc = Dense(1000, activation='relu')(texts)\n",
    "#     text_enc = Dense(d, activation='relu')(text_enc)\n",
    "\n",
    "    text_2d = Lambda(lambda x: K.reshape(x, (-1, 50, 768)), input_shape=(None, 50*768))(texts)\n",
    "    \n",
    "    # Q \n",
    "    text_d = Dense(50, activation='relu')(texts)\n",
    "    \n",
    "    \n",
    "    # text time\n",
    "    text_times = Input(shape=(50,))\n",
    "    cve_units = int(np.sqrt(d))\n",
    "    text_times_emb = CVE(cve_units, 768)(text_times)\n",
    "    \n",
    "    # text varis\n",
    "    text_varis = Input(shape=(50,))\n",
    "    # text_varis_emb = Embedding(V+1, d)(text_varis)\n",
    "    \n",
    "    text_comb_emb = Add()([text_2d, text_times_emb])\n",
    "    text_mask = Lambda(lambda x:K.clip(x,0,1))(text_varis)\n",
    "    # text_mask =  Lambda(lambda x: K.reshape(x, (-1, 50, 768)), input_shape=(None, 50*768))(text_varis)\n",
    "    text_cont_emb = Transformer(N, he, dk=None, dv=None, dff=None, dropout=dropout)(text_comb_emb, mask=text_mask)\n",
    "    text_attn_weights = Attention(2*d)(text_cont_emb, mask=text_mask)\n",
    "    text_fused_emb = Lambda(lambda x:K.sum(x[0]*x[1], axis=-2))([text_cont_emb, text_attn_weights])\n",
    "    \n",
    "    text_dense = Dense(100, activation='relu')(text_fused_emb)\n",
    "    \n",
    "    \n",
    "    ## physio\n",
    "    # triplet\n",
    "    varis = Input(shape=(max_len,))\n",
    "    values = Input(shape=(max_len,))\n",
    "    times = Input(shape=(max_len,))\n",
    "    \n",
    "    \n",
    "    varis_emb = Embedding(V+1, d)(varis)\n",
    "    cve_units = int(np.sqrt(d))\n",
    "    values_emb = CVE(cve_units, d)(values)\n",
    "    times_emb = CVE(cve_units, d)(times)\n",
    "    \n",
    "    \n",
    "    # comb_emb = Add()([varis_emb, values_emb, times_emb]) # b, L, d\n",
    "    \n",
    "    # comb_emb = Add()([varis_emb, values_emb, times_emb]) # b, L, d\n",
    "    \n",
    "    # Q\n",
    "    comb_emb = Add()([varis_emb, values_emb, times_emb, text_d])\n",
    "#     demo_enc = Lambda(lambda x:K.expand_dims(x, axis=-2))(demo_enc) # b, 1, d\n",
    "#     comb_emb = Concatenate(axis=-2)([demo_enc, comb_emb]) # b, L+1, d\n",
    "    mask = Lambda(lambda x:K.clip(x,0,1))(varis) # b, L\n",
    "#     mask = Lambda(lambda x:K.concatenate((K.ones_like(x)[:,0:1], x), axis=-1))(mask) # b, L+1\n",
    "    cont_emb = Transformer(N, he, dk=None, dv=None, dff=None, dropout=dropout)(comb_emb, mask=mask)\n",
    "    attn_weights = Attention(2*d)(cont_emb, mask=mask)\n",
    "    fused_emb = Lambda(lambda x:K.sum(x[0]*x[1], axis=-2))([cont_emb, attn_weights])\n",
    "    \n",
    "#     # embed text input\n",
    "#     texts = Input(shape=(33792,))\n",
    "#     text_enc = Dense(1000, activation='relu')(texts)\n",
    "#     text_enc = Dense(d, activation='relu')(text_enc)\n",
    "\n",
    "\n",
    "    # conc = Concatenate(axis=-1)([fused_emb, text_fused_emb, demo_enc])\n",
    "    conc = Concatenate(axis=-1)([fused_emb, text_dense, demo_enc])\n",
    "    \n",
    "    \n",
    "#     fore_op = Dense(V)(conc)\n",
    "#     op = Dense(1, activation='sigmoid')(fore_op)\n",
    "#     model = Model([demo, times, values, varis, texts, text_times, text_varis], op)\n",
    "#     if forecast:\n",
    "#         fore_model = Model([demo, times, values, varis, texts, text_times, text_varis], fore_op)\n",
    "#         return [model, fore_model]\n",
    "#     return model\n",
    "\n",
    "    \n",
    "    fore_op = Dense(V)(conc)\n",
    "    op = Dense(1, activation='sigmoid')(fore_op)\n",
    "    model = Model([demo, times, values, varis, texts, text_times, text_varis], op)\n",
    "    if forecast:\n",
    "        fore_model = Model([demo, times, values, varis, texts, text_times, text_varis], fore_op)\n",
    "        return [model, fore_model]\n",
    "    return model\n",
    "\n",
    "# To tune:\n",
    "# 1. Transformer parameters. (N, h, dropout)\n",
    "# 2. Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGjR-HJCyU1y"
   },
   "source": [
    "## Pretrain on forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr, batch_size, samples_per_epoch, patience = 0.0005, 32, 102400, 5\n",
    "# lr, batch_size, samples_per_epoch, patience = 0.0005, 1, 1024, 5\n",
    "d, N, he, dropout = 50, 2, 4, 0.2\n",
    "model, fore_model =  build_strats(D, fore_max_len, V, d, N, he, dropout, forecast=True)\n",
    "print (fore_model.summary())\n",
    "fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "\n",
    "# Pretrain fore_model.\n",
    "best_val_loss = np.inf\n",
    "N_fore = len(fore_train_op)\n",
    "\n",
    "fore_savepath = 'hierar/models/forecasting/forecasting_1_epochs.h5'\n",
    "\n",
    "\n",
    "# save losses for visualization\n",
    "# val_losses = []\n",
    "train_losses = []\n",
    "\n",
    "# for e in range(1000):\n",
    "#     e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "#     e_loss = 0\n",
    "#     pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "#     for start in pbar:\n",
    "#         ind = e_indices[start:start+batch_size]\n",
    "#         e_loss += fore_model.train_on_batch([ip[ind] for ip in fore_train_ip], fore_train_op[ind])\n",
    "#         pbar.set_description('%f'%(e_loss/(start+1)))\n",
    "#     val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "#     val_losses.append(val_loss)\n",
    "#     print ('Epoch', e, 'loss', e_loss*batch_size/samples_per_epoch, 'val loss', val_loss)\n",
    "#     train_losses.append(e_loss*batch_size/samples_per_epoch)\n",
    "#     # model should be saved here after each epoch in case of unexpected disconnection\n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         fore_model.save_weights(fore_savepath)\n",
    "#         best_epoch = e\n",
    "#     if (e-best_epoch)>patience:\n",
    "#         break\n",
    "\n",
    "for e in range(1):\n",
    "    e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "    e_loss = 0\n",
    "    pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "    for start in pbar:\n",
    "        ind = e_indices[start:start+batch_size]\n",
    "        e_loss += fore_model.train_on_batch([ip[ind] for ip in fore_train_ip], fore_train_op[ind])\n",
    "        pbar.set_description('%f'%(e_loss/(start+1)))\n",
    "    # val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "    # val_losses.append(val_loss)\n",
    "    # print ('Epoch', e, 'loss', e_loss*batch_size/samples_per_epoch, 'val loss', val_loss)\n",
    "    print ('Epoch', e, 'loss', e_loss*batch_size/samples_per_epoch)\n",
    "    train_losses.append(e_loss*batch_size/samples_per_epoch)\n",
    "    fore_model.save_weights(fore_savepath)\n",
    "    # # model should be saved here after each epoch in case of unexpected disconnection\n",
    "    # if val_loss < best_val_loss:\n",
    "    #     best_val_loss = val_loss\n",
    "    #     fore_model.save_weights(fore_savepath)\n",
    "    #     best_epoch = e\n",
    "    # if (e-best_epoch)>patience:\n",
    "    #     break\n",
    "    print(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "# print(f'validation loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# val_loss\n",
    "## 8.26081371307373"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr, batch_size, samples_per_epoch, patience = 0.0005, 32, 102400, 5\n",
    "# # lr, batch_size, samples_per_epoch, patience = 0.0005, 1, 1024, 5\n",
    "# d, N, he, dropout = 50, 2, 4, 0.2\n",
    "# model, fore_model =  build_strats(D, fore_max_len, V, d, N, he, dropout, forecast=True)\n",
    "# print (fore_model.summary())\n",
    "\n",
    "\n",
    "# # Pretrain fore_model.\n",
    "# best_val_loss = np.inf\n",
    "# N_fore = len(fore_train_op)\n",
    "\n",
    "# # save losses for visualization\n",
    "# # val_losses = []\n",
    "# train_losses = [9.6726073936373]\n",
    "\n",
    "# # for e in range(1000):\n",
    "# #     e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "# #     e_loss = 0\n",
    "# #     pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "# #     for start in pbar:\n",
    "# #         ind = e_indices[start:start+batch_size]\n",
    "# #         e_loss += fore_model.train_on_batch([ip[ind] for ip in fore_train_ip], fore_train_op[ind])\n",
    "# #         pbar.set_description('%f'%(e_loss/(start+1)))\n",
    "# #     val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "# #     val_losses.append(val_loss)\n",
    "# #     print ('Epoch', e, 'loss', e_loss*batch_size/samples_per_epoch, 'val loss', val_loss)\n",
    "# #     train_losses.append(e_loss*batch_size/samples_per_epoch)\n",
    "# #     # model should be saved here after each epoch in case of unexpected disconnection\n",
    "# #     if val_loss < best_val_loss:\n",
    "# #         best_val_loss = val_loss\n",
    "# #         fore_model.save_weights(fore_savepath)\n",
    "# #         best_epoch = e\n",
    "# #     if (e-best_epoch)>patience:\n",
    "# #         break\n",
    "\n",
    "# for e in range(100):\n",
    "\n",
    "#     fore_loadpath = 'hierar/models/forecasting/forecasting_'+str(e+1)+'_epochs.h5'\n",
    "#     fore_savepath = 'hierar/models/forecasting/forecasting_'+str(e+1+1)+'_epochs.h5'\n",
    "    \n",
    "#     fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "#     fore_model.load_weights(fore_loadpath)\n",
    "\n",
    "#     e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "#     e_loss = 0\n",
    "#     pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "#     for start in pbar:\n",
    "#         ind = e_indices[start:start+batch_size]\n",
    "#         e_loss += fore_model.train_on_batch([ip[ind] for ip in fore_train_ip], fore_train_op[ind])\n",
    "#         pbar.set_description('%f'%(e_loss/(start+1)))\n",
    "#     # val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "#     # val_losses.append(val_loss)\n",
    "#     # print ('Epoch', e, 'loss', e_loss*batch_size/samples_per_epoch, 'val loss', val_loss)\n",
    "#     print ('Epoch', e, 'loss', e_loss*batch_size/samples_per_epoch)\n",
    "#     train_losses.append(e_loss*batch_size/samples_per_epoch)\n",
    "#     fore_model.save_weights(fore_savepath)\n",
    "#     # # model should be saved here after each epoch in case of unexpected disconnection\n",
    "#     # if val_loss < best_val_loss:\n",
    "#     #     best_val_loss = val_loss\n",
    "#     #     fore_model.save_weights(fore_savepath)\n",
    "#     #     best_epoch = e\n",
    "#     # if (e-best_epoch)>patience:\n",
    "#     #     break\n",
    "#     print(train_losses)\n",
    "\n",
    "    \n",
    "# # val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "# # print(f'validation loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr, batch_size, samples_per_epoch, patience = 0.0005, 32, 102400, 5\n",
    "# # lr, batch_size, samples_per_epoch, patience = 0.0005, 1, 1024, 5\n",
    "# d, N, he, dropout = 50, 2, 4, 0.2\n",
    "# model, fore_model =  build_strats(D, fore_max_len, V, d, N, he, dropout, forecast=True)\n",
    "# print (fore_model.summary())\n",
    "\n",
    "\n",
    "# # Pretrain fore_model.\n",
    "# best_val_loss = np.inf\n",
    "# N_fore = len(fore_train_op)\n",
    "\n",
    "# # save losses for visualization\n",
    "# # val_losses = []\n",
    "# train_losses = [9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118]\n",
    "\n",
    "# # for e in range(1000):\n",
    "# #     e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "# #     e_loss = 0\n",
    "# #     pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "# #     for start in pbar:\n",
    "# #         ind = e_indices[start:start+batch_size]\n",
    "# #         e_loss += fore_model.train_on_batch([ip[ind] for ip in fore_train_ip], fore_train_op[ind])\n",
    "# #         pbar.set_description('%f'%(e_loss/(start+1)))\n",
    "# #     val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "# #     val_losses.append(val_loss)\n",
    "# #     print ('Epoch', e, 'loss', e_loss*batch_size/samples_per_epoch, 'val loss', val_loss)\n",
    "# #     train_losses.append(e_loss*batch_size/samples_per_epoch)\n",
    "# #     # model should be saved here after each epoch in case of unexpected disconnection\n",
    "# #     if val_loss < best_val_loss:\n",
    "# #         best_val_loss = val_loss\n",
    "# #         fore_model.save_weights(fore_savepath)\n",
    "# #         best_epoch = e\n",
    "# #     if (e-best_epoch)>patience:\n",
    "# #         break\n",
    "\n",
    "# for e in range(100):\n",
    "\n",
    "#     fore_loadpath = 'hierar/models/forecasting/forecasting_'+str(e+17)+'_epochs.h5'\n",
    "#     fore_savepath = 'hierar/models/forecasting/forecasting_'+str(e+17+1)+'_epochs.h5'\n",
    "    \n",
    "#     fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "#     fore_model.load_weights(fore_loadpath)\n",
    "\n",
    "#     e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "#     e_loss = 0\n",
    "#     pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "#     for start in pbar:\n",
    "#         ind = e_indices[start:start+batch_size]\n",
    "#         e_loss += fore_model.train_on_batch([ip[ind] for ip in fore_train_ip], fore_train_op[ind])\n",
    "#         pbar.set_description('%f'%(e_loss/(start+1)))\n",
    "#     # val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "#     # val_losses.append(val_loss)\n",
    "#     # print ('Epoch', e, 'loss', e_loss*batch_size/samples_per_epoch, 'val loss', val_loss)\n",
    "#     print ('Epoch', e, 'loss', e_loss*batch_size/samples_per_epoch)\n",
    "#     train_losses.append(e_loss*batch_size/samples_per_epoch)\n",
    "#     fore_model.save_weights(fore_savepath)\n",
    "#     # # model should be saved here after each epoch in case of unexpected disconnection\n",
    "#     # if val_loss < best_val_loss:\n",
    "#     #     best_val_loss = val_loss\n",
    "#     #     fore_model.save_weights(fore_savepath)\n",
    "#     #     best_epoch = e\n",
    "#     # if (e-best_epoch)>patience:\n",
    "#     #     break\n",
    "#     print(train_losses)\n",
    "\n",
    "    \n",
    "# # val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "# # print(f'validation loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_losses = [9.6726073936373,\n",
    "#  7.827818336114287,\n",
    "#  7.339528672397137,\n",
    "#  7.14841083496809,\n",
    "#  6.650257249735295,\n",
    "#  6.71930052049458,\n",
    "#  6.3753932047262785,\n",
    "#  6.246122511550784,\n",
    "#  6.383257875964046,\n",
    "#  6.14440975420177,\n",
    "#  6.1410007086768745,\n",
    "#  5.9775916450470685,\n",
    "#  5.9476286797598,\n",
    "#  6.023135863617062,\n",
    "#  5.962186483182013,\n",
    "#  5.85297311808914,\n",
    "#  5.768680865727365,\n",
    "#  5.801690417081118,\n",
    "#  5.801871319301426,\n",
    "#  5.561956452168524,\n",
    "#  5.708363916277886,\n",
    "#  5.792748096622526,\n",
    "#  5.7496581207588315,\n",
    "#  5.439435611739754,\n",
    "#  5.584537696801126,\n",
    "#  5.704166349992156,\n",
    "#  5.440190438069403,\n",
    "#  5.513703255839646,\n",
    "#  5.608548376485706,\n",
    "#  5.677496524602175,\n",
    "#  5.360032863207161,\n",
    "#  5.6003397961705925,\n",
    "#  5.352133833542466,\n",
    "#  5.418496854007244,\n",
    "#  5.611297566629946,\n",
    "#  5.386051201373339,\n",
    "#  5.472518955282867,\n",
    "#  5.562354943752289,\n",
    "#  5.387425537928939,\n",
    "#  5.473685835413635,\n",
    "#  5.40586627010256,\n",
    "#  5.478820224441588,\n",
    "#  5.492045880965889,\n",
    "#  5.6129028406366706,\n",
    "#  5.312044258899987,\n",
    "#  5.362207580134273,\n",
    "#  5.408285063430667,\n",
    "#  5.408482057116926,\n",
    "#  5.348271051608026,\n",
    "#  5.3705539362505075,\n",
    "#  5.359316195063293,\n",
    "#  5.4364967308565975,\n",
    "#  5.388157960027456,\n",
    "#  5.397286337986588,\n",
    "#  5.3096947432309385,\n",
    "#  5.544507872723043,\n",
    "#  5.372893713116646,\n",
    "#  5.236083977781236,\n",
    "#  5.232814045846462,\n",
    "#  5.388364875204861,\n",
    "#  5.285311912223697,\n",
    "#  5.390774428062141,\n",
    "#  5.12165357824415,\n",
    "#  5.389126623794437,\n",
    "#  5.371281063705683,\n",
    "#  5.263771855421364]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr, batch_size, samples_per_epoch, patience = 0.0005, 32, 102400, 5\n",
    "# # lr, batch_size, samples_per_epoch, patience = 0.0005, 1, 1024, 5\n",
    "# d, N, he, dropout = 50, 2, 4, 0.2\n",
    "# model, fore_model =  build_strats(D, fore_max_len, V, d, N, he, dropout, forecast=True)\n",
    "# print (fore_model.summary())\n",
    "\n",
    "\n",
    "# # Pretrain fore_model.\n",
    "# best_val_loss = np.inf\n",
    "# N_fore = len(fore_train_op)\n",
    "\n",
    "# # save losses for visualization\n",
    "# # val_losses = []\n",
    "\n",
    "# # for e in range(1000):\n",
    "# #     e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "# #     e_loss = 0\n",
    "# #     pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "# #     for start in pbar:\n",
    "# #         ind = e_indices[start:start+batch_size]\n",
    "# #         e_loss += fore_model.train_on_batch([ip[ind] for ip in fore_train_ip], fore_train_op[ind])\n",
    "# #         pbar.set_description('%f'%(e_loss/(start+1)))\n",
    "# #     val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "# #     val_losses.append(val_loss)\n",
    "# #     print ('Epoch', e, 'loss', e_loss*batch_size/samples_per_epoch, 'val loss', val_loss)\n",
    "# #     train_losses.append(e_loss*batch_size/samples_per_epoch)\n",
    "# #     # model should be saved here after each epoch in case of unexpected disconnection\n",
    "# #     if val_loss < best_val_loss:\n",
    "# #         best_val_loss = val_loss\n",
    "# #         fore_model.save_weights(fore_savepath)\n",
    "# #         best_epoch = e\n",
    "# #     if (e-best_epoch)>patience:\n",
    "# #         break\n",
    "\n",
    "# for e in range(100):\n",
    "\n",
    "#     fore_loadpath = 'hierar/models/forecasting/forecasting_'+str(e+66)+'_epochs.h5'\n",
    "#     fore_savepath = 'hierar/models/forecasting/forecasting_'+str(e+66+1)+'_epochs.h5'\n",
    "    \n",
    "#     fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "#     fore_model.load_weights(fore_loadpath)\n",
    "\n",
    "#     e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "#     e_loss = 0\n",
    "#     pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "#     for start in pbar:\n",
    "#         ind = e_indices[start:start+batch_size]\n",
    "#         e_loss += fore_model.train_on_batch([ip[ind] for ip in fore_train_ip], fore_train_op[ind])\n",
    "#         pbar.set_description('%f'%(e_loss/(start+1)))\n",
    "#     # val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "#     # val_losses.append(val_loss)\n",
    "#     # print ('Epoch', e, 'loss', e_loss*batch_size/samples_per_epoch, 'val loss', val_loss)\n",
    "#     print ('Epoch', e+66, 'loss', e_loss*batch_size/samples_per_epoch)\n",
    "#     train_losses.append(e_loss*batch_size/samples_per_epoch)\n",
    "#     fore_model.save_weights(fore_savepath)\n",
    "#     # # model should be saved here after each epoch in case of unexpected disconnection\n",
    "#     # if val_loss < best_val_loss:\n",
    "#     #     best_val_loss = val_loss\n",
    "#     #     fore_model.save_weights(fore_savepath)\n",
    "#     #     best_epoch = e\n",
    "#     # if (e-best_epoch)>patience:\n",
    "#     #     break\n",
    "#     print(train_losses)\n",
    "\n",
    "    \n",
    "# # val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "# # print(f'validation loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_losses = [9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lr, batch_size, samples_per_epoch, patience = 0.0005, 32, 102400, 5\n",
    "# # lr, batch_size, samples_per_epoch, patience = 0.0005, 1, 1024, 5\n",
    "# d, N, he, dropout = 50, 2, 4, 0.2\n",
    "# model, fore_model =  build_strats(D, fore_max_len, V, d, N, he, dropout, forecast=True)\n",
    "# print (fore_model.summary())\n",
    "\n",
    "\n",
    "# # Pretrain fore_model.\n",
    "# best_val_loss = np.inf\n",
    "# N_fore = len(fore_train_op)\n",
    "\n",
    "# # save losses for visualization\n",
    "# # val_losses = []\n",
    "\n",
    "# # for e in range(1000):\n",
    "# #     e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "# #     e_loss = 0\n",
    "# #     pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "# #     for start in pbar:\n",
    "# #         ind = e_indices[start:start+batch_size]\n",
    "# #         e_loss += fore_model.train_on_batch([ip[ind] for ip in fore_train_ip], fore_train_op[ind])\n",
    "# #         pbar.set_description('%f'%(e_loss/(start+1)))\n",
    "# #     val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "# #     val_losses.append(val_loss)\n",
    "# #     print ('Epoch', e, 'loss', e_loss*batch_size/samples_per_epoch, 'val loss', val_loss)\n",
    "# #     train_losses.append(e_loss*batch_size/samples_per_epoch)\n",
    "# #     # model should be saved here after each epoch in case of unexpected disconnection\n",
    "# #     if val_loss < best_val_loss:\n",
    "# #         best_val_loss = val_loss\n",
    "# #         fore_model.save_weights(fore_savepath)\n",
    "# #         best_epoch = e\n",
    "# #     if (e-best_epoch)>patience:\n",
    "# #         break\n",
    "\n",
    "# for e in range(100):\n",
    "\n",
    "#     fore_loadpath = 'hierar/models/forecasting/forecasting_'+str(e+121)+'_epochs.h5'\n",
    "#     fore_savepath = 'hierar/models/forecasting/forecasting_'+str(e+121+1)+'_epochs.h5'\n",
    "    \n",
    "#     fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "#     fore_model.load_weights(fore_loadpath)\n",
    "\n",
    "#     e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "#     e_loss = 0\n",
    "#     pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "#     for start in pbar:\n",
    "#         ind = e_indices[start:start+batch_size]\n",
    "#         e_loss += fore_model.train_on_batch([ip[ind] for ip in fore_train_ip], fore_train_op[ind])\n",
    "#         pbar.set_description('%f'%(e_loss/(start+1)))\n",
    "#     # val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "#     # val_losses.append(val_loss)\n",
    "#     # print ('Epoch', e, 'loss', e_loss*batch_size/samples_per_epoch, 'val loss', val_loss)\n",
    "#     print ('Epoch', e+66, 'loss', e_loss*batch_size/samples_per_epoch)\n",
    "#     train_losses.append(e_loss*batch_size/samples_per_epoch)\n",
    "#     fore_model.save_weights(fore_savepath)\n",
    "#     # # model should be saved here after each epoch in case of unexpected disconnection\n",
    "#     # if val_loss < best_val_loss:\n",
    "#     #     best_val_loss = val_loss\n",
    "#     #     fore_model.save_weights(fore_savepath)\n",
    "#     #     best_epoch = e\n",
    "#     # if (e-best_epoch)>patience:\n",
    "#     #     break\n",
    "#     print(train_losses)\n",
    "\n",
    "    \n",
    "# # val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "# # print(f'validation loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = [9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 38400)]      0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 880)]        0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 880)]        0           []                               \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 880)]        0           []                               \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 50, 768)      0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " cve (CVE)                      (None, 50, 768)      5390        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 880, 50)      6750        ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " cve_1 (CVE)                    (None, 880, 50)      364         ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " cve_2 (CVE)                    (None, 880, 50)      364         ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 50)           1920050     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 50, 768)      0           ['lambda[0][0]',                 \n",
      "                                                                  'cve[0][0]']                    \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 50)           0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 880, 50)      0           ['embedding[0][0]',              \n",
      "                                                                  'cve_1[0][0]',                  \n",
      "                                                                  'cve_2[0][0]',                  \n",
      "                                                                  'dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 880)          0           ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " transformer (Transformer)      (None, 50, 768)      9441800     ['add[0][0]',                    \n",
      "                                                                  'lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " transformer_1 (Transformer)    (None, 880, 50)      39508       ['add_1[0][0]',                  \n",
      "                                                                  'lambda_3[0][0]']               \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 50, 1)        77000       ['transformer[0][0]',            \n",
      "                                                                  'lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " attention_1 (Attention)        (None, 880, 1)       5200        ['transformer_1[0][0]',          \n",
      "                                                                  'lambda_3[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 768)          0           ['transformer[0][0]',            \n",
      "                                                                  'attention[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 100)          300         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, 50)           0           ['transformer_1[0][0]',          \n",
      "                                                                  'attention_1[0][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 100)          76900       ['lambda_2[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 50)           5050        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 200)          0           ['lambda_4[0][0]',               \n",
      "                                                                  'dense_3[0][0]',                \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 134)          26934       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,605,610\n",
      "Trainable params: 11,605,610\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.159728: 100%|██████████| 3200/3200 [04:12<00:00, 12.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 loss 5.109742404706776\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.161364: 100%|██████████| 3200/3200 [04:00<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 loss 5.162085954248905\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.154937: 100%|██████████| 3200/3200 [04:00<00:00, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 loss 4.956474395804107\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.161048: 100%|██████████| 3200/3200 [03:54<00:00, 13.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 loss 5.151966934166849\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.165613: 100%|██████████| 3200/3200 [03:53<00:00, 13.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 loss 5.298011938072741\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.164953: 100%|██████████| 3200/3200 [03:53<00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 loss 5.2769091617316\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.160662: 100%|██████████| 3200/3200 [03:53<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 loss 5.139627133905887\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.158960: 100%|██████████| 3200/3200 [03:52<00:00, 13.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 loss 5.085182873085142\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.161949: 100%|██████████| 3200/3200 [03:53<00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 loss 5.180812531858683\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.166379: 100%|██████████| 3200/3200 [03:52<00:00, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 loss 5.322513702511787\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.156489: 100%|██████████| 3200/3200 [03:53<00:00, 13.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 loss 5.0061469754949215\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.158466: 100%|██████████| 3200/3200 [03:54<00:00, 13.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 loss 5.069373594857752\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.156835: 100%|██████████| 3200/3200 [03:52<00:00, 13.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 loss 5.017210310138762\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.159555: 100%|██████████| 3200/3200 [03:52<00:00, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 loss 5.104229423068464\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.164743: 100%|██████████| 3200/3200 [03:52<00:00, 13.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 loss 5.27019073240459\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.161474: 100%|██████████| 3200/3200 [03:50<00:00, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 loss 5.165618509575725\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.158929: 100%|██████████| 3200/3200 [03:49<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 loss 5.084191198311746\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.159720: 100%|██████████| 3200/3200 [03:51<00:00, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 loss 5.10948396999389\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.161474: 100%|██████████| 3200/3200 [03:51<00:00, 13.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 loss 5.165602688938379\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.164245: 100%|██████████| 3200/3200 [03:51<00:00, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 loss 5.254258686006069\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.164520: 100%|██████████| 3200/3200 [03:55<00:00, 13.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 loss 5.263038488291204\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069, 5.263038488291204]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.160468: 100%|██████████| 3200/3200 [03:52<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 loss 5.133429842889309\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069, 5.263038488291204, 5.133429842889309]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.165502: 100%|██████████| 3200/3200 [03:58<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 loss 5.294457230269909\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069, 5.263038488291204, 5.133429842889309, 5.294457230269909]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.161123: 100%|██████████| 3200/3200 [03:55<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 loss 5.154379370212555\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069, 5.263038488291204, 5.133429842889309, 5.294457230269909, 5.154379370212555]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.162131: 100%|██████████| 3200/3200 [03:53<00:00, 13.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 loss 5.186611767858267\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069, 5.263038488291204, 5.133429842889309, 5.294457230269909, 5.154379370212555, 5.186611767858267]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.166852: 100%|██████████| 3200/3200 [03:51<00:00, 13.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 loss 5.337653120085597\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069, 5.263038488291204, 5.133429842889309, 5.294457230269909, 5.154379370212555, 5.186611767858267, 5.337653120085597]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.161870: 100%|██████████| 3200/3200 [03:54<00:00, 13.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 loss 5.178275236412883\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069, 5.263038488291204, 5.133429842889309, 5.294457230269909, 5.154379370212555, 5.186611767858267, 5.337653120085597, 5.178275236412883]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.163068: 100%|██████████| 3200/3200 [03:50<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 loss 5.216593872718513\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069, 5.263038488291204, 5.133429842889309, 5.294457230269909, 5.154379370212555, 5.186611767858267, 5.337653120085597, 5.178275236412883, 5.216593872718513]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.161730: 100%|██████████| 3200/3200 [03:53<00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 loss 5.173797446973622\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069, 5.263038488291204, 5.133429842889309, 5.294457230269909, 5.154379370212555, 5.186611767858267, 5.337653120085597, 5.178275236412883, 5.216593872718513, 5.173797446973622]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.160032: 100%|██████████| 3200/3200 [05:47<00:00,  9.20it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 loss 5.11946918297559\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069, 5.263038488291204, 5.133429842889309, 5.294457230269909, 5.154379370212555, 5.186611767858267, 5.337653120085597, 5.178275236412883, 5.216593872718513, 5.173797446973622, 5.11946918297559]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.161638: 100%|██████████| 3200/3200 [04:08<00:00, 12.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 loss 5.1708628893271085\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069, 5.263038488291204, 5.133429842889309, 5.294457230269909, 5.154379370212555, 5.186611767858267, 5.337653120085597, 5.178275236412883, 5.216593872718513, 5.173797446973622, 5.11946918297559, 5.1708628893271085]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.161907: 100%|██████████| 3200/3200 [04:00<00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 loss 5.179464494660497\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069, 5.263038488291204, 5.133429842889309, 5.294457230269909, 5.154379370212555, 5.186611767858267, 5.337653120085597, 5.178275236412883, 5.216593872718513, 5.173797446973622, 5.11946918297559, 5.1708628893271085, 5.179464494660497]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.166057: 100%|██████████| 3200/3200 [03:57<00:00, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 loss 5.312201052866876\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069, 5.263038488291204, 5.133429842889309, 5.294457230269909, 5.154379370212555, 5.186611767858267, 5.337653120085597, 5.178275236412883, 5.216593872718513, 5.173797446973622, 5.11946918297559, 5.1708628893271085, 5.179464494660497, 5.312201052866876]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.161488: 100%|██████████| 3200/3200 [03:54<00:00, 13.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 loss 5.166050132624805\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069, 5.263038488291204, 5.133429842889309, 5.294457230269909, 5.154379370212555, 5.186611767858267, 5.337653120085597, 5.178275236412883, 5.216593872718513, 5.173797446973622, 5.11946918297559, 5.1708628893271085, 5.179464494660497, 5.312201052866876, 5.166050132624805]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.164451: 100%|██████████| 3200/3200 [03:55<00:00, 13.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 loss 5.260845541916788\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069, 5.263038488291204, 5.133429842889309, 5.294457230269909, 5.154379370212555, 5.186611767858267, 5.337653120085597, 5.178275236412883, 5.216593872718513, 5.173797446973622, 5.11946918297559, 5.1708628893271085, 5.179464494660497, 5.312201052866876, 5.166050132624805, 5.260845541916788]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.160913: 100%|██████████| 3200/3200 [03:54<00:00, 13.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101 loss 5.147645687051117\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069, 5.263038488291204, 5.133429842889309, 5.294457230269909, 5.154379370212555, 5.186611767858267, 5.337653120085597, 5.178275236412883, 5.216593872718513, 5.173797446973622, 5.11946918297559, 5.1708628893271085, 5.179464494660497, 5.312201052866876, 5.166050132624805, 5.260845541916788, 5.147645687051117]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.159618: 100%|██████████| 3200/3200 [03:53<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 loss 5.106238405890763\n",
      "[9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069, 5.263038488291204, 5.133429842889309, 5.294457230269909, 5.154379370212555, 5.186611767858267, 5.337653120085597, 5.178275236412883, 5.216593872718513, 5.173797446973622, 5.11946918297559, 5.1708628893271085, 5.179464494660497, 5.312201052866876, 5.166050132624805, 5.260845541916788, 5.147645687051117, 5.106238405890763]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.157883:  48%|████▊     | 1547/3200 [01:59<01:52, 14.70it/s]"
     ]
    }
   ],
   "source": [
    "lr, batch_size, samples_per_epoch, patience = 0.0005, 32, 102400, 5\n",
    "# lr, batch_size, samples_per_epoch, patience = 0.0005, 1, 1024, 5\n",
    "d, N, he, dropout = 50, 2, 4, 0.2\n",
    "model, fore_model =  build_strats(D, fore_max_len, V, d, N, he, dropout, forecast=True)\n",
    "print (fore_model.summary())\n",
    "\n",
    "\n",
    "# Pretrain fore_model.\n",
    "best_val_loss = np.inf\n",
    "N_fore = len(fore_train_op)\n",
    "\n",
    "# save losses for visualization\n",
    "# val_losses = []\n",
    "\n",
    "# for e in range(1000):\n",
    "#     e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "#     e_loss = 0\n",
    "#     pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "#     for start in pbar:\n",
    "#         ind = e_indices[start:start+batch_size]\n",
    "#         e_loss += fore_model.train_on_batch([ip[ind] for ip in fore_train_ip], fore_train_op[ind])\n",
    "#         pbar.set_description('%f'%(e_loss/(start+1)))\n",
    "#     val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "#     val_losses.append(val_loss)\n",
    "#     print ('Epoch', e, 'loss', e_loss*batch_size/samples_per_epoch, 'val loss', val_loss)\n",
    "#     train_losses.append(e_loss*batch_size/samples_per_epoch)\n",
    "#     # model should be saved here after each epoch in case of unexpected disconnection\n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         fore_model.save_weights(fore_savepath)\n",
    "#         best_epoch = e\n",
    "#     if (e-best_epoch)>patience:\n",
    "#         break\n",
    "\n",
    "for e in range(100):\n",
    "\n",
    "    fore_loadpath = 'hierar/models/forecasting/forecasting_'+str(e+127)+'_epochs.h5'\n",
    "    fore_savepath = 'hierar/models/forecasting/forecasting_'+str(e+127+1)+'_epochs.h5'\n",
    "    \n",
    "    fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "    fore_model.load_weights(fore_loadpath)\n",
    "\n",
    "    e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "    e_loss = 0\n",
    "    pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "    for start in pbar:\n",
    "        ind = e_indices[start:start+batch_size]\n",
    "        e_loss += fore_model.train_on_batch([ip[ind] for ip in fore_train_ip], fore_train_op[ind])\n",
    "        pbar.set_description('%f'%(e_loss/(start+1)))\n",
    "    # val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "    # val_losses.append(val_loss)\n",
    "    # print ('Epoch', e, 'loss', e_loss*batch_size/samples_per_epoch, 'val loss', val_loss)\n",
    "    print ('Epoch', e+66, 'loss', e_loss*batch_size/samples_per_epoch)\n",
    "    train_losses.append(e_loss*batch_size/samples_per_epoch)\n",
    "    fore_model.save_weights(fore_savepath)\n",
    "    # # model should be saved here after each epoch in case of unexpected disconnection\n",
    "    # if val_loss < best_val_loss:\n",
    "    #     best_val_loss = val_loss\n",
    "    #     fore_model.save_weights(fore_savepath)\n",
    "    #     best_epoch = e\n",
    "    # if (e-best_epoch)>patience:\n",
    "    #     break\n",
    "    print(train_losses)\n",
    "\n",
    "    \n",
    "# val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "# print(f'validation loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([9.6726073936373, 7.827818336114287, 7.339528672397137, 7.14841083496809, 6.650257249735295, 6.71930052049458, 6.3753932047262785, 6.246122511550784, 6.383257875964046, 6.14440975420177, 6.1410007086768745, 5.9775916450470685, 5.9476286797598, 6.023135863617062, 5.962186483182013, 5.85297311808914, 5.768680865727365, 5.801690417081118, 5.801871319301426, 5.561956452168524, 5.708363916277886, 5.792748096622526, 5.7496581207588315, 5.439435611739754, 5.584537696801126, 5.704166349992156, 5.440190438069403, 5.513703255839646, 5.608548376485706, 5.677496524602175, 5.360032863207161, 5.6003397961705925, 5.352133833542466, 5.418496854007244, 5.611297566629946, 5.386051201373339, 5.472518955282867, 5.562354943752289, 5.387425537928939, 5.473685835413635, 5.40586627010256, 5.478820224441588, 5.492045880965889, 5.6129028406366706, 5.312044258899987, 5.362207580134273, 5.408285063430667, 5.408482057116926, 5.348271051608026, 5.3705539362505075, 5.359316195063293, 5.4364967308565975, 5.388157960027456, 5.397286337986588, 5.3096947432309385, 5.544507872723043, 5.372893713116646, 5.236083977781236, 5.232814045846462, 5.388364875204861, 5.285311912223697, 5.390774428062141, 5.12165357824415, 5.389126623794437, 5.371281063705683, 5.263771855421364, 5.23746578168124, 5.416688159443438, 5.205470519624651, 5.297770969420672, 5.294283067695797, 5.591666744612158, 5.133070289082825, 5.315817803628743, 5.261407737210393, 5.284937768243253, 5.29699768114835, 5.132637087032199, 5.35254779919982, 5.23261724255979, 5.149450082182884, 5.167635361738503, 5.311890206597745, 5.282972572669387, 5.1295755824819205, 5.075229794420302, 5.2687539759278295, 5.233767274618149, 5.200219418369233, 5.249976786412299, 5.303496397100389, 5.187022073045373, 5.205709896497428, 5.231979852579534, 5.264038751870394, 5.181498194336891, 5.148470848277211, 5.304017275571823, 5.230564057789743, 5.12524469319731, 5.221126203387976, 5.1808790271729235, 5.086285249628126, 5.1751138539239765, 5.151869556121528, 5.214914522059262, 5.275770538896322, 5.072343826666474, 5.187715657204389, 5.208328050747514, 5.273546916656196, 5.181960097290576, 5.268980304412544, 5.200946623757481, 5.225574138015508, 5.215654050521553, 5.1830766187980775, 5.251943679004907, 5.327554960735142, 5.2131019575148825, 5.169291452169419, 5.136195200160146, 5.244120051041246, 5.070332445763052, 5.19596264667809, 5.064282140806317, 5.349931869506836, 5.109742404706776, 5.162085954248905, 4.956474395804107, 5.151966934166849, 5.298011938072741, 5.2769091617316, 5.139627133905887, 5.085182873085142, 5.180812531858683, 5.322513702511787, 5.0061469754949215, 5.069373594857752, 5.017210310138762, 5.104229423068464, 5.27019073240459, 5.165618509575725, 5.084191198311746, 5.10948396999389, 5.165602688938379, 5.254258686006069, 5.263038488291204, 5.133429842889309, 5.294457230269909, 5.154379370212555, 5.186611767858267, 5.337653120085597, 5.178275236412883, 5.216593872718513, 5.173797446973622, 5.11946918297559, 5.1708628893271085, 5.179464494660497, 5.312201052866876, 5.166050132624805, 5.260845541916788, 5.147645687051117, 5.106238405890763])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
