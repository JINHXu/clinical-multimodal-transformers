{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! export TF_CPP_MIN_LOG_LEVEL=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECKAJiLXiTlN"
   },
   "source": [
    "## Hardware check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "e7odgm5VsOsb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 15 14:58:33 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000000:3A:00.0 Off |                    0 |\n",
      "| N/A   34C    P0              39W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-32GB           On  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   36C    P0              39W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2-32GB           On  | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   35C    P0              39W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2-32GB           On  | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   36C    P0              40W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2480      G   /usr/libexec/Xorg                             8MiB |\n",
      "|    1   N/A  N/A      2480      G   /usr/libexec/Xorg                             8MiB |\n",
      "|    2   N/A  N/A      2480      G   /usr/libexec/Xorg                             8MiB |\n",
      "|    3   N/A  N/A      2480      G   /usr/libexec/Xorg                             8MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# gpu check\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oEEUeIW3sOsc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of cores\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count() \n",
    "cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY9I5eXWeOom"
   },
   "source": [
    "## Environment Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis\n"
     ]
    }
   ],
   "source": [
    "cd /pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RpTg0QzPqqKv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Lambda\n",
    "# from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "import pandas as pd\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, pipeline, AutoModel\n",
    "import resources.smart_cond as sc\n",
    "import gc\n",
    "# from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AeG1PfTVsOsd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf. __version__)\n",
    "\n",
    "pickle.format_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfKWDkwoeSGU"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = 'Data/sepsis_removed_0.pkl'\n",
    "pkl = pickle.load(open(data_path, 'rb'))\n",
    "data = pkl[0]\n",
    "oc = pkl[1]\n",
    "train_ind = pkl[2]\n",
    "valid_ind = pkl[3]\n",
    "test_ind = pkl[4]\n",
    "del pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_ind</th>\n",
       "      <th>hour</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>TABLE</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10223</td>\n",
       "      <td>467.816667</td>\n",
       "      <td>Text</td>\n",
       "      <td>Admission Date:  [**2119-5-4**]              D...</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18407</td>\n",
       "      <td>28.016667</td>\n",
       "      <td>Text</td>\n",
       "      <td>Admission Date:  [**2112-12-8**]              ...</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40300</td>\n",
       "      <td>155.166667</td>\n",
       "      <td>Text</td>\n",
       "      <td>Admission Date:  [**2194-7-18**]              ...</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23747</td>\n",
       "      <td>52.383333</td>\n",
       "      <td>Text</td>\n",
       "      <td>Admission Date:  [**2194-1-7**]              D...</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2357</td>\n",
       "      <td>73.133333</td>\n",
       "      <td>Text</td>\n",
       "      <td>Admission Date:  [**2186-6-7**]     Discharge ...</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886223</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>MBP</td>\n",
       "      <td>0.195381</td>\n",
       "      <td>chart</td>\n",
       "      <td>78.552377</td>\n",
       "      <td>17.645628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886224</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>O2 Saturation</td>\n",
       "      <td>-0.678068</td>\n",
       "      <td>chart</td>\n",
       "      <td>96.820961</td>\n",
       "      <td>4.160290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886225</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>RR</td>\n",
       "      <td>0.179866</td>\n",
       "      <td>chart</td>\n",
       "      <td>26.278501</td>\n",
       "      <td>15.130729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886226</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>SBP</td>\n",
       "      <td>-0.404061</td>\n",
       "      <td>chart</td>\n",
       "      <td>120.239648</td>\n",
       "      <td>25.341836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886227</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>Urine</td>\n",
       "      <td>-0.24296</td>\n",
       "      <td>output</td>\n",
       "      <td>123.393012</td>\n",
       "      <td>137.442433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82447326 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ts_ind        hour       variable  \\\n",
       "0          10223  467.816667           Text   \n",
       "1          18407   28.016667           Text   \n",
       "2          40300  155.166667           Text   \n",
       "3          23747   52.383333           Text   \n",
       "4           2357   73.133333           Text   \n",
       "...          ...         ...            ...   \n",
       "82886223   57281   20.400000            MBP   \n",
       "82886224   57281   20.400000  O2 Saturation   \n",
       "82886225   57281   20.400000             RR   \n",
       "82886226   57281   20.400000            SBP   \n",
       "82886227   57281   20.400000          Urine   \n",
       "\n",
       "                                                      value       TABLE  \\\n",
       "0         Admission Date:  [**2119-5-4**]              D...  noteevents   \n",
       "1         Admission Date:  [**2112-12-8**]              ...  noteevents   \n",
       "2         Admission Date:  [**2194-7-18**]              ...  noteevents   \n",
       "3         Admission Date:  [**2194-1-7**]              D...  noteevents   \n",
       "4         Admission Date:  [**2186-6-7**]     Discharge ...  noteevents   \n",
       "...                                                     ...         ...   \n",
       "82886223                                           0.195381       chart   \n",
       "82886224                                          -0.678068       chart   \n",
       "82886225                                           0.179866       chart   \n",
       "82886226                                          -0.404061       chart   \n",
       "82886227                                           -0.24296      output   \n",
       "\n",
       "                mean         std  \n",
       "0           1.000000    1.000000  \n",
       "1           1.000000    1.000000  \n",
       "2           1.000000    1.000000  \n",
       "3           1.000000    1.000000  \n",
       "4           1.000000    1.000000  \n",
       "...              ...         ...  \n",
       "82886223   78.552377   17.645628  \n",
       "82886224   96.820961    4.160290  \n",
       "82886225   26.278501   15.130729  \n",
       "82886226  120.239648   25.341836  \n",
       "82886227  123.393012  137.442433  \n",
       "\n",
       "[82447326 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_ind</th>\n",
       "      <th>hour</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>TABLE</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10223</td>\n",
       "      <td>467.816667</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18407</td>\n",
       "      <td>28.016667</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40300</td>\n",
       "      <td>155.166667</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23747</td>\n",
       "      <td>52.383333</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2357</td>\n",
       "      <td>73.133333</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886223</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>MBP</td>\n",
       "      <td>0.195381</td>\n",
       "      <td>chart</td>\n",
       "      <td>78.552377</td>\n",
       "      <td>17.645628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886224</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>O2 Saturation</td>\n",
       "      <td>-0.678068</td>\n",
       "      <td>chart</td>\n",
       "      <td>96.820961</td>\n",
       "      <td>4.160290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886225</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>RR</td>\n",
       "      <td>0.179866</td>\n",
       "      <td>chart</td>\n",
       "      <td>26.278501</td>\n",
       "      <td>15.130729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886226</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>SBP</td>\n",
       "      <td>-0.404061</td>\n",
       "      <td>chart</td>\n",
       "      <td>120.239648</td>\n",
       "      <td>25.341836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886227</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>Urine</td>\n",
       "      <td>-0.24296</td>\n",
       "      <td>output</td>\n",
       "      <td>123.393012</td>\n",
       "      <td>137.442433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82447326 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ts_ind        hour       variable     value       TABLE        mean  \\\n",
       "0          10223  467.816667           Text         1  noteevents    1.000000   \n",
       "1          18407   28.016667           Text         1  noteevents    1.000000   \n",
       "2          40300  155.166667           Text         1  noteevents    1.000000   \n",
       "3          23747   52.383333           Text         1  noteevents    1.000000   \n",
       "4           2357   73.133333           Text         1  noteevents    1.000000   \n",
       "...          ...         ...            ...       ...         ...         ...   \n",
       "82886223   57281   20.400000            MBP  0.195381       chart   78.552377   \n",
       "82886224   57281   20.400000  O2 Saturation -0.678068       chart   96.820961   \n",
       "82886225   57281   20.400000             RR  0.179866       chart   26.278501   \n",
       "82886226   57281   20.400000            SBP -0.404061       chart  120.239648   \n",
       "82886227   57281   20.400000          Urine  -0.24296      output  123.393012   \n",
       "\n",
       "                 std  \n",
       "0           1.000000  \n",
       "1           1.000000  \n",
       "2           1.000000  \n",
       "3           1.000000  \n",
       "4           1.000000  \n",
       "...              ...  \n",
       "82886223   17.645628  \n",
       "82886224    4.160290  \n",
       "82886225   15.130729  \n",
       "82886226   25.341836  \n",
       "82886227  137.442433  \n",
       "\n",
       "[82447326 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['variable'] == 'Text', 'value'] = 1\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_window = 2 # hours\n",
    "obs_windows = range(20, 124, 4)\n",
    "# Remove test patients.\n",
    "data = data.merge(oc[['ts_ind', 'SUBJECT_ID']], on='ts_ind', how='left')\n",
    "test_sub = oc.loc[oc.ts_ind.isin(test_ind)].SUBJECT_ID.unique()\n",
    "data = data.loc[~data.SUBJECT_ID.isin(test_sub)]\n",
    "oc = oc.loc[~oc.SUBJECT_ID.isin(test_sub)]\n",
    "data.drop(columns=['SUBJECT_ID', 'TABLE'], inplace=True)\n",
    "# Fix age.\n",
    "data.loc[(data.variable=='Age')&(data.value>200), 'value'] = 91.4\n",
    "# data[data.variable=='Age'][data.value>200]['value'] = 91.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91626it [00:00, 811607.04it/s]\n",
      "100%|██████████| 26/26 [04:57<00:00, 11.46s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get static data with mean fill and missingness indicator.\n",
    "static_varis = ['Age', 'Gender']\n",
    "ii = data.variable.isin(static_varis)\n",
    "static_data = data.loc[ii]\n",
    "data = data.loc[~ii]\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "static_var_to_ind = inv_list(static_varis)\n",
    "D = len(static_varis)\n",
    "N = data.ts_ind.max()+1\n",
    "demo = np.zeros((N, D))\n",
    "for row in tqdm(static_data.itertuples()):\n",
    "    demo[row.ts_ind, static_var_to_ind[row.variable]] = row.value\n",
    "# Normalize static data.\n",
    "means = demo.mean(axis=0, keepdims=True)\n",
    "stds = demo.std(axis=0, keepdims=True)\n",
    "stds = (stds==0)*1 + (stds!=0)*stds\n",
    "demo = (demo-means)/stds\n",
    "# Get variable indices.\n",
    "varis = sorted(list(set(data.variable)))\n",
    "V = len(varis)\n",
    "var_to_ind = inv_list(varis, start=1)\n",
    "data['vind'] = data.variable.map(var_to_ind)\n",
    "data = data[['ts_ind', 'vind', 'hour', 'value']].sort_values(by=['ts_ind', 'vind', 'hour'])\n",
    "# Find max_len.\n",
    "fore_max_len = 880\n",
    "# Get forecast inputs and outputs.\n",
    "fore_times_ip = []\n",
    "fore_values_ip = []\n",
    "fore_varis_ip = []\n",
    "fore_op = []\n",
    "fore_inds = []\n",
    "def f(x):\n",
    "    mask = [0 for i in range(V)]\n",
    "    values = [0 for i in range(V)]\n",
    "    for vv in x:\n",
    "        v = int(vv[0])-1\n",
    "        mask[v] = 1\n",
    "        values[v] = vv[1]\n",
    "    return values+mask\n",
    "def pad(x):\n",
    "    return x+[0]*(fore_max_len-len(x))\n",
    "for w in tqdm(obs_windows):\n",
    "    pred_data = data.loc[(data.hour>=w)&(data.hour<=w+pred_window)]\n",
    "    pred_data = pred_data.groupby(['ts_ind', 'vind']).agg({'value':'first'}).reset_index()\n",
    "    pred_data['vind_value'] = pred_data[['vind', 'value']].values.tolist()\n",
    "    pred_data = pred_data.groupby('ts_ind').agg({'vind_value':list}).reset_index()\n",
    "    pred_data['vind_value'] = pred_data['vind_value'].apply(f)    \n",
    "    obs_data = data.loc[(data.hour<w)&(data.hour>=w-24)]\n",
    "    obs_data = obs_data.loc[obs_data.ts_ind.isin(pred_data.ts_ind)]\n",
    "    obs_data = obs_data.groupby('ts_ind').head(fore_max_len)\n",
    "    obs_data = obs_data.groupby('ts_ind').agg({'vind':list, 'hour':list, 'value':list}).reset_index()\n",
    "    obs_data = obs_data.merge(pred_data, on='ts_ind')\n",
    "    for col in ['vind', 'hour', 'value']:\n",
    "        obs_data[col] = obs_data[col].apply(pad)\n",
    "    fore_op.append(np.array(list(obs_data.vind_value)))\n",
    "    fore_inds.append(np.array(list(obs_data.ts_ind)))\n",
    "    fore_times_ip.append(np.array(list(obs_data.hour)))\n",
    "    fore_values_ip.append(np.array(list(obs_data.value)))\n",
    "    fore_varis_ip.append(np.array(list(obs_data.vind)))\n",
    "del data\n",
    "fore_times_ip = np.concatenate(fore_times_ip, axis=0)\n",
    "fore_values_ip = np.concatenate(fore_values_ip, axis=0)\n",
    "fore_varis_ip = np.concatenate(fore_varis_ip, axis=0)\n",
    "fore_op = np.concatenate(fore_op, axis=0)\n",
    "fore_inds = np.concatenate(fore_inds, axis=0)\n",
    "fore_demo = demo[fore_inds]\n",
    "# Get train and valid ts_ind for forecast task.\n",
    "# train_sub = oc.loc[oc.ts_ind.isin(train_ind)].SUBJECT_ID.unique()\n",
    "valid_sub = oc.loc[oc.ts_ind.isin(valid_ind)].SUBJECT_ID.unique()\n",
    "rem_sub = oc.loc[~oc.SUBJECT_ID.isin(np.concatenate((train_ind, valid_ind)))].SUBJECT_ID.unique()\n",
    "bp = int(0.8*len(rem_sub))\n",
    "# train_sub = np.concatenate((train_sub, rem_sub[:bp]))\n",
    "valid_sub = np.concatenate((valid_sub, rem_sub[bp:]))\n",
    "# train_ind = oc.loc[oc.SUBJECT_ID.isin(train_sub)].ts_ind.unique() # Add remaining ts_ind s of train subjects.\n",
    "valid_ind = oc.loc[oc.SUBJECT_ID.isin(valid_sub)].ts_ind.unique() # Add remaining ts_ind s of train subjects.\n",
    "# Generate 3 sets of inputs and outputs.\n",
    "# train_ind = np.argwhere(np.in1d(fore_inds, train_ind)).flatten()\n",
    "valid_ind = np.argwhere(np.in1d(fore_inds, valid_ind)).flatten()\n",
    "# fore_train_ip = [ip[train_ind] for ip in [fore_demo, fore_times_ip, fore_values_ip, fore_varis_ip]]\n",
    "fore_valid_ip = [ip[valid_ind] for ip in [fore_demo, fore_times_ip, fore_values_ip, fore_varis_ip]]\n",
    "del fore_times_ip, fore_values_ip, fore_varis_ip, demo, fore_demo\n",
    "# fore_train_op = fore_op[train_ind]\n",
    "fore_valid_op = fore_op[valid_ind]\n",
    "del fore_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add text features\n",
    "text_ip = pickle.load(open('Data/hierar/text_emb_input_train_val_1.pkl', 'rb'))\n",
    "\n",
    "# train_text_ip = text_ip[0]\n",
    "valid_text_ip = text_ip[1]\n",
    "\n",
    "# fore_train_ip.append(train_text_ip)\n",
    "fore_valid_ip.append(valid_text_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid text times\n",
    "valid_text_times = []\n",
    "valid_text_varis = []\n",
    "\n",
    "valid_times = fore_valid_ip[1]\n",
    "valid_varis = fore_valid_ip[3]\n",
    "\n",
    "for i in tqdm(range(len(fore_valid_ip[0]))):\n",
    "    times = []\n",
    "    varis = []\n",
    "    for j in range(880):\n",
    "        if valid_varis[i][j] == 124:\n",
    "            times.append(valid_times[i][j])\n",
    "            varis.append(135)\n",
    "    valid_text_times.append(np.array(times))\n",
    "    valid_text_varis.append(np.array(varis))\n",
    "\n",
    "valid_text_times = np.array(valid_text_times)\n",
    "valid_text_varis = np.array(valid_text_varis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "# padding\n",
    "padded_valid_text_times = pad_sequences(valid_text_times, maxlen=50, padding='post', dtype='float32')\n",
    "padded_valid_text_varis = pad_sequences(valid_text_varis, maxlen=50, padding='post')\n",
    "\n",
    "del valid_text_times, valid_text_varis, valid_times, valid_varis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fore_valid_ip.append(padded_valid_text_times)\n",
    "fore_valid_ip.append(padded_valid_text_varis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res(y_true, y_pred):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    minrp = np.minimum(precision, recall).max()\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    return [roc_auc, pr_auc, minrp]\n",
    "\n",
    "# ######################################################################################################## \n",
    "# ######################################################################################################## \n",
    "# class_weights = compute_class_weight(class_weight='balanced', classes=[0,1], y=train_op)\n",
    "# def mortality_loss(y_true, y_pred):\n",
    "#     sample_weights = (1-y_true)*class_weights[0] + y_true*class_weights[1]\n",
    "#     bce = K.binary_crossentropy(y_true, y_pred)\n",
    "#     return K.mean(sample_weights*bce, axis=-1)\n",
    "# ######################################################################################################## \n",
    "# ######################################################################################################## \n",
    "\n",
    "# var_weights = np.sum(fore_train_op[:, V:], axis=0)\n",
    "# var_weights[var_weights==0] = var_weights.max()\n",
    "# var_weights = var_weights.max()/var_weights\n",
    "# var_weights = var_weights.reshape((1, V))\n",
    "def forecast_loss(y_true, y_pred):\n",
    "    return K.sum(y_true[:,V:]*(y_true[:,:V]-y_pred)**2, axis=-1)\n",
    "\n",
    "def get_min_loss(weight):\n",
    "    def min_loss(y_true, y_pred):\n",
    "        return weight*y_pred\n",
    "    return min_loss\n",
    "\n",
    "class CustomCallback(Callback):\n",
    "    def __init__(self, validation_data, batch_size):\n",
    "        self.val_x, self.val_y = validation_data\n",
    "        self.batch_size = batch_size\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.val_x, verbose=0, batch_size=self.batch_size)\n",
    "        if type(y_pred)==type([]):\n",
    "            y_pred = y_pred[0]\n",
    "        precision, recall, thresholds = precision_recall_curve(self.val_y, y_pred)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        roc_auc = roc_auc_score(self.val_y, y_pred)\n",
    "        logs['custom_metric'] = pr_auc + roc_auc\n",
    "        print ('val_aucs:', pr_auc, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Embedding, Activation, Dropout, Softmax, Layer, InputSpec, Input, Dense, Lambda, TimeDistributed, Concatenate, Add\n",
    "from tensorflow.keras import initializers, regularizers, constraints, Model\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "  \n",
    "class CVE(Layer):\n",
    "    def __init__(self, hid_units, output_dim):\n",
    "        self.hid_units = hid_units\n",
    "        self.output_dim = output_dim\n",
    "        super(CVE, self).__init__()\n",
    "        \n",
    "    def build(self, input_shape): \n",
    "        self.W1 = self.add_weight(name='CVE_W1',\n",
    "                            shape=(1, self.hid_units),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        self.b1 = self.add_weight(name='CVE_b1',\n",
    "                            shape=(self.hid_units,),\n",
    "                            initializer='zeros',\n",
    "                            trainable=True)\n",
    "        self.W2 = self.add_weight(name='CVE_W2',\n",
    "                            shape=(self.hid_units, self.output_dim),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        super(CVE, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = K.expand_dims(x, axis=-1)\n",
    "        x = K.dot(K.tanh(K.bias_add(K.dot(x, self.W1), self.b1)), self.W2)\n",
    "        return x\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape + (self.output_dim,)\n",
    "    \n",
    "    \n",
    "class Attention(Layer):\n",
    "    \n",
    "    def __init__(self, hid_dim):\n",
    "        self.hid_dim = hid_dim\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        self.W = self.add_weight(shape=(d, self.hid_dim), name='Att_W',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.hid_dim,), name='Att_b',\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        self.u = self.add_weight(shape=(self.hid_dim,1), name='Att_u',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask, mask_value=-1e30):\n",
    "        attn_weights = K.dot(K.tanh(K.bias_add(K.dot(x,self.W), self.b)), self.u)\n",
    "        mask = K.expand_dims(mask, axis=-1)\n",
    "        attn_weights = mask*attn_weights + (1-mask)*mask_value\n",
    "        attn_weights = K.softmax(attn_weights, axis=-2)\n",
    "        return attn_weights\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1] + (1,)\n",
    "    \n",
    "    \n",
    "class Transformer(Layer):\n",
    "    \n",
    "    def __init__(self, N=2, h=8, dk=None, dv=None, dff=None, dropout=0):\n",
    "        self.N, self.h, self.dk, self.dv, self.dff, self.dropout = N, h, dk, dv, dff, dropout\n",
    "        self.epsilon = K.epsilon() * K.epsilon()\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        if self.dk==None:\n",
    "            self.dk = d//self.h\n",
    "        if self.dv==None:\n",
    "            self.dv = d//self.h\n",
    "        if self.dff==None:\n",
    "            self.dff = 2*d\n",
    "        self.Wq = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wq',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wk = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wk',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wv = self.add_weight(shape=(self.N, self.h, d, self.dv), name='Wv',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wo = self.add_weight(shape=(self.N, self.dv*self.h, d), name='Wo',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.W1 = self.add_weight(shape=(self.N, d, self.dff), name='W1',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b1 = self.add_weight(shape=(self.N, self.dff), name='b1',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.W2 = self.add_weight(shape=(self.N, self.dff, d), name='W2',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b2 = self.add_weight(shape=(self.N, d), name='b2',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.gamma = self.add_weight(shape=(2*self.N,), name='gamma',\n",
    "                                 initializer='ones', trainable=True)\n",
    "        self.beta = self.add_weight(shape=(2*self.N,), name='beta',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        super(Transformer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask, mask_value=-1e-30):\n",
    "        mask = K.expand_dims(mask, axis=-2)\n",
    "        for i in range(self.N):\n",
    "            # MHA\n",
    "            mha_ops = []\n",
    "            for j in range(self.h):\n",
    "                q = K.dot(x, self.Wq[i,j,:,:])\n",
    "                k = K.permute_dimensions(K.dot(x, self.Wk[i,j,:,:]), (0,2,1))\n",
    "                v = K.dot(x, self.Wv[i,j,:,:])\n",
    "                A = K.batch_dot(q,k)\n",
    "                # Mask unobserved steps.\n",
    "                A = mask*A + (1-mask)*mask_value\n",
    "                # Mask for attention dropout.\n",
    "                def dropped_A():\n",
    "                    dp_mask = K.cast((K.random_uniform(shape=array_ops.shape(A))>=self.dropout), K.floatx())\n",
    "                    return A*dp_mask + (1-dp_mask)*mask_value\n",
    "                A = sc.smart_cond(K.learning_phase(), dropped_A, lambda: array_ops.identity(A))\n",
    "                A = K.softmax(A, axis=-1)\n",
    "                mha_ops.append(K.batch_dot(A,v))\n",
    "            conc = K.concatenate(mha_ops, axis=-1)\n",
    "            proj = K.dot(conc, self.Wo[i,:,:])\n",
    "            # Dropout.\n",
    "            proj = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(proj, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(proj))\n",
    "            # Add & LN\n",
    "            x = x+proj\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i] + self.beta[2*i]\n",
    "            # FFN\n",
    "            ffn_op = K.bias_add(K.dot(K.relu(K.bias_add(K.dot(x, self.W1[i,:,:]), self.b1[i,:])), \n",
    "                           self.W2[i,:,:]), self.b2[i,:,])\n",
    "            # Dropout.\n",
    "            ffn_op = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(ffn_op, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(ffn_op))\n",
    "            # Add & LN\n",
    "            x = x+ffn_op\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i+1] + self.beta[2*i+1]            \n",
    "        return x\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "def build_strats(D, max_len, V, d, N, he, dropout, forecast=False):\n",
    "    # demo\n",
    "    demo = Input(shape=(D,))\n",
    "    demo_enc = Dense(2*d, activation='tanh')(demo)\n",
    "    demo_enc = Dense(d, activation='tanh')(demo_enc)\n",
    "    \n",
    "    ## text\n",
    "    # text\n",
    "    texts = Input(shape=(768*50,))\n",
    "    text_enc = Dense(1000, activation='relu')(texts)\n",
    "    text_enc = Dense(d, activation='relu')(text_enc)\n",
    "\n",
    "    text_2d = Lambda(lambda x: K.reshape(x, (-1, 50, 768)), input_shape=(None, 50*768))(texts)\n",
    "    \n",
    "    # Q \n",
    "    text_enc = Dense(1000, activation='relu')(texts)\n",
    "    text_d = Dense(50, activation='relu')(text_enc)\n",
    "    \n",
    "    \n",
    "    # text time\n",
    "    text_times = Input(shape=(50,))\n",
    "    cve_units = int(np.sqrt(d))\n",
    "    text_times_emb = CVE(cve_units, 768)(text_times)\n",
    "    \n",
    "    # text varis\n",
    "    text_varis = Input(shape=(50,))\n",
    "    # text_varis_emb = Embedding(1+1, d)(text_varis)\n",
    "    \n",
    "    text_comb_emb = Add()([text_2d, text_times_emb])\n",
    "    text_mask = Lambda(lambda x:K.clip(x,0,1))(text_varis)\n",
    "    # text_mask =  Lambda(lambda x: K.reshape(x, (-1, 50, 768)), input_shape=(None, 50*768))(text_varis)\n",
    "    text_cont_emb = Transformer(N, he, dk=None, dv=None, dff=None, dropout=dropout)(text_comb_emb, mask=text_mask)\n",
    "    text_attn_weights = Attention(2*d)(text_cont_emb, mask=text_mask)\n",
    "    text_fused_emb = Lambda(lambda x:K.sum(x[0]*x[1], axis=-2))([text_cont_emb, text_attn_weights])\n",
    "    \n",
    "    text_dense_0 = Dense(200, activation='relu')(text_fused_emb)\n",
    "    text_dense = Dense(50, activation='relu')(text_dense_0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## physio\n",
    "    # triplet\n",
    "    varis = Input(shape=(max_len,))\n",
    "    values = Input(shape=(max_len,))\n",
    "    times = Input(shape=(max_len,))\n",
    "    \n",
    "    \n",
    "    varis_emb = Embedding(V+1, d)(varis)\n",
    "    cve_units = int(np.sqrt(d))\n",
    "    values_emb = CVE(cve_units, d)(values)\n",
    "    times_emb = CVE(cve_units, d)(times)\n",
    "    \n",
    "    \n",
    "    # comb_emb = Add()([varis_emb, values_emb, times_emb]) # b, L, d\n",
    "    \n",
    "    # comb_emb = Add()([varis_emb, values_emb, times_emb]) # b, L, d\n",
    "    \n",
    "    # Q\n",
    "    comb_emb = Add()([varis_emb, values_emb, times_emb, text_d])\n",
    "#     demo_enc = Lambda(lambda x:K.expand_dims(x, axis=-2))(demo_enc) # b, 1, d\n",
    "#     comb_emb = Concatenate(axis=-2)([demo_enc, comb_emb]) # b, L+1, d\n",
    "    mask = Lambda(lambda x:K.clip(x,0,1))(varis) # b, L\n",
    "#     mask = Lambda(lambda x:K.concatenate((K.ones_like(x)[:,0:1], x), axis=-1))(mask) # b, L+1\n",
    "    cont_emb = Transformer(N, he, dk=None, dv=None, dff=None, dropout=dropout)(comb_emb, mask=mask)\n",
    "    attn_weights = Attention(2*d)(cont_emb, mask=mask)\n",
    "    fused_emb = Lambda(lambda x:K.sum(x[0]*x[1], axis=-2))([cont_emb, attn_weights])\n",
    "    \n",
    "#     # embed text input\n",
    "#     texts = Input(shape=(33792,))\n",
    "#     text_enc = Dense(1000, activation='relu')(texts)\n",
    "#     text_enc = Dense(d, activation='relu')(text_enc)\n",
    "\n",
    "\n",
    "    # conc = Concatenate(axis=-1)([fused_emb, text_fused_emb, demo_enc])\n",
    "    conc = Concatenate(axis=-1)([fused_emb, text_dense, demo_enc])\n",
    "    \n",
    "    \n",
    "#     fore_op = Dense(V)(conc)\n",
    "#     op = Dense(1, activation='sigmoid')(fore_op)\n",
    "#     model = Model([demo, times, values, varis, texts, text_times, text_varis], op)\n",
    "#     if forecast:\n",
    "#         fore_model = Model([demo, times, values, varis, texts, text_times, text_varis], fore_op)\n",
    "#         return [model, fore_model]\n",
    "#     return model\n",
    "\n",
    "    \n",
    "    fore_op = Dense(V)(conc)\n",
    "    op = Dense(1, activation='sigmoid')(fore_op)\n",
    "    model = Model([demo, times, values, varis, texts, text_times, text_varis], op)\n",
    "    if forecast:\n",
    "        fore_model = Model([demo, times, values, varis, texts, text_times, text_varis], fore_op)\n",
    "        return [model, fore_model]\n",
    "    return model\n",
    "\n",
    "# To tune:\n",
    "# 1. Transformer parameters. (N, h, dropout)\n",
    "# 2. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, batch_size, samples_per_epoch, patience = 0.0005, 8, 102400, 5\n",
    "# lr, batch_size, samples_per_epoch, patience = 0.0005, 1, 1024, 5\n",
    "d, N, he, dropout = 50, 2, 4, 0.2\n",
    "model, fore_model =  build_strats(D, fore_max_len, V, d, N, he, dropout, forecast=True)\n",
    "print (fore_model.summary())\n",
    "\n",
    "val_losses = []\n",
    "\n",
    "for i in list(range(100)):\n",
    "    gc.collect()\n",
    "    fore_path = 'hierar/Pro/models/forecasting/forecasting_'+str(i+1)+'_epochs.h5'\n",
    "    fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "    fore_model.load_weights(fore_path)\n",
    "\n",
    "    val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f'validation loss: {val_loss}')\n",
    "    gc.collect()\n",
    "    print(val_losses)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[8.483444213867188, 7.473776340484619, 6.93328857421875, 6.587220191955566, 6.426333904266357, 6.160365581512451, 6.131229400634766, 5.9929986000061035, 5.9875593185424805, 5.831292152404785, 5.763743877410889, 5.772653579711914, 5.716346263885498, 5.6492919921875, 5.701827526092529, 5.616291522979736, 5.586249828338623, 5.613157272338867, 5.566737651824951, 5.521819591522217, 5.539564609527588, 5.536924839019775, 5.491822719573975, 5.4548139572143555, 5.457018852233887, 5.455965995788574, 5.44157600402832, 5.579344272613525, 5.466297626495361, 5.432507514953613, 5.6279473304748535, 5.4310126304626465, 5.467263221740723, 5.627671241760254, 5.470911502838135, 5.374270439147949, 5.393491744995117, 5.368008136749268, 5.416056156158447, 5.413441181182861, 5.505258560180664, 5.4463725090026855, 5.374141216278076, 5.357137203216553, 5.3646159172058105, 5.550652980804443, 5.341265678405762, 5.385351657867432, 5.3984479904174805, 5.38784122467041, 5.3086395263671875, 5.329946517944336, 5.377668380737305, 5.3150634765625, 5.335404872894287, 5.463996887207031, 5.278020858764648, 5.423778533935547, 5.292324542999268, 5.274566173553467, 5.356962203979492, 5.326461315155029, 5.3152174949646, 5.37034797668457, 5.29688835144043, 5.330498218536377, 5.288092613220215, 5.28347635269165, 5.2894158363342285, 5.286518096923828, 5.304732799530029, 5.317917823791504, 5.2567267417907715, 5.24439001083374, 5.268968105316162, 5.260003566741943, 5.304421901702881, 5.303035259246826, 5.258347511291504]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of y values\n",
    "y_values = [8.483444213867188, 7.473776340484619, 6.93328857421875, 6.587220191955566, 6.426333904266357, 6.160365581512451, 6.131229400634766, 5.9929986000061035, 5.9875593185424805, 5.831292152404785, 5.763743877410889, 5.772653579711914, 5.716346263885498, 5.6492919921875, 5.701827526092529, 5.616291522979736, 5.586249828338623, 5.613157272338867, 5.566737651824951, 5.521819591522217, 5.539564609527588, 5.536924839019775, 5.491822719573975, 5.4548139572143555, 5.457018852233887, 5.455965995788574, 5.44157600402832, 5.579344272613525, 5.466297626495361, 5.432507514953613, 5.6279473304748535, 5.4310126304626465, 5.467263221740723, 5.627671241760254, 5.470911502838135, 5.374270439147949, 5.393491744995117, 5.368008136749268, 5.416056156158447, 5.413441181182861, 5.505258560180664, 5.4463725090026855, 5.374141216278076, 5.357137203216553, 5.3646159172058105, 5.550652980804443, 5.341265678405762, 5.385351657867432, 5.3984479904174805, 5.38784122467041, 5.3086395263671875, 5.329946517944336, 5.377668380737305, 5.3150634765625, 5.335404872894287, 5.463996887207031, 5.278020858764648, 5.423778533935547, 5.292324542999268, 5.274566173553467, 5.356962203979492, 5.326461315155029, 5.3152174949646, 5.37034797668457, 5.29688835144043, 5.330498218536377, 5.288092613220215, 5.28347635269165, 5.2894158363342285, 5.286518096923828, 5.304732799530029, 5.317917823791504, 5.2567267417907715, 5.24439001083374, 5.268968105316162, 5.260003566741943, 5.304421901702881, 5.303035259246826, 5.258347511291504]\n",
    "\n",
    "y_values += [5.270775318145752, 5.240047931671143, 5.3805413246154785, 5.247272968292236, 5.260074615478516, 5.228386878967285, 5.242153644561768, 5.245741367340088, 5.242713451385498, 5.220280170440674, 5.243130683898926, 5.388330459594727, 5.280952453613281, 5.333823204040527, 5.244796276092529, 5.260797500610352, 5.231106758117676, 5.2983317375183105, 5.205908298492432, 5.238000869750977, 5.256564140319824, 5.208333492279053, 5.183602333068848, 5.260712146759033, 5.221482753753662, 5.195287704467773, 5.250069618225098, 5.242126941680908, 5.225848197937012, 5.317182540893555, 5.225686073303223, 5.2749762535095215, 5.207957744598389, 5.465452194213867, 5.27269172668457, 5.251333713531494, 5.207937240600586, 5.197074890136719, 5.179708003997803, 5.172123908996582, 5.222113609313965, 5.1610565185546875, 5.186363697052002, 5.2389068603515625, 5.284305572509766, 5.3309645652771, 5.207242965698242, 5.168575763702393, 5.154052734375, 5.206447601318359, 5.269092082977295, 5.201481342315674, 5.179599285125732]\n",
    "\n",
    "y_values = y_values[:60]\n",
    "# Generating x values\n",
    "x_values = list(range(1, len(y_values) + 1))\n",
    "\n",
    "# Creating the line chart\n",
    "plt.plot(x_values, y_values, marker='o', linestyle='-')\n",
    "\n",
    "# Adding title and labels\n",
    "plt.title('Line Chart')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "\n",
    "# Displaying the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# val_losses = [8.483444213867188, 7.473776340484619, 6.93328857421875, 6.587220191955566, 6.426333904266357, 6.160365581512451, 6.131229400634766, 5.9929986000061035, 5.9875593185424805, 5.831292152404785, 5.763743877410889, 5.772653579711914, 5.716346263885498, 5.6492919921875, 5.701827526092529, 5.616291522979736, 5.586249828338623, 5.613157272338867, 5.566737651824951, 5.521819591522217, 5.539564609527588, 5.536924839019775, 5.491822719573975, 5.4548139572143555, 5.457018852233887, 5.455965995788574, 5.44157600402832, 5.579344272613525, 5.466297626495361, 5.432507514953613, 5.6279473304748535, 5.4310126304626465, 5.467263221740723, 5.627671241760254, 5.470911502838135, 5.374270439147949, 5.393491744995117, 5.368008136749268, 5.416056156158447, 5.413441181182861, 5.505258560180664, 5.4463725090026855, 5.374141216278076, 5.357137203216553, 5.3646159172058105, 5.550652980804443, 5.341265678405762, 5.385351657867432, 5.3984479904174805, 5.38784122467041, 5.3086395263671875, 5.329946517944336, 5.377668380737305, 5.3150634765625, 5.335404872894287, 5.463996887207031, 5.278020858764648, 5.423778533935547, 5.292324542999268, 5.274566173553467, 5.356962203979492, 5.326461315155029, 5.3152174949646, 5.37034797668457, 5.29688835144043, 5.330498218536377, 5.288092613220215, 5.28347635269165, 5.2894158363342285, 5.286518096923828, 5.304732799530029, 5.317917823791504, 5.2567267417907715, 5.24439001083374, 5.268968105316162, 5.260003566741943, 5.304421901702881, 5.303035259246826, 5.258347511291504]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr, batch_size, samples_per_epoch, patience = 0.0005, 8, 102400, 5\n",
    "# # lr, batch_size, samples_per_epoch, patience = 0.0005, 1, 1024, 5\n",
    "# d, N, he, dropout = 50, 2, 4, 0.2\n",
    "# model, fore_model =  build_strats(D, fore_max_len, V, d, N, he, dropout, forecast=True)\n",
    "# print (fore_model.summary())\n",
    "\n",
    "# val_losses = []\n",
    "\n",
    "# for i in list(range(100)):\n",
    "#     gc.collect()\n",
    "#     fore_path = 'hierar/Pro/models/forecasting/forecasting_'+str(i+80)+'_epochs.h5'\n",
    "#     fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "#     fore_model.load_weights(fore_path)\n",
    "\n",
    "#     val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "#     val_losses.append(val_loss)\n",
    "#     print(f'validation loss: {val_loss}')\n",
    "#     gc.collect()\n",
    "#     print(val_losses)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[5.270775318145752, 5.240047931671143, 5.3805413246154785, 5.247272968292236, 5.260074615478516, 5.228386878967285, 5.242153644561768, 5.245741367340088, 5.242713451385498, 5.220280170440674, 5.243130683898926, 5.388330459594727, 5.280952453613281, 5.333823204040527, 5.244796276092529, 5.260797500610352, 5.231106758117676, 5.2983317375183105, 5.205908298492432, 5.238000869750977, 5.256564140319824, 5.208333492279053, 5.183602333068848, 5.260712146759033, 5.221482753753662, 5.195287704467773, 5.250069618225098, 5.242126941680908, 5.225848197937012, 5.317182540893555, 5.225686073303223, 5.2749762535095215, 5.207957744598389, 5.465452194213867, 5.27269172668457, 5.251333713531494, 5.207937240600586, 5.197074890136719, 5.179708003997803, 5.172123908996582, 5.222113609313965, 5.1610565185546875, 5.186363697052002, 5.2389068603515625, 5.284305572509766, 5.3309645652771, 5.207242965698242, 5.168575763702393, 5.154052734375, 5.206447601318359, 5.269092082977295, 5.201481342315674, 5.179599285125732]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr, batch_size, samples_per_epoch, patience = 0.0005, 8, 102400, 5\n",
    "# lr, batch_size, samples_per_epoch, patience = 0.0005, 1, 1024, 5\n",
    "d, N, he, dropout = 50, 2, 4, 0.2\n",
    "model, fore_model =  build_strats(D, fore_max_len, V, d, N, he, dropout, forecast=True)\n",
    "print (fore_model.summary())\n",
    "gc.collect()\n",
    "fore_path = 'hierar/Pro/models/forecasting/forecasting_103_epochs.h5'\n",
    "fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "fore_model.load_weights(fore_path)\n",
    "\n",
    "val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "print(f'validation loss: {val_loss}')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.260712146759033"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
