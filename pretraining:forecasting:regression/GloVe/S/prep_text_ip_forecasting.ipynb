{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! export TF_CPP_MIN_LOG_LEVEL=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "e7odgm5VsOsb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec  2 13:12:33 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:3A:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    42W / 300W |     15MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    41W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    40W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    41W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1957      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    1   N/A  N/A      1957      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    2   N/A  N/A      1957      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    3   N/A  N/A      1957      G   /usr/libexec/Xorg                   8MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# gpu check\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis\n"
     ]
    }
   ],
   "source": [
    "cd /pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RpTg0QzPqqKv"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Lambda\n",
    "# # from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras import models\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "# import tensorflow.keras.backend as K\n",
    "# from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "import pandas as pd\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "# from transformers import AutoTokenizer, pipeline, AutoModel\n",
    "import resources.smart_cond as sc\n",
    "# from google.colab import files\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AeG1PfTVsOsd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.format_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfKWDkwoeSGU"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path to glove data\n",
    "data_path = 'Data/glove_kws_reserved.pkl'\n",
    "pkl = pickle.load(open(data_path, 'rb'))\n",
    "data = pkl[0]\n",
    "oc = pkl[1]\n",
    "train_ind = pkl[2]\n",
    "valid_ind = pkl[3]\n",
    "test_ind = pkl[4]\n",
    "del pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_ind</th>\n",
       "      <th>hour</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>TABLE</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10223</td>\n",
       "      <td>467.816667</td>\n",
       "      <td>Text</td>\n",
       "      <td>Admission Date : 2119 - 5 - 4 Discharge Date :...</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18407</td>\n",
       "      <td>28.016667</td>\n",
       "      <td>Text</td>\n",
       "      <td>Admission Date : 2112 - 12 - 8 Discharge Date ...</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40300</td>\n",
       "      <td>155.166667</td>\n",
       "      <td>Text</td>\n",
       "      <td>Admission Date : 2194 - 7 - 18 Discharge Date ...</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23747</td>\n",
       "      <td>52.383333</td>\n",
       "      <td>Text</td>\n",
       "      <td>Admission Date : 2194 - 1 - 7 Discharge Date :...</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2357</td>\n",
       "      <td>73.133333</td>\n",
       "      <td>Text</td>\n",
       "      <td>Admission Date : 2186 - 6 - 7 Discharge Date :...</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886223</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>MBP</td>\n",
       "      <td>0.195381</td>\n",
       "      <td>chart</td>\n",
       "      <td>78.552377</td>\n",
       "      <td>17.645628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886224</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>O2 Saturation</td>\n",
       "      <td>-0.678068</td>\n",
       "      <td>chart</td>\n",
       "      <td>96.820961</td>\n",
       "      <td>4.160290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886225</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>RR</td>\n",
       "      <td>0.179866</td>\n",
       "      <td>chart</td>\n",
       "      <td>26.278501</td>\n",
       "      <td>15.130729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886226</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>SBP</td>\n",
       "      <td>-0.404061</td>\n",
       "      <td>chart</td>\n",
       "      <td>120.239648</td>\n",
       "      <td>25.341836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886227</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>Urine</td>\n",
       "      <td>-0.24296</td>\n",
       "      <td>output</td>\n",
       "      <td>123.393012</td>\n",
       "      <td>137.442433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82447326 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ts_ind        hour       variable  \\\n",
       "0          10223  467.816667           Text   \n",
       "1          18407   28.016667           Text   \n",
       "2          40300  155.166667           Text   \n",
       "3          23747   52.383333           Text   \n",
       "4           2357   73.133333           Text   \n",
       "...          ...         ...            ...   \n",
       "82886223   57281   20.400000            MBP   \n",
       "82886224   57281   20.400000  O2 Saturation   \n",
       "82886225   57281   20.400000             RR   \n",
       "82886226   57281   20.400000            SBP   \n",
       "82886227   57281   20.400000          Urine   \n",
       "\n",
       "                                                      value       TABLE  \\\n",
       "0         Admission Date : 2119 - 5 - 4 Discharge Date :...  noteevents   \n",
       "1         Admission Date : 2112 - 12 - 8 Discharge Date ...  noteevents   \n",
       "2         Admission Date : 2194 - 7 - 18 Discharge Date ...  noteevents   \n",
       "3         Admission Date : 2194 - 1 - 7 Discharge Date :...  noteevents   \n",
       "4         Admission Date : 2186 - 6 - 7 Discharge Date :...  noteevents   \n",
       "...                                                     ...         ...   \n",
       "82886223                                           0.195381       chart   \n",
       "82886224                                          -0.678068       chart   \n",
       "82886225                                           0.179866       chart   \n",
       "82886226                                          -0.404061       chart   \n",
       "82886227                                           -0.24296      output   \n",
       "\n",
       "                mean         std  \n",
       "0           1.000000    1.000000  \n",
       "1           1.000000    1.000000  \n",
       "2           1.000000    1.000000  \n",
       "3           1.000000    1.000000  \n",
       "4           1.000000    1.000000  \n",
       "...              ...         ...  \n",
       "82886223   78.552377   17.645628  \n",
       "82886224   96.820961    4.160290  \n",
       "82886225   26.278501   15.130729  \n",
       "82886226  120.239648   25.341836  \n",
       "82886227  123.393012  137.442433  \n",
       "\n",
       "[82447326 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data.loc[data['variable'] == 'Text', 'value'] = 1\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_window = 2 # hours\n",
    "obs_windows = range(20, 124, 4)\n",
    "# Remove test patients.\n",
    "data = data.merge(oc[['ts_ind', 'SUBJECT_ID']], on='ts_ind', how='left')\n",
    "test_sub = oc.loc[oc.ts_ind.isin(test_ind)].SUBJECT_ID.unique()\n",
    "data = data.loc[~data.SUBJECT_ID.isin(test_sub)]\n",
    "oc = oc.loc[~oc.SUBJECT_ID.isin(test_sub)]\n",
    "data.drop(columns=['SUBJECT_ID', 'TABLE'], inplace=True)\n",
    "# # Fix age.\n",
    "# data.loc[(data.variable=='Age')&(data.value>200), 'value'] = 91.4\n",
    "# # data[data.variable=='Age'][data.value>200]['value'] = 91.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91626it [00:00, 799862.01it/s]\n",
      "  0%|          | 0/26 [00:00<?, ?it/s]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      "  4%|▍         | 1/26 [00:17<07:25, 17.82s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      "  8%|▊         | 2/26 [00:36<07:18, 18.27s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 12%|█▏        | 3/26 [00:54<06:56, 18.09s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 15%|█▌        | 4/26 [01:10<06:25, 17.54s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 19%|█▉        | 5/26 [01:25<05:44, 16.39s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 23%|██▎       | 6/26 [01:39<05:10, 15.53s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 27%|██▋       | 7/26 [01:51<04:36, 14.55s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 31%|███       | 8/26 [02:03<04:06, 13.72s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 35%|███▍      | 9/26 [02:14<03:39, 12.89s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 38%|███▊      | 10/26 [02:25<03:13, 12.10s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 42%|████▏     | 11/26 [02:35<02:53, 11.59s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 46%|████▌     | 12/26 [02:44<02:31, 10.85s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 50%|█████     | 13/26 [02:53<02:12, 10.18s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 54%|█████▍    | 14/26 [03:01<01:54,  9.58s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 58%|█████▊    | 15/26 [03:09<01:41,  9.20s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 62%|██████▏   | 16/26 [03:17<01:26,  8.61s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 65%|██████▌   | 17/26 [03:24<01:13,  8.16s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 69%|██████▉   | 18/26 [03:31<01:02,  7.79s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 73%|███████▎  | 19/26 [03:37<00:52,  7.46s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 77%|███████▋  | 20/26 [03:44<00:43,  7.17s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 81%|████████  | 21/26 [03:50<00:34,  6.86s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 85%|████████▍ | 22/26 [03:56<00:26,  6.51s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 88%|████████▊ | 23/26 [04:01<00:18,  6.27s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 92%|█████████▏| 24/26 [04:07<00:12,  6.06s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      " 96%|█████████▌| 25/26 [04:12<00:05,  5.74s/it]/scratch/slurm_tmpdir/job_22884292/ipykernel_280184/1663465024.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  fore_texts_ip.append(np.array(texts))\n",
      "100%|██████████| 26/26 [04:17<00:00,  9.91s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get static data with mean fill and missingness indicator.\n",
    "static_varis = ['Age', 'Gender']\n",
    "ii = data.variable.isin(static_varis)\n",
    "static_data = data.loc[ii]\n",
    "data = data.loc[~ii]\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "static_var_to_ind = inv_list(static_varis)\n",
    "D = len(static_varis)\n",
    "N = data.ts_ind.max()+1\n",
    "demo = np.zeros((N, D))\n",
    "for row in tqdm(static_data.itertuples()):\n",
    "    demo[row.ts_ind, static_var_to_ind[row.variable]] = row.value\n",
    "# Normalize static data.\n",
    "means = demo.mean(axis=0, keepdims=True)\n",
    "stds = demo.std(axis=0, keepdims=True)\n",
    "stds = (stds==0)*1 + (stds!=0)*stds\n",
    "demo = (demo-means)/stds\n",
    "# Get variable indices.\n",
    "varis = sorted(list(set(data.variable)))\n",
    "V = len(varis)\n",
    "var_to_ind = inv_list(varis, start=1)\n",
    "data['vind'] = data.variable.map(var_to_ind)\n",
    "data = data[['ts_ind', 'vind', 'hour', 'value']].sort_values(by=['ts_ind', 'vind', 'hour'])\n",
    "# Find max_len.\n",
    "fore_max_len = 880\n",
    "# Get forecast inputs and outputs.\n",
    "# fore_times_ip = []\n",
    "# fore_values_ip = []\n",
    "# fore_varis_ip = []\n",
    "fore_texts_ip = []\n",
    "# fore_op = []\n",
    "fore_inds = []\n",
    "def f(x):\n",
    "    mask = [0 for i in range(V)]\n",
    "    values = [0 for i in range(V)]\n",
    "    for vv in x:\n",
    "        v = int(vv[0])-1\n",
    "        mask[v] = 1\n",
    "        values[v] = vv[1]\n",
    "    return values+mask\n",
    "def pad(x):\n",
    "    return x+[0]*(fore_max_len-len(x))\n",
    "for w in tqdm(obs_windows):\n",
    "    pred_data = data.loc[(data.hour>=w)&(data.hour<=w+pred_window)]\n",
    "    pred_data = pred_data.groupby(['ts_ind', 'vind']).agg({'value':'first'}).reset_index()\n",
    "    pred_data['vind_value'] = pred_data[['vind', 'value']].values.tolist()\n",
    "    pred_data = pred_data.groupby('ts_ind').agg({'vind_value':list}).reset_index()\n",
    "    pred_data['vind_value'] = pred_data['vind_value'].apply(f)    \n",
    "    obs_data = data.loc[(data.hour<w)&(data.hour>=w-24)]\n",
    "    obs_data = obs_data.loc[obs_data.ts_ind.isin(pred_data.ts_ind)]\n",
    "    obs_data = obs_data.groupby('ts_ind').head(fore_max_len)\n",
    "    obs_data = obs_data.groupby('ts_ind').agg({'vind':list, 'hour':list, 'value':list}).reset_index()\n",
    "    obs_data = obs_data.merge(pred_data, on='ts_ind')\n",
    "    for col in ['vind', 'hour', 'value']:\n",
    "        obs_data[col] = obs_data[col].apply(pad)\n",
    "    # fore_op.append(np.array(list(obs_data.vind_value)))\n",
    "    fore_inds.append(np.array(list(obs_data.ts_ind)))\n",
    "    # fore_times_ip.append(np.array(list(obs_data.hour)))\n",
    "    # fore_values_ip.append(np.array(list(obs_data.value)))\n",
    "    \n",
    "    values = list(obs_data.value)\n",
    "    texts = []\n",
    "    for value in values:\n",
    "        texts.append(np.array([item for item in value if isinstance(item, str)]))\n",
    "    fore_texts_ip.append(np.array(texts))\n",
    "    \n",
    "    # fore_varis_ip.append(np.array(list(obs_data.vind)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "# fore_times_ip = np.concatenate(fore_times_ip, axis=0)\n",
    "# fore_values_ip = np.concatenate(fore_values_ip, axis=0)\n",
    "# fore_varis_ip = np.concatenate(fore_varis_ip, axis=0)\n",
    "fore_texts_ip = np.concatenate(fore_texts_ip, axis=0)\n",
    "# fore_op = np.concatenate(fore_op, axis=0)\n",
    "fore_inds = np.concatenate(fore_inds, axis=0)\n",
    "fore_demo = demo[fore_inds]\n",
    "# Get train and valid ts_ind for forecast task.\n",
    "train_sub = oc.loc[oc.ts_ind.isin(train_ind)].SUBJECT_ID.unique()\n",
    "valid_sub = oc.loc[oc.ts_ind.isin(valid_ind)].SUBJECT_ID.unique()\n",
    "rem_sub = oc.loc[~oc.SUBJECT_ID.isin(np.concatenate((train_ind, valid_ind)))].SUBJECT_ID.unique()\n",
    "bp = int(0.8*len(rem_sub))\n",
    "train_sub = np.concatenate((train_sub, rem_sub[:bp]))\n",
    "valid_sub = np.concatenate((valid_sub, rem_sub[bp:]))\n",
    "train_ind = oc.loc[oc.SUBJECT_ID.isin(train_sub)].ts_ind.unique() # Add remaining ts_ind s of train subjects.\n",
    "valid_ind = oc.loc[oc.SUBJECT_ID.isin(valid_sub)].ts_ind.unique() # Add remaining ts_ind s of train subjects.\n",
    "# Generate 3 sets of inputs and outputs.\n",
    "train_ind = np.argwhere(np.in1d(fore_inds, train_ind)).flatten()\n",
    "valid_ind = np.argwhere(np.in1d(fore_inds, valid_ind)).flatten()\n",
    "\n",
    "fore_train_texts_ip = [ip[train_ind] for ip in [fore_texts_ip]]\n",
    "fore_valid_texts_ip = [ip[valid_ind] for ip in [fore_texts_ip]]\n",
    "\n",
    "fore_train_texts = fore_train_texts_ip[0]\n",
    "fore_valid_texts = fore_valid_texts_ip[0]\n",
    "\n",
    "del fore_train_texts_ip\n",
    "del fore_valid_texts_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_texts = []\n",
    "# for text in tqdm(fore_train_texts):\n",
    "#     train_texts.append(' '.join(text))\n",
    "\n",
    "# train_texts = np.array(train_texts)\n",
    "\n",
    "# del fore_train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.savetxt('forecasting_train_ip.txt', train_texts, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136823/136823 [00:06<00:00, 21812.42it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_texts = []\n",
    "for text in tqdm(fore_valid_texts):\n",
    "    valid_texts.append(' '.join(text))\n",
    "\n",
    "valid_texts = np.array(valid_texts)\n",
    "\n",
    "del fore_valid_texts\n",
    "np.savetxt('forecasting_valid_ip.txt', valid_texts, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_val_texts = train_texts + val_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141579"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(valid_texts)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoded_docs = t.texts_to_sequences(valid_texts)\n",
    "# encoded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136823/136823 [00:00<00:00, 2427835.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22867"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "for doc in tqdm(encoded_docs):\n",
    "    if len(doc)>max_len:\n",
    "        max_len = len(doc)\n",
    "\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del valid_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Wrong number of columns at line 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_texts \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforecasting_valid_ip.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/lib/npyio.py:1159\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1157\u001b[0m     words \u001b[38;5;241m=\u001b[39m usecols_getter(words)\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(words) \u001b[38;5;241m!=\u001b[39m ncols:\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong number of columns at line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlineno\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;66;03m# Convert each value according to its column, then pack it\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;66;03m# according to the dtype's nesting, and store it.\u001b[39;00m\n\u001b[1;32m   1163\u001b[0m chunk\u001b[38;5;241m.\u001b[39mappend(packer(convert_row(words)))\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of columns at line 2"
     ]
    }
   ],
   "source": [
    "test_texts = np.loadtxt('forecasting_valid_ip.txt', dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from numpy import array, asarray, zeros\n",
    "# # # GloVe\n",
    "# # glove_path = 'resources/glove.840B.300d.txt'\n",
    "\n",
    "# # # load the whole embedding into memory\n",
    "# # embeddings_index = dict()\n",
    "# # f = open(glove_path)\n",
    "# # for line in f:\n",
    "# #     values = line.split()\n",
    "# #     word = values[0]\n",
    "# #     coefs = asarray(values[1:], dtype='float32')\n",
    "# #     embeddings_index[word] = coefs\n",
    "# # f.close()\n",
    "# # print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "# embedding_model = {}\n",
    "# f = open('resources/glove.840B.300d.txt', 'r', encoding=\"utf8\")\n",
    "# for line in f:\n",
    "#     values = line.split()\n",
    "#     word = ''.join(values[:-300])\n",
    "#     coefs = np.asarray(values[-300:], dtype='float32')\n",
    "#     embedding_model[word] = coefs\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # create a weight matrix for words in training docs\n",
    "# embedding_matrix = zeros((vocab_size, 300))\n",
    "# for word, i in t.word_index.items():\n",
    "#     embedding_vector = embeddings_index.get(word)\n",
    "#     if embedding_vector is not None:\n",
    "#         embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# embedding_matrix.shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
