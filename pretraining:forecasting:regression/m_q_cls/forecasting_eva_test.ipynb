{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c6a8d57-4fbb-4783-8a15-991e090bee29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 21 12:11:20 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000000:3A:00.0 Off |                    0 |\n",
      "| N/A   31C    P0              40W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-32GB           On  | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   32C    P0              40W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2292      G   /usr/libexec/Xorg                             8MiB |\n",
      "|    1   N/A  N/A      2292      G   /usr/libexec/Xorg                             8MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# gpu check\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "910e34b6-f416-4a46-ab35-a047cfe17c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis\n"
     ]
    }
   ],
   "source": [
    "cd /pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76443227-3cf6-4379-b21d-6aec2443738c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 12:11:23.795765: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-21 12:11:24.591084: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-21 12:11:41.970178: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Lambda\n",
    "# from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "import pandas as pd\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, pipeline, AutoModel\n",
    "import resources.smart_cond as sc\n",
    "# from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "174f33fd-69b1-4d29-ad43-b9ae694b4f29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = 'Data/sepsis_removed_0.pkl'\n",
    "pkl = pickle.load(open(data_path, 'rb'))\n",
    "data = pkl[0]\n",
    "oc = pkl[1]\n",
    "train_ind = pkl[2]\n",
    "valid_ind = pkl[3]\n",
    "test_ind = pkl[4]\n",
    "del pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9de00119-48bb-4706-ab2f-d501afc56380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.loc[data['variable'] == 'Text', 'value'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f927205b-b7a0-45c1-b292-7b5a39ea4e93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22938it [00:00, 772830.89it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_window = 2 # hours\n",
    "obs_windows = range(20, 124, 4)\n",
    "\n",
    "# Remove train, val patients\n",
    "data = data.merge(oc[['ts_ind', 'SUBJECT_ID']], on='ts_ind', how='left')\n",
    "train_sub = oc.loc[oc.ts_ind.isin(train_ind)].SUBJECT_ID.unique()\n",
    "valid_sub = oc.loc[oc.ts_ind.isin(valid_ind)].SUBJECT_ID.unique()\n",
    "data = data.loc[~data.SUBJECT_ID.isin(train_sub)]\n",
    "data = data.loc[~data.SUBJECT_ID.isin(valid_sub)]\n",
    "oc = oc.loc[~oc.SUBJECT_ID.isin(train_sub)]\n",
    "oc = oc.loc[~oc.SUBJECT_ID.isin(valid_sub)]\n",
    "\n",
    "data.drop(columns=['SUBJECT_ID', 'TABLE'], inplace=True)\n",
    "# Fix age.\n",
    "data.loc[(data.variable=='Age')&(data.value>200), 'value'] = 91.4\n",
    "# Get static data with mean fill and missingness indicator.\n",
    "static_varis = ['Age', 'Gender']\n",
    "ii = data.variable.isin(static_varis)\n",
    "static_data = data.loc[ii]\n",
    "data = data.loc[~ii]\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "static_var_to_ind = inv_list(static_varis)\n",
    "D = len(static_varis)\n",
    "N = data.ts_ind.max()+1\n",
    "demo = np.zeros((N, D))\n",
    "for row in tqdm(static_data.itertuples()):\n",
    "    demo[row.ts_ind, static_var_to_ind[row.variable]] = row.value\n",
    "# Normalize static data.\n",
    "means = demo.mean(axis=0, keepdims=True)\n",
    "stds = demo.std(axis=0, keepdims=True)\n",
    "stds = (stds==0)*1 + (stds!=0)*stds\n",
    "demo = (demo-means)/stds\n",
    "\n",
    "# Get variable indices.\n",
    "varis = sorted(list(set(data.variable)))\n",
    "V = len(varis)\n",
    "var_to_ind = inv_list(varis, start=1)\n",
    "data['vind'] = data.variable.map(var_to_ind)\n",
    "data = data[['ts_ind', 'vind', 'hour', 'value']].sort_values(by=['ts_ind', 'vind', 'hour'])\n",
    "# Find max_len.\n",
    "fore_max_len = 880\n",
    "# Get forecast inputs and outputs.\n",
    "fore_times_ip = []\n",
    "fore_values_ip = []\n",
    "fore_varis_ip = []\n",
    "fore_op = []\n",
    "fore_inds = []\n",
    "def f(x):\n",
    "    mask = [0 for i in range(V)]\n",
    "    values = [0 for i in range(V)]\n",
    "    for vv in x:\n",
    "        v = int(vv[0])-1\n",
    "        mask[v] = 1\n",
    "        values[v] = vv[1]\n",
    "    return values+mask\n",
    "def pad(x):\n",
    "    return x+[0]*(fore_max_len-len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c575424-240a-46a2-9d93-284b5c3d7045",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n"
     ]
    }
   ],
   "source": [
    "for w in tqdm(obs_windows):\n",
    "    pred_data = data.loc[(data.hour>=w)&(data.hour<=w+pred_window)]\n",
    "    pred_data = pred_data.groupby(['ts_ind', 'vind']).agg({'value':'first'}).reset_index()\n",
    "    pred_data['vind_value'] = pred_data[['vind', 'value']].values.tolist()\n",
    "    pred_data = pred_data.groupby('ts_ind').agg({'vind_value':list}).reset_index()\n",
    "    pred_data['vind_value'] = pred_data['vind_value'].apply(f)    \n",
    "    obs_data = data.loc[(data.hour<w)&(data.hour>=w-24)]\n",
    "    obs_data = obs_data.loc[obs_data.ts_ind.isin(pred_data.ts_ind)]\n",
    "    obs_data = obs_data.groupby('ts_ind').head(fore_max_len)\n",
    "    obs_data = obs_data.groupby('ts_ind').agg({'vind':list, 'hour':list, 'value':list}).reset_index()\n",
    "    obs_data = obs_data.merge(pred_data, on='ts_ind')\n",
    "    for col in ['vind', 'hour', 'value']:\n",
    "        obs_data[col] = obs_data[col].apply(pad)\n",
    "    fore_op.append(np.array(list(obs_data.vind_value)))\n",
    "    fore_inds.append(np.array(list(obs_data.ts_ind)))\n",
    "    fore_times_ip.append(np.array(list(obs_data.hour)))\n",
    "    fore_values_ip.append(np.array(list(obs_data.value)))\n",
    "    fore_varis_ip.append(np.array(list(obs_data.vind)))\n",
    "\n",
    "del data\n",
    "fore_times_ip = np.concatenate(fore_times_ip, axis=0)\n",
    "fore_values_ip = np.concatenate(fore_values_ip, axis=0)\n",
    "fore_varis_ip = np.concatenate(fore_varis_ip, axis=0)\n",
    "fore_op = np.concatenate(fore_op, axis=0)\n",
    "fore_inds = np.concatenate(fore_inds, axis=0)\n",
    "fore_demo = demo[fore_inds]\n",
    "\n",
    "fore_test_ip = [fore_demo, fore_times_ip, fore_values_ip, fore_varis_ip]\n",
    "fore_test_op = fore_op\n",
    "# release RAM\n",
    "del fore_times_ip, fore_values_ip, fore_varis_ip, demo, fore_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab28b29b-5f88-465d-9ddd-59b2467a5ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# laod text features\n",
    "path = 'Data/text_emb_input_test_1.pkl'\n",
    "text_ip = pickle.load(open(path, 'rb'))\n",
    "text_features = text_ip[0]\n",
    "fore_test_ip.append(text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9f1749b-2d99-49bd-ae5b-d3ca0732e29c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_res(y_true, y_pred):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    minrp = np.minimum(precision, recall).max()\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    return [roc_auc, pr_auc, minrp]\n",
    "\n",
    "# ######################################################################################################## \n",
    "# ######################################################################################################## \n",
    "# class_weights = compute_class_weight(class_weight='balanced', classes=[0,1], y=train_op)\n",
    "# def mortality_loss(y_true, y_pred):\n",
    "#     sample_weights = (1-y_true)*class_weights[0] + y_true*class_weights[1]\n",
    "#     bce = K.binary_crossentropy(y_true, y_pred)\n",
    "#     return K.mean(sample_weights*bce, axis=-1)\n",
    "# ######################################################################################################## \n",
    "# ######################################################################################################## \n",
    "\n",
    "# var_weights = np.sum(fore_train_op[:, V:], axis=0)\n",
    "# var_weights[var_weights==0] = var_weights.max()\n",
    "# var_weights = var_weights.max()/var_weights\n",
    "# var_weights = var_weights.reshape((1, V))\n",
    "def forecast_loss(y_true, y_pred):\n",
    "    return K.sum(y_true[:,V:]*(y_true[:,:V]-y_pred)**2, axis=-1)\n",
    "\n",
    "def get_min_loss(weight):\n",
    "    def min_loss(y_true, y_pred):\n",
    "        return weight*y_pred\n",
    "    return min_loss\n",
    "\n",
    "class CustomCallback(Callback):\n",
    "    def __init__(self, validation_data, batch_size):\n",
    "        self.val_x, self.val_y = validation_data\n",
    "        self.batch_size = batch_size\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.val_x, verbose=0, batch_size=self.batch_size)\n",
    "        if type(y_pred)==type([]):\n",
    "            y_pred = y_pred[0]\n",
    "        precision, recall, thresholds = precision_recall_curve(self.val_y, y_pred)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        roc_auc = roc_auc_score(self.val_y, y_pred)\n",
    "        logs['custom_metric'] = pr_auc + roc_auc\n",
    "        print ('val_aucs:', pr_auc, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cde35606-16f3-4042-9f9e-5af8aa4730a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Embedding, Activation, Dropout, Softmax, Layer, InputSpec, Input, Dense, Lambda, TimeDistributed, Concatenate, Add\n",
    "from tensorflow.keras import initializers, regularizers, constraints, Model\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow import nn\n",
    "\n",
    "    \n",
    "class CVE(Layer):\n",
    "    def __init__(self, hid_units, output_dim):\n",
    "        self.hid_units = hid_units\n",
    "        self.output_dim = output_dim\n",
    "        super(CVE, self).__init__()\n",
    "        \n",
    "    def build(self, input_shape): \n",
    "        self.W1 = self.add_weight(name='CVE_W1',\n",
    "                            shape=(1, self.hid_units),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        self.b1 = self.add_weight(name='CVE_b1',\n",
    "                            shape=(self.hid_units,),\n",
    "                            initializer='zeros',\n",
    "                            trainable=True)\n",
    "        self.W2 = self.add_weight(name='CVE_W2',\n",
    "                            shape=(self.hid_units, self.output_dim),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        super(CVE, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = K.expand_dims(x, axis=-1)\n",
    "        x = K.dot(K.tanh(K.bias_add(K.dot(x, self.W1), self.b1)), self.W2)\n",
    "        return x\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape + (self.output_dim,)\n",
    "    \n",
    "    \n",
    "class Attention(Layer):\n",
    "    \n",
    "    def __init__(self, hid_dim):\n",
    "        self.hid_dim = hid_dim\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        self.W = self.add_weight(shape=(d, self.hid_dim), name='Att_W',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.hid_dim,), name='Att_b',\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        self.u = self.add_weight(shape=(self.hid_dim,1), name='Att_u',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask, mask_value=-1e30):\n",
    "        attn_weights = K.dot(K.tanh(K.bias_add(K.dot(x,self.W), self.b)), self.u)\n",
    "        mask = K.expand_dims(mask, axis=-1)\n",
    "        attn_weights = mask*attn_weights + (1-mask)*mask_value\n",
    "        attn_weights = K.softmax(attn_weights, axis=-2)\n",
    "        return attn_weights\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1] + (1,)\n",
    "    \n",
    "    \n",
    "class Transformer(Layer):\n",
    "    \n",
    "    def __init__(self, N=2, h=8, dk=None, dv=None, dff=None, dropout=0):\n",
    "        self.N, self.h, self.dk, self.dv, self.dff, self.dropout = N, h, dk, dv, dff, dropout\n",
    "        self.epsilon = K.epsilon() * K.epsilon()\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        if self.dk==None:\n",
    "            self.dk = d//self.h\n",
    "        if self.dv==None:\n",
    "            self.dv = d//self.h\n",
    "        if self.dff==None:\n",
    "            self.dff = 2*d\n",
    "        self.Wq = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wq',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wk = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wk',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wv = self.add_weight(shape=(self.N, self.h, d, self.dv), name='Wv',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wo = self.add_weight(shape=(self.N, self.dv*self.h, d), name='Wo',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.W1 = self.add_weight(shape=(self.N, d, self.dff), name='W1',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b1 = self.add_weight(shape=(self.N, self.dff), name='b1',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.W2 = self.add_weight(shape=(self.N, self.dff, d), name='W2',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b2 = self.add_weight(shape=(self.N, d), name='b2',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.gamma = self.add_weight(shape=(2*self.N,), name='gamma',\n",
    "                                 initializer='ones', trainable=True)\n",
    "        self.beta = self.add_weight(shape=(2*self.N,), name='beta',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        super(Transformer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask, mask_value=-1e-30):\n",
    "        mask = K.expand_dims(mask, axis=-2)\n",
    "        for i in range(self.N):\n",
    "            # MHA\n",
    "            mha_ops = []\n",
    "            for j in range(self.h):\n",
    "                q = K.dot(x, self.Wq[i,j,:,:])\n",
    "                k = K.permute_dimensions(K.dot(x, self.Wk[i,j,:,:]), (0,2,1))\n",
    "                v = K.dot(x, self.Wv[i,j,:,:])\n",
    "                A = K.batch_dot(q,k)\n",
    "                # Mask unobserved steps.\n",
    "                A = mask*A + (1-mask)*mask_value\n",
    "                # Mask for attention dropout.\n",
    "                def dropped_A():\n",
    "                    dp_mask = K.cast((K.random_uniform(shape=array_ops.shape(A))>=self.dropout), K.floatx())\n",
    "                    return A*dp_mask + (1-dp_mask)*mask_value\n",
    "                A = sc.smart_cond(K.learning_phase(), dropped_A, lambda: array_ops.identity(A))\n",
    "                A = K.softmax(A, axis=-1)\n",
    "                mha_ops.append(K.batch_dot(A,v))\n",
    "            conc = K.concatenate(mha_ops, axis=-1)\n",
    "            proj = K.dot(conc, self.Wo[i,:,:])\n",
    "            # Dropout.\n",
    "            proj = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(proj, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(proj))\n",
    "            # Add & LN\n",
    "            x = x+proj\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i] + self.beta[2*i]\n",
    "            # FFN\n",
    "            ffn_op = K.bias_add(K.dot(K.relu(K.bias_add(K.dot(x, self.W1[i,:,:]), self.b1[i,:])), \n",
    "                           self.W2[i,:,:]), self.b2[i,:,])\n",
    "            # Dropout.\n",
    "            ffn_op = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(ffn_op, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(ffn_op))\n",
    "            # Add & LN\n",
    "            x = x+ffn_op\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i+1] + self.beta[2*i+1]            \n",
    "        return x\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "def build_strats(D, max_len, V, d, N, he, dropout, forecast=False):\n",
    "    # demo\n",
    "    demo = Input(shape=(D,))\n",
    "    demo_enc = Dense(2*d, activation='tanh')(demo)\n",
    "    demo_enc = Dense(d, activation='tanh')(demo_enc)\n",
    "    \n",
    "    # text\n",
    "    texts = Input(shape=(33792,))\n",
    "    text_enc = Dense(1000, activation='relu')(texts)\n",
    "    text_enc = Dense(d, activation='relu')(text_enc)\n",
    "    \n",
    "    # triplet\n",
    "    varis = Input(shape=(max_len,))\n",
    "    values = Input(shape=(max_len,))\n",
    "    times = Input(shape=(max_len,))\n",
    "    \n",
    "    varis_emb = Embedding(V+1, d)(varis)\n",
    "    cve_units = int(np.sqrt(d))\n",
    "    values_emb = CVE(cve_units, d)(values)\n",
    "    times_emb = CVE(cve_units, d)(times)\n",
    "    \n",
    "    # comb_emb = Add()([varis_emb, values_emb, times_emb]) # b, L, d\n",
    "    comb_emb = Add()([varis_emb, values_emb, times_emb, text_enc]) # b, L, d\n",
    "#     demo_enc = Lambda(lambda x:K.expand_dims(x, axis=-2))(demo_enc) # b, 1, d\n",
    "#     comb_emb = Concatenate(axis=-2)([demo_enc, comb_emb]) # b, L+1, d\n",
    "    mask = Lambda(lambda x:K.clip(x,0,1))(varis) # b, L\n",
    "#     mask = Lambda(lambda x:K.concatenate((K.ones_like(x)[:,0:1], x), axis=-1))(mask) # b, L+1\n",
    "    cont_emb = Transformer(N, he, dk=None, dv=None, dff=None, dropout=dropout)(comb_emb, mask=mask)\n",
    "    attn_weights = Attention(2*d)(cont_emb, mask=mask)\n",
    "    fused_emb = Lambda(lambda x:K.sum(x[0]*x[1], axis=-2))([cont_emb, attn_weights])\n",
    "    \n",
    "#     # embed text input\n",
    "#     texts = Input(shape=(33792,))\n",
    "#     text_enc = Dense(1000, activation='relu')(texts)\n",
    "#     text_enc = Dense(d, activation='relu')(text_enc)\n",
    "    \n",
    "    conc = Concatenate(axis=-1)([fused_emb, text_enc, demo_enc])\n",
    "    fore_op = Dense(V)(conc)\n",
    "    op = Dense(1, activation='sigmoid')(fore_op)\n",
    "    model = Model([demo, times, values, varis, texts], op)\n",
    "    if forecast:\n",
    "        fore_model = Model([demo, times, values, varis, texts], fore_op)\n",
    "        return [model, fore_model]\n",
    "    return model\n",
    "\n",
    "# To tune:\n",
    "# 1. Transformer parameters. (N, h, dropout)\n",
    "# 2. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c47b9f4e-dc43-4733-8218-f2f1a7dee8d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5ed0d61-eaf4-4b3e-a848-e29189d12a7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131920/131920 [==============================] - 367s 3ms/step - loss: 5.1650\n",
      "Test loss: 5.165024280548096\n"
     ]
    }
   ],
   "source": [
    "# quick eva\n",
    "lr, batch_size, samples_per_epoch, patience = 0.0005, 1, 102400, 5\n",
    "# lr, batch_size, samples_per_epoch, patience = 0.0005, 1, 1024, 5\n",
    "d, N, he, dropout = 50, 2, 4, 0.2\n",
    "model, fore_model =  build_strats(D, fore_max_len, V, d, N, he, dropout, forecast=True)\n",
    "# print (fore_model.summary())\n",
    "\n",
    "\n",
    "\n",
    "fore_path = 'Exp1/Exp_M_Q/models/forecasting/forecasting_105_epochs.h5'\n",
    "\n",
    "fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "fore_model.load_weights(fore_path)\n",
    "\n",
    "val_loss = fore_model.evaluate(fore_test_ip, fore_op, batch_size=batch_size, verbose=1)\n",
    "print(f'Test loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3e50249-6657-40ee-a521-9a900ad51977",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0c9b9d2-1449-4feb-8081-a95b3e21bc1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131920/131920 [==============================] - 369s 3ms/step - loss: 5.2607\n",
      "Test loss: 5.260740756988525\n"
     ]
    }
   ],
   "source": [
    "# quick eva\n",
    "lr, batch_size, samples_per_epoch, patience = 0.0005, 1, 102400, 5\n",
    "# lr, batch_size, samples_per_epoch, patience = 0.0005, 1, 1024, 5\n",
    "d, N, he, dropout = 50, 2, 4, 0.2\n",
    "model, fore_model =  build_strats(D, fore_max_len, V, d, N, he, dropout, forecast=True)\n",
    "# print (fore_model.summary())\n",
    "\n",
    "\n",
    "\n",
    "fore_path = 'Exp1/Exp_M_Q/models/forecasting/forecasting_60_epochs.h5'\n",
    "\n",
    "fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "fore_model.load_weights(fore_path)\n",
    "\n",
    "val_loss = fore_model.evaluate(fore_test_ip, fore_op, batch_size=batch_size, verbose=1)\n",
    "print(f'Test loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39873c81-7a35-4dae-9a72-a707695be9c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4123/4123 [==============================] - 68s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "# quick eva\n",
    "lr, batch_size, samples_per_epoch, patience = 0.0005, 1, 102400, 5\n",
    "# lr, batch_size, samples_per_epoch, patience = 0.0005, 1, 1024, 5\n",
    "d, N, he, dropout = 50, 2, 4, 0.2\n",
    "model, fore_model =  build_strats(D, fore_max_len, V, d, N, he, dropout, forecast=True)\n",
    "# print (fore_model.summary())\n",
    "\n",
    "\n",
    "\n",
    "fore_path = 'Exp1/Exp_M_Q/models/forecasting/forecasting_105_epochs.h5'\n",
    "\n",
    "fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "fore_model.load_weights(fore_path)\n",
    "\n",
    "test_y_preds = fore_model.predict(fore_test_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9951132b-dafe-43a9-91e1-474c2e23eda9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hours = []\n",
    "max_hours = []\n",
    "# get hours\n",
    "for time in fore_test_ip[1]:\n",
    "  hour = max(time)\n",
    "  max_hours.append(hour)\n",
    "  \n",
    "  for obs_window in obs_windows:\n",
    "    if hour < obs_window:\n",
    "      hour = obs_window\n",
    "      break\n",
    "  \n",
    "  hours.append(hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1108eecd-f5e4-47b6-ae7d-9178e20e9019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get patient ids\n",
    "test_patient_ids = []\n",
    "test_sepsis_labels = []\n",
    "\n",
    "# sub_ids = oc['SUBJECT_ID'].tolist()\n",
    "# ts_ind = oc['ts_ind'].tolist()\n",
    "# sepsis = oc['in_hospital_sepsis'].tolist()\n",
    "\n",
    "# for ind in val_inds:\n",
    "#    for i in range(len(sub_ids)):\n",
    "#      if ts_ind[i] == ind:\n",
    "#        val_sepsis_labels.append(sepsis[i])\n",
    "#        val_patient_ids.append(sub_ids[i])\n",
    "#        break\n",
    "\n",
    "for ind in fore_inds:\n",
    "  test_sepsis_labels.append(oc[oc['ts_ind']==ind]['in_hospital_sepsis'].item())\n",
    "  test_patient_ids.append(oc[oc['ts_ind']==ind]['SUBJECT_ID'].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2891737-88ee-49db-baed-121c671c797e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame(\n",
    "    {'ts_ind': fore_inds,\n",
    "     'obs_window': hours,\n",
    "     'SUBJECT_ID': test_patient_ids,\n",
    "     'sepsis_label': test_sepsis_labels,\n",
    "     'forecasting_pred': pd.Series(test_y_preds.tolist()),\n",
    "     'forecasting_test_op': pd.Series(fore_op.tolist())\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a0eaed0-cdc8-4c43-add4-e46c21b0b97a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_ind</th>\n",
       "      <th>obs_window</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>sepsis_label</th>\n",
       "      <th>forecasting_pred</th>\n",
       "      <th>forecasting_test_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.49272620677948, -0.29160264134407043, -0.2...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>279</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.27466630935668945, -0.46084466576576233, -0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1481923907995224, -0.28777334094047546, -0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>306</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.28344935178756714, -0.2493726909160614, -0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "      <td>310</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.3760759234428406, -0.16107144951820374, -0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131915</th>\n",
       "      <td>55277</td>\n",
       "      <td>120</td>\n",
       "      <td>43098</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6258872151374817, 0.6905070543289185, 0.529...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131916</th>\n",
       "      <td>55444</td>\n",
       "      <td>120</td>\n",
       "      <td>58826</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.16931919753551483, 0.7916445136070251, 0.42...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131917</th>\n",
       "      <td>56391</td>\n",
       "      <td>120</td>\n",
       "      <td>23560</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.11549341678619385, 0.7576522827148438, 0.38...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131918</th>\n",
       "      <td>56406</td>\n",
       "      <td>120</td>\n",
       "      <td>48388</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.1665789932012558, 0.801519513130188, 0.4231...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131919</th>\n",
       "      <td>56712</td>\n",
       "      <td>120</td>\n",
       "      <td>7509</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.16461528837680817, 0.8069006204605103, 0.42...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131920 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ts_ind  obs_window  SUBJECT_ID  sepsis_label  \\\n",
       "0            3          20         272             0   \n",
       "1            7          20         279             1   \n",
       "2            9          20         281             0   \n",
       "3           32          20         306             0   \n",
       "4           37          20         310             0   \n",
       "...        ...         ...         ...           ...   \n",
       "131915   55277         120       43098             0   \n",
       "131916   55444         120       58826             1   \n",
       "131917   56391         120       23560             1   \n",
       "131918   56406         120       48388             1   \n",
       "131919   56712         120        7509             0   \n",
       "\n",
       "                                         forecasting_pred  \\\n",
       "0       [-0.49272620677948, -0.29160264134407043, -0.2...   \n",
       "1       [0.27466630935668945, -0.46084466576576233, -0...   \n",
       "2       [0.1481923907995224, -0.28777334094047546, -0....   \n",
       "3       [-0.28344935178756714, -0.2493726909160614, -0...   \n",
       "4       [-0.3760759234428406, -0.16107144951820374, -0...   \n",
       "...                                                   ...   \n",
       "131915  [0.6258872151374817, 0.6905070543289185, 0.529...   \n",
       "131916  [0.16931919753551483, 0.7916445136070251, 0.42...   \n",
       "131917  [0.11549341678619385, 0.7576522827148438, 0.38...   \n",
       "131918  [0.1665789932012558, 0.801519513130188, 0.4231...   \n",
       "131919  [0.16461528837680817, 0.8069006204605103, 0.42...   \n",
       "\n",
       "                                      forecasting_test_op  \n",
       "0       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                   ...  \n",
       "131915  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "131916  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "131917  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "131918  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "131919  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "\n",
       "[131920 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd9631e8-a354-4720-ade7-c0a54ca4aee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dump to pkl\n",
    "pickle.dump([test_data, var_to_ind], open('randomization_test/data/bert_q_m.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b72b64-ff2d-4118-9163-7a77f0f901a0",
   "metadata": {},
   "source": [
    "## Eva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1c0e0ba-4b26-47e7-beb9-78d7a8923f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow.keras.backend as K\n",
    "# def forecast_loss(y_true, y_pred):\n",
    "#     V=134\n",
    "#     return K.sum(y_true[:,V:]*(y_true[:,:V]-y_pred)**2, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a63d07b8-6de4-4470-a645-a2b180595093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = []\n",
    "# for y in test_data['forecasting_test_op']:\n",
    "#   y_true.append(y)\n",
    "# y_true = np.array(y_true)\n",
    "# # y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdec11ee-a451-4965-af1a-ee681a2a3dde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_pred = []\n",
    "# for y in test_data['forecasting_pred']:\n",
    "#   y_pred.append(y)\n",
    "# y_pred = np.array(y_pred)\n",
    "# # y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50ead362-2bbd-474a-90d2-57f19351a008",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mmse = forecast_loss(y_true, y_pred)\n",
    "# s = 0\n",
    "# for i in mmse:\n",
    "#   s += i\n",
    "# s/len(mmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee6abdc2-b603-4779-a894-4072ce2fcadc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mmse = forecast_loss(y_true, y_pred)\n",
    "# s = 0\n",
    "# for i in mmse:\n",
    "#   s += i\n",
    "# s/len(mmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
