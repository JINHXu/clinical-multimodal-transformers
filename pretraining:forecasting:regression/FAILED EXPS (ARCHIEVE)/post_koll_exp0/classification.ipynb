{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECKAJiLXiTlN"
   },
   "source": [
    "## Hardware check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e7odgm5VsOsb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 20 01:42:10 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    41W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    42W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2044      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    1   N/A  N/A      2044      G   /usr/libexec/Xorg                   8MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# gpu check\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oEEUeIW3sOsc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of cores\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count() \n",
    "cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY9I5eXWeOom"
   },
   "source": [
    "## Environment Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis\n"
     ]
    }
   ],
   "source": [
    "cd /pfs/data5/home/hd/hd_hd/hd_nf283/MA_Thesis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 01:42:12.446657: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-20 01:42:12.885267: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 01:42:29.505493: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Lambda\n",
    "# from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "import pandas as pd\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, pipeline, AutoModel\n",
    "import resources.smart_cond as sc\n",
    "# from google.colab import files\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Data/classification_embs_1.pkl'\n",
    "train_text, valid_text, test_text = pickle.load(open(data_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = 'Data/sepsis_removed_0.pkl'\n",
    "pkl = pickle.load(open(data_path, 'rb'))\n",
    "data = pkl[0]\n",
    "oc = pkl[1]\n",
    "train_ind = pkl[2]\n",
    "valid_ind = pkl[3]\n",
    "test_ind = pkl[4]\n",
    "del pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_ind</th>\n",
       "      <th>hour</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>TABLE</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10223</td>\n",
       "      <td>467.816667</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18407</td>\n",
       "      <td>28.016667</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40300</td>\n",
       "      <td>155.166667</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23747</td>\n",
       "      <td>52.383333</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2357</td>\n",
       "      <td>73.133333</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886223</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>MBP</td>\n",
       "      <td>0.195381</td>\n",
       "      <td>chart</td>\n",
       "      <td>78.552377</td>\n",
       "      <td>17.645628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886224</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>O2 Saturation</td>\n",
       "      <td>-0.678068</td>\n",
       "      <td>chart</td>\n",
       "      <td>96.820961</td>\n",
       "      <td>4.160290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886225</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>RR</td>\n",
       "      <td>0.179866</td>\n",
       "      <td>chart</td>\n",
       "      <td>26.278501</td>\n",
       "      <td>15.130729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886226</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>SBP</td>\n",
       "      <td>-0.404061</td>\n",
       "      <td>chart</td>\n",
       "      <td>120.239648</td>\n",
       "      <td>25.341836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886227</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>Urine</td>\n",
       "      <td>-0.24296</td>\n",
       "      <td>output</td>\n",
       "      <td>123.393012</td>\n",
       "      <td>137.442433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82447326 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ts_ind        hour       variable     value       TABLE        mean  \\\n",
       "0          10223  467.816667           Text         1  noteevents    1.000000   \n",
       "1          18407   28.016667           Text         1  noteevents    1.000000   \n",
       "2          40300  155.166667           Text         1  noteevents    1.000000   \n",
       "3          23747   52.383333           Text         1  noteevents    1.000000   \n",
       "4           2357   73.133333           Text         1  noteevents    1.000000   \n",
       "...          ...         ...            ...       ...         ...         ...   \n",
       "82886223   57281   20.400000            MBP  0.195381       chart   78.552377   \n",
       "82886224   57281   20.400000  O2 Saturation -0.678068       chart   96.820961   \n",
       "82886225   57281   20.400000             RR  0.179866       chart   26.278501   \n",
       "82886226   57281   20.400000            SBP -0.404061       chart  120.239648   \n",
       "82886227   57281   20.400000          Urine  -0.24296      output  123.393012   \n",
       "\n",
       "                 std  \n",
       "0           1.000000  \n",
       "1           1.000000  \n",
       "2           1.000000  \n",
       "3           1.000000  \n",
       "4           1.000000  \n",
       "...              ...  \n",
       "82886223   17.645628  \n",
       "82886224    4.160290  \n",
       "82886225   15.130729  \n",
       "82886226   25.341836  \n",
       "82886227  137.442433  \n",
       "\n",
       "[82447326 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['variable'] == 'Text', 'value'] = 1\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "114564it [00:00, 787455.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len 880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19267073it [00:27, 702243.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter labeled data in first 24h.\n",
    "data = data.loc[data.ts_ind.isin(np.concatenate((train_ind, valid_ind, test_ind), axis=-1))]\n",
    "data = data.loc[(data.hour>=0)&(data.hour<=24)]\n",
    "oc = oc.loc[oc.ts_ind.isin(np.concatenate((train_ind, valid_ind, test_ind), axis=-1))]\n",
    "# Fix age.\n",
    "data.loc[(data.variable=='Age')&(data.value>200), 'value'] = 91.4\n",
    "# Get y and N.\n",
    "y = np.array(oc.sort_values(by='ts_ind')['in_hospital_sepsis']).astype('float32')\n",
    "N = data.ts_ind.max() + 1\n",
    "# Get static data with mean fill and missingness indicator.\n",
    "static_varis = ['Age', 'Gender']\n",
    "ii = data.variable.isin(static_varis)\n",
    "static_data = data.loc[ii]\n",
    "data = data.loc[~ii]\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "static_var_to_ind = inv_list(static_varis)\n",
    "D = len(static_varis)\n",
    "demo = np.zeros((N, D))\n",
    "for row in tqdm(static_data.itertuples()):\n",
    "    demo[row.ts_ind, static_var_to_ind[row.variable]] = row.value\n",
    "# Normalize static data.\n",
    "means = demo.mean(axis=0, keepdims=True)\n",
    "stds = demo.std(axis=0, keepdims=True)\n",
    "stds = (stds==0)*1 + (stds!=0)*stds\n",
    "demo = (demo-means)/stds\n",
    "# # Trim to max len.\n",
    "# data = data.sample(frac=1)\n",
    "data = data.groupby('ts_ind').head(880)\n",
    "# Get N, V, var_to_ind.\n",
    "N = data.ts_ind.max() + 1\n",
    "varis = sorted(list(set(data.variable)))\n",
    "V = len(varis)\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "var_to_ind = inv_list(varis, start=1)\n",
    "data['vind'] = data.variable.map(var_to_ind)\n",
    "data = data[['ts_ind', 'vind', 'hour', 'value']].sort_values(by=['ts_ind', 'vind', 'hour'])\n",
    "# Add obs index.\n",
    "data = data.sort_values(by=['ts_ind']).reset_index(drop=True)\n",
    "data = data.reset_index().rename(columns={'index':'obs_ind'})\n",
    "data = data.merge(data.groupby('ts_ind').agg({'obs_ind':'min'}).reset_index().rename(columns={ \\\n",
    "                                                            'obs_ind':'first_obs_ind'}), on='ts_ind')\n",
    "data['obs_ind'] = data['obs_ind'] - data['first_obs_ind']\n",
    "# Find max_len.\n",
    "max_len = data.obs_ind.max()+1\n",
    "print ('max_len', max_len)\n",
    "# Generate times_ip and values_ip matrices.\n",
    "times_inp = np.zeros((N, max_len), dtype='float32')\n",
    "values_inp = np.zeros((N, max_len), dtype='float32')\n",
    "varis_inp = np.zeros((N, max_len), dtype='int32')\n",
    "for row in tqdm(data.itertuples()):\n",
    "    ts_ind = row.ts_ind\n",
    "    l = row.obs_ind\n",
    "    times_inp[ts_ind, l] = row.hour\n",
    "    values_inp[ts_ind, l] = row.value\n",
    "    varis_inp[ts_ind, l] = row.vind\n",
    "data.drop(columns=['obs_ind', 'first_obs_ind'], inplace=True)\n",
    "# Generate 3 sets of inputs and outputs.\n",
    "train_ip = [ip[train_ind] for ip in [demo, times_inp, values_inp, varis_inp]]\n",
    "valid_ip = [ip[valid_ind] for ip in [demo, times_inp, values_inp, varis_inp]]\n",
    "test_ip = [ip[test_ind] for ip in [demo, times_inp, values_inp, varis_inp]]\n",
    "del times_inp, values_inp, varis_inp\n",
    "# train_op = y[train_ind]\n",
    "# valid_op = y[valid_ind]\n",
    "# test_op = y[test_ind]\n",
    "# del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ip.append(train_text)\n",
    "valid_ip.append(valid_text)\n",
    "test_ip.append(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_path = 'Data/sepsis_removed_0.pkl'\n",
    "pkl = pickle.load(open(data_path, 'rb'))\n",
    "data = pkl[0]\n",
    "oc = pkl[1]\n",
    "train_ind = pkl[2]\n",
    "valid_ind = pkl[3]\n",
    "test_ind = pkl[4]\n",
    "del pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_ind</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>in_hospital_sepsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>110404</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>188028</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>173727</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>164716</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>158689</td>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54862</th>\n",
       "      <td>57277</td>\n",
       "      <td>182476</td>\n",
       "      <td>83967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29333</th>\n",
       "      <td>57278</td>\n",
       "      <td>118320</td>\n",
       "      <td>23200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54573</th>\n",
       "      <td>57279</td>\n",
       "      <td>146497</td>\n",
       "      <td>73807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14317</th>\n",
       "      <td>57280</td>\n",
       "      <td>118512</td>\n",
       "      <td>10762</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4430</th>\n",
       "      <td>57281</td>\n",
       "      <td>122737</td>\n",
       "      <td>4094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57282 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ts_ind  HADM_ID  SUBJECT_ID  in_hospital_sepsis\n",
       "0           0   110404         268                   1\n",
       "1           1   188028         270                   0\n",
       "2           2   173727         271                   0\n",
       "3           3   164716         272                   0\n",
       "4           4   158689         273                   0\n",
       "...       ...      ...         ...                 ...\n",
       "54862   57277   182476       83967                   0\n",
       "29333   57278   118320       23200                   0\n",
       "54573   57279   146497       73807                   0\n",
       "14317   57280   118512       10762                   0\n",
       "4430    57281   122737        4094                   0\n",
       "\n",
       "[57282 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oc = oc.sort_values(by='ts_ind')\n",
    "oc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ts_ind</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>in_hospital_sepsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110404</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>188028</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>173727</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>164716</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>158689</td>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57277</th>\n",
       "      <td>54862</td>\n",
       "      <td>57277</td>\n",
       "      <td>182476</td>\n",
       "      <td>83967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57278</th>\n",
       "      <td>29333</td>\n",
       "      <td>57278</td>\n",
       "      <td>118320</td>\n",
       "      <td>23200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57279</th>\n",
       "      <td>54573</td>\n",
       "      <td>57279</td>\n",
       "      <td>146497</td>\n",
       "      <td>73807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57280</th>\n",
       "      <td>14317</td>\n",
       "      <td>57280</td>\n",
       "      <td>118512</td>\n",
       "      <td>10762</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57281</th>\n",
       "      <td>4430</td>\n",
       "      <td>57281</td>\n",
       "      <td>122737</td>\n",
       "      <td>4094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57282 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  ts_ind  HADM_ID  SUBJECT_ID  in_hospital_sepsis\n",
       "0          0       0   110404         268                   1\n",
       "1          1       1   188028         270                   0\n",
       "2          2       2   173727         271                   0\n",
       "3          3       3   164716         272                   0\n",
       "4          4       4   158689         273                   0\n",
       "...      ...     ...      ...         ...                 ...\n",
       "57277  54862   57277   182476       83967                   0\n",
       "57278  29333   57278   118320       23200                   0\n",
       "57279  54573   57279   146497       73807                   0\n",
       "57280  14317   57280   118512       10762                   0\n",
       "57281   4430   57281   122737        4094                   0\n",
       "\n",
       "[57282 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_oc = oc.reset_index()\n",
    "reset_oc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_op = reset_oc['in_hospital_sepsis'][train_ind]\n",
    "valid_op = reset_oc['in_hospital_sepsis'][valid_ind]\n",
    "test_op = reset_oc['in_hospital_sepsis'][test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_op = train_op.to_numpy(dtype='float32')\n",
    "valid_op = valid_op.to_numpy(dtype='float32')\n",
    "test_op = test_op.to_numpy(dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_res(y_true, y_pred):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    minrp = np.minimum(precision, recall).max()\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    return [roc_auc, pr_auc, minrp]\n",
    "\n",
    "######################################################################################################## \n",
    "######################################################################################################## \n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=[0,1], y=train_op)\n",
    "def mortality_loss(y_true, y_pred):\n",
    "    sample_weights = (1-y_true)*class_weights[0] + y_true*class_weights[1]\n",
    "    bce = K.binary_crossentropy(y_true, y_pred)\n",
    "    return K.mean(sample_weights*bce, axis=-1)\n",
    "######################################################################################################## \n",
    "######################################################################################################## \n",
    "\n",
    "# var_weights = np.sum(fore_train_op[:, V:], axis=0)\n",
    "# var_weights[var_weights==0] = var_weights.max()\n",
    "# var_weights = var_weights.max()/var_weights\n",
    "# var_weights = var_weights.reshape((1, V))\n",
    "def forecast_loss(y_true, y_pred):\n",
    "    return K.sum(y_true[:,V:]*(y_true[:,:V]-y_pred)**2, axis=-1)\n",
    "\n",
    "def get_min_loss(weight):\n",
    "    def min_loss(y_true, y_pred):\n",
    "        return weight*y_pred\n",
    "    return min_loss\n",
    "\n",
    "class CustomCallback(Callback):\n",
    "    def __init__(self, validation_data, batch_size):\n",
    "        self.val_x, self.val_y = validation_data\n",
    "        self.batch_size = batch_size\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.val_x, verbose=0, batch_size=self.batch_size)\n",
    "        if type(y_pred)==type([]):\n",
    "            y_pred = y_pred[0]\n",
    "        precision, recall, thresholds = precision_recall_curve(self.val_y, y_pred)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        roc_auc = roc_auc_score(self.val_y, y_pred)\n",
    "        logs['custom_metric'] = pr_auc + roc_auc\n",
    "        print ('val_aucs:', pr_auc, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Embedding, Activation, Dropout, Softmax, Layer, InputSpec, Input, Dense, Lambda, TimeDistributed, Concatenate, Add\n",
    "from tensorflow.keras import initializers, regularizers, constraints, Model\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow import nn\n",
    "\n",
    "    \n",
    "class CVE(Layer):\n",
    "    def __init__(self, hid_units, output_dim):\n",
    "        self.hid_units = hid_units\n",
    "        self.output_dim = output_dim\n",
    "        super(CVE, self).__init__()\n",
    "        \n",
    "    def build(self, input_shape): \n",
    "        self.W1 = self.add_weight(name='CVE_W1',\n",
    "                            shape=(1, self.hid_units),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        self.b1 = self.add_weight(name='CVE_b1',\n",
    "                            shape=(self.hid_units,),\n",
    "                            initializer='zeros',\n",
    "                            trainable=True)\n",
    "        self.W2 = self.add_weight(name='CVE_W2',\n",
    "                            shape=(self.hid_units, self.output_dim),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        super(CVE, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = K.expand_dims(x, axis=-1)\n",
    "        x = K.dot(K.tanh(K.bias_add(K.dot(x, self.W1), self.b1)), self.W2)\n",
    "        return x\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape + (self.output_dim,)\n",
    "    \n",
    "    \n",
    "class Attention(Layer):\n",
    "    \n",
    "    def __init__(self, hid_dim):\n",
    "        self.hid_dim = hid_dim\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        self.W = self.add_weight(shape=(d, self.hid_dim), name='Att_W',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.hid_dim,), name='Att_b',\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        self.u = self.add_weight(shape=(self.hid_dim,1), name='Att_u',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask, mask_value=-1e30):\n",
    "        attn_weights = K.dot(K.tanh(K.bias_add(K.dot(x,self.W), self.b)), self.u)\n",
    "        mask = K.expand_dims(mask, axis=-1)\n",
    "        attn_weights = mask*attn_weights + (1-mask)*mask_value\n",
    "        attn_weights = K.softmax(attn_weights, axis=-2)\n",
    "        return attn_weights\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1] + (1,)\n",
    "    \n",
    "    \n",
    "class Transformer(Layer):\n",
    "    \n",
    "    def __init__(self, N=2, h=8, dk=None, dv=None, dff=None, dropout=0):\n",
    "        self.N, self.h, self.dk, self.dv, self.dff, self.dropout = N, h, dk, dv, dff, dropout\n",
    "        self.epsilon = K.epsilon() * K.epsilon()\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        if self.dk==None:\n",
    "            self.dk = d//self.h\n",
    "        if self.dv==None:\n",
    "            self.dv = d//self.h\n",
    "        if self.dff==None:\n",
    "            self.dff = 2*d\n",
    "        self.Wq = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wq',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wk = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wk',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wv = self.add_weight(shape=(self.N, self.h, d, self.dv), name='Wv',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wo = self.add_weight(shape=(self.N, self.dv*self.h, d), name='Wo',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.W1 = self.add_weight(shape=(self.N, d, self.dff), name='W1',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b1 = self.add_weight(shape=(self.N, self.dff), name='b1',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.W2 = self.add_weight(shape=(self.N, self.dff, d), name='W2',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b2 = self.add_weight(shape=(self.N, d), name='b2',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.gamma = self.add_weight(shape=(2*self.N,), name='gamma',\n",
    "                                 initializer='ones', trainable=True)\n",
    "        self.beta = self.add_weight(shape=(2*self.N,), name='beta',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        super(Transformer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask, mask_value=-1e-30):\n",
    "        mask = K.expand_dims(mask, axis=-2)\n",
    "        for i in range(self.N):\n",
    "            # MHA\n",
    "            mha_ops = []\n",
    "            for j in range(self.h):\n",
    "                q = K.dot(x, self.Wq[i,j,:,:])\n",
    "                k = K.permute_dimensions(K.dot(x, self.Wk[i,j,:,:]), (0,2,1))\n",
    "                v = K.dot(x, self.Wv[i,j,:,:])\n",
    "                A = K.batch_dot(q,k)\n",
    "                # Mask unobserved steps.\n",
    "                A = mask*A + (1-mask)*mask_value\n",
    "                # Mask for attention dropout.\n",
    "                def dropped_A():\n",
    "                    dp_mask = K.cast((K.random_uniform(shape=array_ops.shape(A))>=self.dropout), K.floatx())\n",
    "                    return A*dp_mask + (1-dp_mask)*mask_value\n",
    "                A = sc.smart_cond(K.learning_phase(), dropped_A, lambda: array_ops.identity(A))\n",
    "                A = K.softmax(A, axis=-1)\n",
    "                mha_ops.append(K.batch_dot(A,v))\n",
    "            conc = K.concatenate(mha_ops, axis=-1)\n",
    "            proj = K.dot(conc, self.Wo[i,:,:])\n",
    "            # Dropout.\n",
    "            proj = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(proj, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(proj))\n",
    "            # Add & LN\n",
    "            x = x+proj\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i] + self.beta[2*i]\n",
    "            # FFN\n",
    "            ffn_op = K.bias_add(K.dot(K.relu(K.bias_add(K.dot(x, self.W1[i,:,:]), self.b1[i,:])), \n",
    "                           self.W2[i,:,:]), self.b2[i,:,])\n",
    "            # Dropout.\n",
    "            ffn_op = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(ffn_op, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(ffn_op))\n",
    "            # Add & LN\n",
    "            x = x+ffn_op\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i+1] + self.beta[2*i+1]            \n",
    "        return x\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "\n",
    "def build_strats(D, max_len, V, d, N, he, dropout, forecast=False):\n",
    "    # demo\n",
    "    demo = Input(shape=(D,))\n",
    "    demo_enc = Dense(2*d, activation='tanh')(demo)\n",
    "    demo_enc = Dense(d, activation='tanh')(demo_enc)\n",
    "    \n",
    "    # text\n",
    "    texts = Input(shape=(33792,))\n",
    "    text_enc = Dense(1000, activation='relu')(texts)\n",
    "    text_enc = Dense(d, activation='relu')(text_enc)\n",
    "    \n",
    "    # triplet\n",
    "    varis = Input(shape=(max_len,))\n",
    "    values = Input(shape=(max_len,))\n",
    "    times = Input(shape=(max_len,))\n",
    "    \n",
    "    varis_emb = Embedding(V+1, d)(varis)\n",
    "    cve_units = int(np.sqrt(d))\n",
    "    values_emb = CVE(cve_units, d)(values)\n",
    "    times_emb = CVE(cve_units, d)(times)\n",
    "    \n",
    "    # comb_emb = Add()([varis_emb, values_emb, times_emb]) # b, L, d\n",
    "    comb_emb = Add()([varis_emb, values_emb, times_emb, text_enc]) # b, L, d\n",
    "#     demo_enc = Lambda(lambda x:K.expand_dims(x, axis=-2))(demo_enc) # b, 1, d\n",
    "#     comb_emb = Concatenate(axis=-2)([demo_enc, comb_emb]) # b, L+1, d\n",
    "    mask = Lambda(lambda x:K.clip(x,0,1))(varis) # b, L\n",
    "#     mask = Lambda(lambda x:K.concatenate((K.ones_like(x)[:,0:1], x), axis=-1))(mask) # b, L+1\n",
    "    cont_emb = Transformer(N, he, dk=None, dv=None, dff=None, dropout=dropout)(comb_emb, mask=mask)\n",
    "    attn_weights = Attention(2*d)(cont_emb, mask=mask)\n",
    "    fused_emb = Lambda(lambda x:K.sum(x[0]*x[1], axis=-2))([cont_emb, attn_weights])\n",
    "    \n",
    "#     # embed text input\n",
    "#     texts = Input(shape=(33792,))\n",
    "#     text_enc = Dense(1000, activation='relu')(texts)\n",
    "#     text_enc = Dense(d, activation='relu')(text_enc)\n",
    "    \n",
    "    conc = Concatenate(axis=-1)([fused_emb, text_enc, demo_enc])\n",
    "    fore_op = Dense(V)(conc)\n",
    "    op = Dense(1, activation='sigmoid')(fore_op)\n",
    "    model = Model([demo, times, values, varis, texts], op)\n",
    "    if forecast:\n",
    "        fore_model = Model([demo, times, values, varis, texts], fore_op)\n",
    "        return [model, fore_model]\n",
    "    return model\n",
    "\n",
    "# To tune:\n",
    "# 1. Transformer parameters. (N, h, dropout)\n",
    "# 2. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 0 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_10ld.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 01:46:00.165563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30503 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b2:00.0, compute capability: 7.0\n",
      "2023-11-20 01:46:00.166281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30503 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b3:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 01:46:08.984993: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x564f7e9b1160 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-20 01:46:08.985034: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2023-11-20 01:46:08.985040: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2023-11-20 01:46:08.992708: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-20 01:46:09.327521: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
      "2023-11-20 01:46:09.699668: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - ETA: 0s - loss: 0.5646val_aucs: 0.3814584972827368 0.8482869457228432\n",
      "115/115 [==============================] - 19s 76ms/step - loss: 0.5646 - custom_metric: 1.2297\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4717val_aucs: 0.42378426647047723 0.8559427277375996\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.4717 - custom_metric: 1.2797\n",
      "Epoch 3/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4208val_aucs: 0.4648429104060732 0.8683760683760684\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.4208 - custom_metric: 1.3332\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3813val_aucs: 0.45041641464534976 0.8656731682372708\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3813 - custom_metric: 1.3161\n",
      "Epoch 5/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3631val_aucs: 0.547498824659415 0.8759149682226605\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.3631 - custom_metric: 1.4234\n",
      "Epoch 6/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3474val_aucs: 0.5050320887336899 0.8622689750894879\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3474 - custom_metric: 1.3673\n",
      "Epoch 7/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2718val_aucs: 0.4513612432139294 0.8502739425816349\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.2718 - custom_metric: 1.3016\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2390val_aucs: 0.4916281087705608 0.8568777850829132\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2390 - custom_metric: 1.3485\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2059val_aucs: 0.44461313620876447 0.8536927460004384\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2059 - custom_metric: 1.2983\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1732val_aucs: 0.4246033987908914 0.8359120461684564\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1732 - custom_metric: 1.2605\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1835val_aucs: 0.4303920433940776 0.8502155014975528\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.1835 - custom_metric: 1.2806\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1719val_aucs: 0.41075138354124147 0.8370516473080576\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1719 - custom_metric: 1.2478\n",
      "Epoch 13/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1049val_aucs: 0.425932234236223 0.839111695521952\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1049 - custom_metric: 1.2650\n",
      "Epoch 14/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1354val_aucs: 0.4498003108236927 0.8466359850975236\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1354 - custom_metric: 1.2964\n",
      "Epoch 15/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1085val_aucs: 0.41781922164057933 0.8419606983709548\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1085 - custom_metric: 1.2598\n",
      "Test res 0.8683559624072523 0.43019719307940774 0.4365234375\n",
      "[[0.8683559624072523, 0.43019719307940774, 0.4365234375]]\n",
      "Repeat 1 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_10ld.h5\n",
      "Epoch 1/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.5612val_aucs: 0.5286955526985513 0.8985441679716955\n",
      "115/115 [==============================] - 15s 68ms/step - loss: 0.5612 - custom_metric: 1.4272\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4718val_aucs: 0.5389682566571313 0.9038222840902499\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.4718 - custom_metric: 1.4428\n",
      "Epoch 3/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4353val_aucs: 0.5637250680334444 0.9146569224522939\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.4353 - custom_metric: 1.4784\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4075val_aucs: 0.561687634192892 0.9150977321501073\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.4075 - custom_metric: 1.4768\n",
      "Epoch 5/1000\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.3763val_aucs: 0.584269386464177 0.9140305086711908\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3762 - custom_metric: 1.4983\n",
      "Epoch 6/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3282val_aucs: 0.5562547059253946 0.910654834406357\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.3282 - custom_metric: 1.4669\n",
      "Epoch 7/1000\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.2855val_aucs: 0.5850715867728409 0.9078011716257758\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2851 - custom_metric: 1.4929\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2451val_aucs: 0.5492622111457848 0.8931036482802621\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2451 - custom_metric: 1.4424\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2350val_aucs: 0.5910658274533344 0.9078359723913926\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.2350 - custom_metric: 1.4989\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2259val_aucs: 0.5744945502892934 0.9085435879589352\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.2259 - custom_metric: 1.4830\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2058val_aucs: 0.5389086316793661 0.8945420799257584\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2058 - custom_metric: 1.4335\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1468val_aucs: 0.5806690022560587 0.901235427179398\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.1468 - custom_metric: 1.4819\n",
      "Epoch 13/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2062val_aucs: 0.5626069625579265 0.8897047735050171\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2062 - custom_metric: 1.4523\n",
      "Epoch 14/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1280val_aucs: 0.5754545185472718 0.8967113276492084\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.1280 - custom_metric: 1.4722\n",
      "Epoch 15/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1147val_aucs: 0.526894646831031 0.8944492778841134\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.1147 - custom_metric: 1.4213\n",
      "Epoch 16/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0882val_aucs: 0.5586506582753362 0.8978945536801809\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.0882 - custom_metric: 1.4565\n",
      "Epoch 17/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0846val_aucs: 0.5193999281473336 0.8982077605707325\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.0846 - custom_metric: 1.4176\n",
      "Epoch 18/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1413val_aucs: 0.5233325418451944 0.8718751812539876\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.1413 - custom_metric: 1.3952\n",
      "Epoch 19/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0955val_aucs: 0.5047386866670105 0.8677454904007889\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.0955 - custom_metric: 1.3725\n",
      "Test res 0.8453729449646961 0.4006637702595039 0.4230396902226525\n",
      "[[0.8683559624072523, 0.43019719307940774, 0.4365234375], [0.8453729449646961, 0.4006637702595039, 0.4230396902226525]]\n",
      "Repeat 2 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_10ld.h5\n",
      "Epoch 1/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.5230val_aucs: 0.39529474712388973 0.8492316784869977\n",
      "115/115 [==============================] - 14s 67ms/step - loss: 0.5230 - custom_metric: 1.2445\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4303val_aucs: 0.4219279664811572 0.8600325059101656\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.4303 - custom_metric: 1.2820\n",
      "Epoch 3/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3979val_aucs: 0.37428515348628355 0.8431442080378251\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3979 - custom_metric: 1.2174\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3674val_aucs: 0.39145337935207036 0.8471187943262412\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.3674 - custom_metric: 1.2386\n",
      "Epoch 5/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3254val_aucs: 0.38121998666724716 0.8429816784869978\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.3254 - custom_metric: 1.2242\n",
      "Epoch 6/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3083val_aucs: 0.36260681423251995 0.8326241134751772\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3083 - custom_metric: 1.1952\n",
      "Epoch 7/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2539val_aucs: 0.30869846078008717 0.8220744680851064\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2539 - custom_metric: 1.1308\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2399val_aucs: 0.35139698256181184 0.821764184397163\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2399 - custom_metric: 1.1732\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1963val_aucs: 0.3656573414693985 0.8383274231678487\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1963 - custom_metric: 1.2040\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2125val_aucs: 0.3697843332201156 0.839982269503546\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2125 - custom_metric: 1.2098\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1849val_aucs: 0.325183138797495 0.830008865248227\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1849 - custom_metric: 1.1552\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1568val_aucs: 0.27287271816248804 0.8057180851063829\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1568 - custom_metric: 1.0786\n",
      "Test res 0.8722779196834609 0.4407442940652385 0.4501953125\n",
      "[[0.8683559624072523, 0.43019719307940774, 0.4365234375], [0.8453729449646961, 0.4006637702595039, 0.4230396902226525], [0.8722779196834609, 0.4407442940652385, 0.4501953125]]\n",
      "Repeat 3 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_10ld.h5\n",
      "Epoch 1/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.5081val_aucs: 0.503567045793171 0.8607233153786962\n",
      "115/115 [==============================] - 15s 69ms/step - loss: 0.5081 - custom_metric: 1.3643\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4113val_aucs: 0.5366675306477613 0.8702502656553441\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.4113 - custom_metric: 1.4069\n",
      "Epoch 3/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3896val_aucs: 0.5314851616027093 0.8662196328459932\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3896 - custom_metric: 1.3977\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3565val_aucs: 0.5379355953941503 0.8740976878824521\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3565 - custom_metric: 1.4120\n",
      "Epoch 5/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3446val_aucs: 0.5586149809289358 0.8770046291207114\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3446 - custom_metric: 1.4356\n",
      "Epoch 6/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3051val_aucs: 0.5217454097770129 0.8623111404248044\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.3051 - custom_metric: 1.3841\n",
      "Epoch 7/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2936val_aucs: 0.5168510096341513 0.868931149463193\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2936 - custom_metric: 1.3858\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2618val_aucs: 0.5022703866933063 0.8676364613486742\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2618 - custom_metric: 1.3699\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2234val_aucs: 0.5145271195554876 0.865413506284123\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2234 - custom_metric: 1.3799\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2038val_aucs: 0.4831066650869306 0.862860772171534\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.2038 - custom_metric: 1.3460\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1624val_aucs: 0.481465847240297 0.8610286663491017\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1624 - custom_metric: 1.3425\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1347val_aucs: 0.4985131465881762 0.8595263395747073\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1347 - custom_metric: 1.3580\n",
      "Epoch 13/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1190val_aucs: 0.45949431947151326 0.8429763169787353\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1190 - custom_metric: 1.3025\n",
      "Epoch 14/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1341val_aucs: 0.4293905447335489 0.845907686294627\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1341 - custom_metric: 1.2753\n",
      "Epoch 15/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1573val_aucs: 0.4564518153501077 0.850671161432951\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1573 - custom_metric: 1.3071\n",
      "Test res 0.8747494315461943 0.4511574823419411 0.458984375\n",
      "[[0.8683559624072523, 0.43019719307940774, 0.4365234375], [0.8453729449646961, 0.4006637702595039, 0.4230396902226525], [0.8722779196834609, 0.4407442940652385, 0.4501953125], [0.8747494315461943, 0.4511574823419411, 0.458984375]]\n",
      "Repeat 4 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_10ld.h5\n",
      "Epoch 1/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.5297val_aucs: 0.4125731525886806 0.8658627699685507\n",
      "115/115 [==============================] - 14s 67ms/step - loss: 0.5297 - custom_metric: 1.2784\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4129val_aucs: 0.49352752468933614 0.8688165690754609\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.4129 - custom_metric: 1.3623\n",
      "Epoch 3/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3618val_aucs: 0.5109041208523708 0.879015863638733\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.3618 - custom_metric: 1.3899\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3308val_aucs: 0.48388614084101045 0.8817437839904089\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.3308 - custom_metric: 1.3656\n",
      "Epoch 5/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3077val_aucs: 0.46480027442304395 0.8786509825725852\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3077 - custom_metric: 1.3435\n",
      "Epoch 6/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2685val_aucs: 0.4551527129872034 0.8780775980400675\n",
      "115/115 [==============================] - 6s 54ms/step - loss: 0.2685 - custom_metric: 1.3332\n",
      "Epoch 7/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2297val_aucs: 0.4621372928594952 0.8708842284502979\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.2297 - custom_metric: 1.3330\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2143val_aucs: 0.4202809160760523 0.8803885114590029\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2143 - custom_metric: 1.3007\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1759val_aucs: 0.4556345684216913 0.88636561082828\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.1759 - custom_metric: 1.3420\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1593val_aucs: 0.39412308852331157 0.8601115493545081\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1593 - custom_metric: 1.2542\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1700val_aucs: 0.4043838037982876 0.8569839973589561\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.1700 - custom_metric: 1.2614\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1394val_aucs: 0.4078144811110251 0.8571403749587336\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1394 - custom_metric: 1.2650\n",
      "Epoch 13/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1491val_aucs: 0.44433606690147653 0.8568449950480427\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1491 - custom_metric: 1.3012\n",
      "Test res 0.8742354857288176 0.4747078282695076 0.490234375\n",
      "[[0.8683559624072523, 0.43019719307940774, 0.4365234375], [0.8453729449646961, 0.4006637702595039, 0.4230396902226525], [0.8722779196834609, 0.4407442940652385, 0.4501953125], [0.8747494315461943, 0.4511574823419411, 0.458984375], [0.8742354857288176, 0.4747078282695076, 0.490234375]]\n",
      "Repeat 5 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_10ld.h5\n",
      "Epoch 1/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.5219val_aucs: 0.516768058610468 0.8935349502119689\n",
      "115/115 [==============================] - 14s 67ms/step - loss: 0.5219 - custom_metric: 1.4103\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4459val_aucs: 0.5290246517451347 0.8891600118308193\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.4459 - custom_metric: 1.4182\n",
      "Epoch 3/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3902val_aucs: 0.5223838237177493 0.889369515922311\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.3902 - custom_metric: 1.4118\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3609val_aucs: 0.498500053996839 0.8886054421768708\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3609 - custom_metric: 1.3871\n",
      "Epoch 5/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3225val_aucs: 0.48610244798429153 0.882394262052647\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3225 - custom_metric: 1.3685\n",
      "Epoch 6/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2846val_aucs: 0.4434951536264147 0.8580055210489993\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2846 - custom_metric: 1.3015\n",
      "Epoch 7/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2586val_aucs: 0.4638986505804021 0.8671004633737553\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2586 - custom_metric: 1.3310\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2148val_aucs: 0.43474231922146833 0.8561816030760129\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2148 - custom_metric: 1.2909\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1779val_aucs: 0.40516543209272826 0.8301661244207827\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.1779 - custom_metric: 1.2353\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1604val_aucs: 0.4721338799756186 0.8568224391205759\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.1604 - custom_metric: 1.3290\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1548val_aucs: 0.38836500731748486 0.8442275460909001\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1548 - custom_metric: 1.2326\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1291val_aucs: 0.4364281673460567 0.8411712511091394\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1291 - custom_metric: 1.2776\n",
      "Test res 0.8616695712661561 0.4370282946398207 0.45445736434108525\n",
      "[[0.8683559624072523, 0.43019719307940774, 0.4365234375], [0.8453729449646961, 0.4006637702595039, 0.4230396902226525], [0.8722779196834609, 0.4407442940652385, 0.4501953125], [0.8747494315461943, 0.4511574823419411, 0.458984375], [0.8742354857288176, 0.4747078282695076, 0.490234375], [0.8616695712661561, 0.4370282946398207, 0.45445736434108525]]\n",
      "Repeat 6 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_10ld.h5\n",
      "Epoch 1/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.5295val_aucs: 0.3621503979710132 0.8373424536069415\n",
      "115/115 [==============================] - 15s 68ms/step - loss: 0.5295 - custom_metric: 1.1995\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4592val_aucs: 0.37610127244896824 0.8399265311292672\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.4592 - custom_metric: 1.2160\n",
      "Epoch 3/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4056val_aucs: 0.3819589489787367 0.8180378744695673\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.4056 - custom_metric: 1.2000\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3905val_aucs: 0.3822857667760935 0.8445120020267275\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3905 - custom_metric: 1.2268\n",
      "Epoch 5/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3360val_aucs: 0.34459862018810106 0.818709227943505\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.3360 - custom_metric: 1.1633\n",
      "Epoch 6/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3168val_aucs: 0.41441774745792404 0.8330483247830769\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3168 - custom_metric: 1.2475\n",
      "Epoch 7/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2792val_aucs: 0.4129198483045318 0.8521122300335677\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.2792 - custom_metric: 1.2650\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2533val_aucs: 0.3611491950864227 0.805117486857939\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2533 - custom_metric: 1.1663\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2212val_aucs: 0.3489493992833983 0.8426879473050859\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2212 - custom_metric: 1.1916\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1852val_aucs: 0.3831548517369619 0.8491228070175438\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1852 - custom_metric: 1.2323\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1470val_aucs: 0.340441091333396 0.8393691810754322\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1470 - custom_metric: 1.1798\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1217val_aucs: 0.35994185228762465 0.8365824308062575\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1217 - custom_metric: 1.1965\n",
      "Epoch 13/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1486val_aucs: 0.3197353685146868 0.8142250934194692\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1486 - custom_metric: 1.1340\n",
      "Epoch 14/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1445val_aucs: 0.3583036522006537 0.8434733041991259\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.1445 - custom_metric: 1.2018\n",
      "Epoch 15/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1316val_aucs: 0.36352637506176866 0.8334283361834188\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1316 - custom_metric: 1.1970\n",
      "Epoch 16/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0886val_aucs: 0.3704761183879051 0.8183418835898411\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.0886 - custom_metric: 1.1888\n",
      "Epoch 17/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1418val_aucs: 0.37862626535301513 0.8264994616505162\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1418 - custom_metric: 1.2051\n",
      "Test res 0.8450383706318813 0.4103874809551794 0.418426103646833\n",
      "[[0.8683559624072523, 0.43019719307940774, 0.4365234375], [0.8453729449646961, 0.4006637702595039, 0.4230396902226525], [0.8722779196834609, 0.4407442940652385, 0.4501953125], [0.8747494315461943, 0.4511574823419411, 0.458984375], [0.8742354857288176, 0.4747078282695076, 0.490234375], [0.8616695712661561, 0.4370282946398207, 0.45445736434108525], [0.8450383706318813, 0.4103874809551794, 0.418426103646833]]\n",
      "Repeat 7 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_10ld.h5\n",
      "Epoch 1/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.5276val_aucs: 0.549766903267866 0.8746338685181168\n",
      "115/115 [==============================] - 14s 67ms/step - loss: 0.5276 - custom_metric: 1.4244\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4464val_aucs: 0.5191076714592888 0.876491646778043\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.4464 - custom_metric: 1.3956\n",
      "Epoch 3/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3967val_aucs: 0.48777186561249486 0.8845058581037101\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3967 - custom_metric: 1.3723\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3745val_aucs: 0.5272071633798235 0.8760441527446301\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3745 - custom_metric: 1.4033\n",
      "Epoch 5/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3390val_aucs: 0.4957424049842838 0.8691961379908876\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3390 - custom_metric: 1.3649\n",
      "Epoch 6/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3034val_aucs: 0.47853980467955376 0.8692503796919072\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.3034 - custom_metric: 1.3478\n",
      "Epoch 7/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2711val_aucs: 0.5256647542925996 0.8792850943805598\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.2711 - custom_metric: 1.4049\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2468val_aucs: 0.4981679445369068 0.86546702104578\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2468 - custom_metric: 1.3636\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2241val_aucs: 0.4620552423394605 0.8608564764591017\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2241 - custom_metric: 1.3229\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2040val_aucs: 0.4696499786337728 0.8700233239314386\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2040 - custom_metric: 1.3397\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1290val_aucs: 0.47415672193685104 0.8553238229550878\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1290 - custom_metric: 1.3295\n",
      "Test res 0.8556092740246529 0.40546831407696865 0.4296875\n",
      "[[0.8683559624072523, 0.43019719307940774, 0.4365234375], [0.8453729449646961, 0.4006637702595039, 0.4230396902226525], [0.8722779196834609, 0.4407442940652385, 0.4501953125], [0.8747494315461943, 0.4511574823419411, 0.458984375], [0.8742354857288176, 0.4747078282695076, 0.490234375], [0.8616695712661561, 0.4370282946398207, 0.45445736434108525], [0.8450383706318813, 0.4103874809551794, 0.418426103646833], [0.8556092740246529, 0.40546831407696865, 0.4296875]]\n",
      "Repeat 8 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_10ld.h5\n",
      "Epoch 1/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.5218val_aucs: 0.46472062750680887 0.8652436702836475\n",
      "115/115 [==============================] - 15s 67ms/step - loss: 0.5218 - custom_metric: 1.3300\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4326val_aucs: 0.47210348539094626 0.8733342851703789\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.4326 - custom_metric: 1.3454\n",
      "Epoch 3/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3887val_aucs: 0.4706242748400145 0.8593184846754236\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3887 - custom_metric: 1.3299\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3474val_aucs: 0.5085882376861588 0.8744764896249763\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.3474 - custom_metric: 1.3831\n",
      "Epoch 5/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3188val_aucs: 0.47813213798715376 0.8556182181610508\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.3188 - custom_metric: 1.3338\n",
      "Epoch 6/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2827val_aucs: 0.4795284136248812 0.8630901389682086\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2827 - custom_metric: 1.3426\n",
      "Epoch 7/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2592val_aucs: 0.4866515197851835 0.8606867504283267\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2592 - custom_metric: 1.3473\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2195val_aucs: 0.46382960492076336 0.8528816866552447\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2195 - custom_metric: 1.3167\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2275val_aucs: 0.47741253527627053 0.8471706643822579\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2275 - custom_metric: 1.3246\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1753val_aucs: 0.5002150373302363 0.8379497430039977\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1753 - custom_metric: 1.3382\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1296val_aucs: 0.456483881625 0.8215900437845041\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.1296 - custom_metric: 1.2781\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1470val_aucs: 0.4826674989850798 0.8429052446221208\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.1470 - custom_metric: 1.3256\n",
      "Epoch 13/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1347val_aucs: 0.42231000656413115 0.8106439177612792\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1347 - custom_metric: 1.2330\n",
      "Epoch 14/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0859val_aucs: 0.41457055941491516 0.8040405482581382\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.0859 - custom_metric: 1.2186\n",
      "Test res 0.8623864962302538 0.4254920656105917 0.4406614785992218\n",
      "[[0.8683559624072523, 0.43019719307940774, 0.4365234375], [0.8453729449646961, 0.4006637702595039, 0.4230396902226525], [0.8722779196834609, 0.4407442940652385, 0.4501953125], [0.8747494315461943, 0.4511574823419411, 0.458984375], [0.8742354857288176, 0.4747078282695076, 0.490234375], [0.8616695712661561, 0.4370282946398207, 0.45445736434108525], [0.8450383706318813, 0.4103874809551794, 0.418426103646833], [0.8556092740246529, 0.40546831407696865, 0.4296875], [0.8623864962302538, 0.4254920656105917, 0.4406614785992218]]\n",
      "Repeat 9 ld 10\n",
      "Num train: 3655 Num valid: 926\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_10ld.h5\n",
      "Epoch 1/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.5505val_aucs: 0.39846805383154793 0.8692763078410052\n",
      "115/115 [==============================] - 15s 68ms/step - loss: 0.5505 - custom_metric: 1.2677\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4585val_aucs: 0.4291414389758022 0.8783778341589144\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.4585 - custom_metric: 1.3075\n",
      "Epoch 3/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.4166val_aucs: 0.4309274801374464 0.8722967258668599\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.4166 - custom_metric: 1.3032\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3875val_aucs: 0.4326790001229261 0.8769548816667337\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3875 - custom_metric: 1.3096\n",
      "Epoch 5/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3582val_aucs: 0.4117318729898126 0.8671821513430792\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3582 - custom_metric: 1.2789\n",
      "Epoch 6/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.3112val_aucs: 0.4092507085508725 0.874833877008578\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.3112 - custom_metric: 1.2841\n",
      "Epoch 7/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2662val_aucs: 0.38647613143887427 0.8514088572080597\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.2662 - custom_metric: 1.2379\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2390val_aucs: 0.36034741588946645 0.8619333360181494\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.2390 - custom_metric: 1.2223\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1935val_aucs: 0.4121866982234045 0.8596780905588445\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1935 - custom_metric: 1.2719\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1555val_aucs: 0.3732529137749172 0.8448981783523284\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.1555 - custom_metric: 1.2182\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2312val_aucs: 0.32063553870163797 0.8330715637710926\n",
      "115/115 [==============================] - 6s 48ms/step - loss: 0.2312 - custom_metric: 1.1537\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1395val_aucs: 0.34886861896711013 0.8424818439316446\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1395 - custom_metric: 1.1914\n",
      "Epoch 13/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.1016val_aucs: 0.34917528366355544 0.8478380518974937\n",
      "115/115 [==============================] - 6s 49ms/step - loss: 0.1016 - custom_metric: 1.1970\n",
      "Epoch 14/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0975val_aucs: 0.3634143259563279 0.8459721047615212\n",
      "115/115 [==============================] - 6s 50ms/step - loss: 0.0975 - custom_metric: 1.2094\n",
      "Test res 0.8465987202309718 0.39978609877669835 0.416015625\n",
      "[[0.8683559624072523, 0.43019719307940774, 0.4365234375], [0.8453729449646961, 0.4006637702595039, 0.4230396902226525], [0.8722779196834609, 0.4407442940652385, 0.4501953125], [0.8747494315461943, 0.4511574823419411, 0.458984375], [0.8742354857288176, 0.4747078282695076, 0.490234375], [0.8616695712661561, 0.4370282946398207, 0.45445736434108525], [0.8450383706318813, 0.4103874809551794, 0.418426103646833], [0.8556092740246529, 0.40546831407696865, 0.4296875], [0.8623864962302538, 0.4254920656105917, 0.4406614785992218], [0.8465987202309718, 0.39978609877669835, 0.416015625]]\n",
      "gen_res {10: [(0.8606294176714337, 0.01132236387503929), (0.4275632822074858, 0.023091554494499296), (0.4418225261809793, 0.021472889284831424)]}\n"
     ]
    }
   ],
   "source": [
    "repeats = {k:10 for k in [10,20,30,40,50,60,70,80,90,100]}\n",
    "lds = [10]\n",
    "batch_size, lr, patience = 32, 0.0005, 10\n",
    "d, N, he, dropout = 50,2,4,0.2\n",
    "\n",
    "# best val model\n",
    "fore_savepath = 'Exp1/Exp_M_Q/models/forecasting/forecasting_25_epochs.h5'\n",
    "\n",
    "f = open('Exp1/Exp_M_Q/logs/log_text_'+ str(lds[0]) +'.csv', 'a+')\n",
    "f.write('\\nTraining on different % of labeled data\\n')\n",
    "\n",
    "train_inds = np.arange(len(train_op))\n",
    "valid_inds = np.arange(len(valid_op))\n",
    "gen_res = {}\n",
    "\n",
    "np.random.seed(2023)\n",
    "for ld in lds:\n",
    "    np.random.shuffle(train_inds)\n",
    "    np.random.shuffle(valid_inds)\n",
    "    train_starts = [int(i) for i in np.linspace(0, len(train_inds)-int(ld*len(train_inds)/100), repeats[ld])]\n",
    "    valid_starts = [int(i) for i in np.linspace(0, len(valid_inds)-int(ld*len(valid_inds)/100), repeats[ld])]\n",
    "    f.write('Training on '+str(ld)+' % of labaled data+\\n'+'val_metric,roc_auc,pr_auc,min_rp,savepath\\n')\n",
    "    all_test_res = []\n",
    "    for i in range(repeats[ld]):\n",
    "        print ('Repeat', i, 'ld', ld)\n",
    "        # Get train and validation data.\n",
    "        curr_train_ind = train_inds[np.arange(train_starts[i], train_starts[i]+int(ld*len(train_inds)/100))]\n",
    "        curr_valid_ind = valid_inds[np.arange(valid_starts[i], valid_starts[i]+int(ld*len(valid_inds)/100))]\n",
    "        curr_train_ip = [ip[curr_train_ind] for ip in train_ip]\n",
    "        curr_valid_ip = [ip[curr_valid_ind] for ip in valid_ip]\n",
    "        curr_train_op = train_op[curr_train_ind]\n",
    "        curr_valid_op = valid_op[curr_valid_ind]\n",
    "        print ('Num train:',len(curr_train_op),'Num valid:',len(curr_valid_op))\n",
    "        # Construct save_path.\n",
    "        savepath = 'Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat'+str(i)+'_'+str(ld)+'ld'+'.h5'\n",
    "        print (savepath)\n",
    "        # Build and compile model.\n",
    "        model, fore_model =  build_strats(D, max_len, V, d, N, he, dropout, forecast=True)\n",
    "        model.compile(loss=mortality_loss, optimizer=Adam(lr))\n",
    "        fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "        # Load pretrained weights here.\n",
    "        fore_model.load_weights(fore_savepath)\n",
    "        # Train model.\n",
    "        es = EarlyStopping(monitor='custom_metric', patience=patience, mode='max', \n",
    "                           restore_best_weights=True)\n",
    "        cus = CustomCallback(validation_data=(curr_valid_ip, curr_valid_op), batch_size=batch_size)\n",
    "        his = model.fit(curr_train_ip, curr_train_op, batch_size=batch_size, epochs=1000,\n",
    "                        verbose=1, callbacks=[cus, es]).history\n",
    "        model.save_weights(savepath)\n",
    "        # Test and write to log.\n",
    "        rocauc, prauc, minrp = get_res(test_op, model.predict(test_ip, verbose=0, batch_size=batch_size))\n",
    "        f.write(str(np.min(his['custom_metric']))+str(rocauc)+str(prauc)+str(minrp)+savepath+'\\n')\n",
    "        print ('Test res', rocauc, prauc, minrp)\n",
    "        all_test_res.append([rocauc, prauc, minrp])\n",
    "        \n",
    "        # in case of unexpected disconnection\n",
    "        print(all_test_res)\n",
    "        \n",
    "    gen_res[ld] = []\n",
    "    for i in range(len(all_test_res[0])):\n",
    "        nums = [test_res[i] for test_res in all_test_res]\n",
    "        gen_res[ld].append((np.mean(nums), np.std(nums)))\n",
    "    print ('gen_res', gen_res)\n",
    "f.close()\n",
    "\n",
    "# # save to local\n",
    "# log_path = '/content/log.csv'\n",
    "# files.download(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 0 ld 20\n",
      "Num train: 7310 Num valid: 1852\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_20ld.h5\n",
      "Epoch 1/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.5204val_aucs: 0.484422858387274 0.8835501942712568\n",
      "229/229 [==============================] - 20s 58ms/step - loss: 0.5204 - custom_metric: 1.3680\n",
      "Epoch 2/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4484val_aucs: 0.5279554579374925 0.8981237656352864\n",
      "229/229 [==============================] - 11s 50ms/step - loss: 0.4484 - custom_metric: 1.4261\n",
      "Epoch 3/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4158val_aucs: 0.50942355770375 0.8903400069705301\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.4158 - custom_metric: 1.3998\n",
      "Epoch 4/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3894val_aucs: 0.5393268817575275 0.8931701712943242\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3894 - custom_metric: 1.4325\n",
      "Epoch 5/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3629val_aucs: 0.5164236498508344 0.8901689708141322\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3629 - custom_metric: 1.4066\n",
      "Epoch 6/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3276val_aucs: 0.5124121513966792 0.8951322464469659\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3276 - custom_metric: 1.4075\n",
      "Epoch 7/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3083val_aucs: 0.49021340966231186 0.8882133498560714\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3083 - custom_metric: 1.3784\n",
      "Epoch 8/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2845val_aucs: 0.4768916427192705 0.8825852921813886\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2845 - custom_metric: 1.3595\n",
      "Epoch 9/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2561val_aucs: 0.48967059923414724 0.8842375659941396\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2561 - custom_metric: 1.3739\n",
      "Epoch 10/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2363val_aucs: 0.4800639284938448 0.8830725838722586\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2363 - custom_metric: 1.3631\n",
      "Epoch 11/1000\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.2139val_aucs: 0.46521966811085796 0.8714001729724148\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2144 - custom_metric: 1.3366\n",
      "Epoch 12/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1906val_aucs: 0.46865257438562713 0.8556906633621192\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1906 - custom_metric: 1.3243\n",
      "Epoch 13/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1992val_aucs: 0.4551855428947048 0.8739011733725748\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1992 - custom_metric: 1.3291\n",
      "Epoch 14/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1734val_aucs: 0.46197603891862343 0.8752662355264687\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.1734 - custom_metric: 1.3372\n",
      "Test res 0.8778769091820249 0.4587387283117992 0.4582933844678811\n",
      "[[0.8778769091820249, 0.4587387283117992, 0.4582933844678811]]\n",
      "Repeat 1 ld 20\n",
      "Num train: 7310 Num valid: 1852\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_20ld.h5\n",
      "Epoch 1/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.5031val_aucs: 0.4823841738670815 0.883336474337992\n",
      "229/229 [==============================] - 21s 59ms/step - loss: 0.5031 - custom_metric: 1.3657\n",
      "Epoch 2/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4438val_aucs: 0.5240610120211402 0.8998515462008723\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.4438 - custom_metric: 1.4239\n",
      "Epoch 3/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4123val_aucs: 0.5256038097239941 0.9074131016263791\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.4123 - custom_metric: 1.4330\n",
      "Epoch 4/1000\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.3775val_aucs: 0.5401794988546637 0.904698612337205\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3770 - custom_metric: 1.4449\n",
      "Epoch 5/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3686val_aucs: 0.5438895129033423 0.9089538470694426\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3686 - custom_metric: 1.4528\n",
      "Epoch 6/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3398val_aucs: 0.5157737246353674 0.904797801958003\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3398 - custom_metric: 1.4206\n",
      "Epoch 7/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3199val_aucs: 0.5458960003200639 0.9019675914445646\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3199 - custom_metric: 1.4479\n",
      "Epoch 8/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2884val_aucs: 0.5310315239498811 0.9011839934402597\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2884 - custom_metric: 1.4322\n",
      "Epoch 9/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2585val_aucs: 0.5133495472849247 0.892250314927046\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2585 - custom_metric: 1.4056\n",
      "Epoch 10/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2417val_aucs: 0.4977414334954901 0.8893473653583556\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2417 - custom_metric: 1.3871\n",
      "Epoch 11/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2329val_aucs: 0.47427060470438703 0.8872280137939699\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2329 - custom_metric: 1.3615\n",
      "Epoch 12/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2017val_aucs: 0.4613695734873349 0.8641102195066308\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2017 - custom_metric: 1.3255\n",
      "Epoch 13/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1817val_aucs: 0.4893604716521483 0.8835778357486005\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1817 - custom_metric: 1.3729\n",
      "Epoch 14/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1835val_aucs: 0.4683602394752391 0.8678529745314116\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1835 - custom_metric: 1.3362\n",
      "Epoch 15/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1595val_aucs: 0.48522686778798785 0.8868246426693911\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1595 - custom_metric: 1.3721\n",
      "Test res 0.8811266791826232 0.478560401013453 0.4902534113060429\n",
      "[[0.8778769091820249, 0.4587387283117992, 0.4582933844678811], [0.8811266791826232, 0.478560401013453, 0.4902534113060429]]\n",
      "Repeat 2 ld 20\n",
      "Num train: 7310 Num valid: 1852\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_20ld.h5\n",
      "Epoch 1/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4804val_aucs: 0.4512223866447751 0.8708704173546508\n",
      "229/229 [==============================] - 20s 59ms/step - loss: 0.4804 - custom_metric: 1.3221\n",
      "Epoch 2/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4284val_aucs: 0.47219942370672363 0.8767770126052112\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.4284 - custom_metric: 1.3490\n",
      "Epoch 3/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4038val_aucs: 0.49141743219518474 0.8770857664478541\n",
      "229/229 [==============================] - 11s 50ms/step - loss: 0.4038 - custom_metric: 1.3685\n",
      "Epoch 4/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3800val_aucs: 0.4861135056679333 0.8805223309572711\n",
      "229/229 [==============================] - 12s 51ms/step - loss: 0.3800 - custom_metric: 1.3666\n",
      "Epoch 5/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3450val_aucs: 0.4815120871807824 0.8775354731317037\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3450 - custom_metric: 1.3590\n",
      "Epoch 6/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3282val_aucs: 0.4939309459883459 0.8698166270656303\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3282 - custom_metric: 1.3637\n",
      "Epoch 7/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3138val_aucs: 0.47376144340457366 0.8707026163532143\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3138 - custom_metric: 1.3445\n",
      "Epoch 8/1000\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.2895val_aucs: 0.45980519343953974 0.8620071684587813\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.2894 - custom_metric: 1.3218\n",
      "Epoch 9/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2605val_aucs: 0.46623340733745755 0.8714677889197642\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2605 - custom_metric: 1.3377\n",
      "Epoch 10/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2359val_aucs: 0.4506236474518275 0.8587451169908582\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2359 - custom_metric: 1.3094\n",
      "Epoch 11/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2048val_aucs: 0.4695809889275247 0.8512242761064799\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.2048 - custom_metric: 1.3208\n",
      "Epoch 12/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1887val_aucs: 0.45939176845998153 0.8586813526103123\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1887 - custom_metric: 1.3181\n",
      "Epoch 13/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1827val_aucs: 0.44855366056825163 0.8575369497805162\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1827 - custom_metric: 1.3061\n",
      "Test res 0.8777260071355911 0.4590078157607206 0.4580896686159844\n",
      "[[0.8778769091820249, 0.4587387283117992, 0.4582933844678811], [0.8811266791826232, 0.478560401013453, 0.4902534113060429], [0.8777260071355911, 0.4590078157607206, 0.4580896686159844]]\n",
      "Repeat 3 ld 20\n",
      "Num train: 7310 Num valid: 1852\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_20ld.h5\n",
      "Epoch 1/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4799val_aucs: 0.4522704887502654 0.8485094461112709\n",
      "229/229 [==============================] - 20s 58ms/step - loss: 0.4799 - custom_metric: 1.3008\n",
      "Epoch 2/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4121val_aucs: 0.4663204711207785 0.8632574356445138\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.4121 - custom_metric: 1.3296\n",
      "Epoch 3/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3909val_aucs: 0.47024920081545324 0.8659083747756635\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3909 - custom_metric: 1.3362\n",
      "Epoch 4/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3578val_aucs: 0.46175319761452394 0.8653124272190483\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3578 - custom_metric: 1.3271\n",
      "Epoch 5/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3245val_aucs: 0.4831670182381269 0.8659631745509843\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3245 - custom_metric: 1.3491\n",
      "Epoch 6/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3074val_aucs: 0.47593354254092907 0.8596372254873755\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3074 - custom_metric: 1.3356\n",
      "Epoch 7/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2779val_aucs: 0.49479533798534686 0.8644972805611497\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2779 - custom_metric: 1.3593\n",
      "Epoch 8/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2620val_aucs: 0.46233874803676733 0.8572739851766609\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2620 - custom_metric: 1.3196\n",
      "Epoch 9/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2340val_aucs: 0.4180055324512468 0.8465983039469539\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2340 - custom_metric: 1.2646\n",
      "Epoch 10/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2007val_aucs: 0.4412427589694788 0.838994835121176\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2007 - custom_metric: 1.2802\n",
      "Epoch 11/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2116val_aucs: 0.4647469006836582 0.8545973586508294\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2116 - custom_metric: 1.3193\n",
      "Epoch 12/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1659val_aucs: 0.4408120428134625 0.8496225665474773\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1659 - custom_metric: 1.2904\n",
      "Epoch 13/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1635val_aucs: 0.42192062578748885 0.8378474648253942\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1635 - custom_metric: 1.2598\n",
      "Epoch 14/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1573val_aucs: 0.3920652707463429 0.8472970010822956\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1573 - custom_metric: 1.2394\n",
      "Epoch 15/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1231val_aucs: 0.382628548327707 0.8273635828093105\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.1231 - custom_metric: 1.2100\n",
      "Epoch 16/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1851val_aucs: 0.4359442501263967 0.8368644938555752\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.1851 - custom_metric: 1.2728\n",
      "Epoch 17/1000\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.1184val_aucs: 0.432217113446979 0.839614757579494\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.1183 - custom_metric: 1.2718\n",
      "Test res 0.8739127386010052 0.4454336490942883 0.464354527938343\n",
      "[[0.8778769091820249, 0.4587387283117992, 0.4582933844678811], [0.8811266791826232, 0.478560401013453, 0.4902534113060429], [0.8777260071355911, 0.4590078157607206, 0.4580896686159844], [0.8739127386010052, 0.4454336490942883, 0.464354527938343]]\n",
      "Repeat 4 ld 20\n",
      "Num train: 7310 Num valid: 1852\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_20ld.h5\n",
      "Epoch 1/1000\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.4979val_aucs: 0.4053880696915418 0.8702855416762914\n",
      "229/229 [==============================] - 21s 59ms/step - loss: 0.4976 - custom_metric: 1.2757\n",
      "Epoch 2/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4177val_aucs: 0.45196089229593156 0.8898985411965387\n",
      "229/229 [==============================] - 11s 50ms/step - loss: 0.4177 - custom_metric: 1.3419\n",
      "Epoch 3/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3830val_aucs: 0.4742657098929657 0.8987721885605643\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3830 - custom_metric: 1.3730\n",
      "Epoch 4/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3647val_aucs: 0.4802056304411284 0.8872972156577054\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3647 - custom_metric: 1.3675\n",
      "Epoch 5/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3370val_aucs: 0.46580312619251796 0.8880612661916523\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3370 - custom_metric: 1.3539\n",
      "Epoch 6/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3057val_aucs: 0.43629365053921976 0.8781037331864461\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3057 - custom_metric: 1.3144\n",
      "Epoch 7/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2843val_aucs: 0.45049804817966066 0.8855701060786438\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2843 - custom_metric: 1.3361\n",
      "Epoch 8/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2565val_aucs: 0.41438471313117264 0.8812701007480588\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2565 - custom_metric: 1.2957\n",
      "Epoch 9/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2308val_aucs: 0.46037904359708853 0.884006467776613\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2308 - custom_metric: 1.3444\n",
      "Epoch 10/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2175val_aucs: 0.4436363570904356 0.8787647257413954\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2175 - custom_metric: 1.3224\n",
      "Epoch 11/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1847val_aucs: 0.45339285505421223 0.8833916736260417\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1847 - custom_metric: 1.3368\n",
      "Epoch 12/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1860val_aucs: 0.3948469142038893 0.8737966204090335\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1860 - custom_metric: 1.2686\n",
      "Epoch 13/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1541val_aucs: 0.4207387644104421 0.8824357220277547\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1541 - custom_metric: 1.3032\n",
      "Test res 0.879506772827908 0.4658651451630321 0.4668615984405458\n",
      "[[0.8778769091820249, 0.4587387283117992, 0.4582933844678811], [0.8811266791826232, 0.478560401013453, 0.4902534113060429], [0.8777260071355911, 0.4590078157607206, 0.4580896686159844], [0.8739127386010052, 0.4454336490942883, 0.464354527938343], [0.879506772827908, 0.4658651451630321, 0.4668615984405458]]\n",
      "Repeat 5 ld 20\n",
      "Num train: 7310 Num valid: 1852\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_20ld.h5\n",
      "Epoch 1/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4837val_aucs: 0.4678826191174651 0.880970988098476\n",
      "229/229 [==============================] - 20s 58ms/step - loss: 0.4837 - custom_metric: 1.3489\n",
      "Epoch 2/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4243val_aucs: 0.5160462948346723 0.9024295358853157\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.4243 - custom_metric: 1.4185\n",
      "Epoch 3/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3973val_aucs: 0.5443293289781018 0.9051286376765691\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3973 - custom_metric: 1.4495\n",
      "Epoch 4/1000\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.3626val_aucs: 0.5227360051766157 0.9042748401711725\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3623 - custom_metric: 1.4270\n",
      "Epoch 5/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3410val_aucs: 0.5242347783755357 0.9041887718742576\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3410 - custom_metric: 1.4284\n",
      "Epoch 6/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3186val_aucs: 0.4924096854488482 0.8954855456902161\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3186 - custom_metric: 1.3879\n",
      "Epoch 7/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2846val_aucs: 0.4731615642942105 0.8774628443162218\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2846 - custom_metric: 1.3506\n",
      "Epoch 8/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2706val_aucs: 0.46066090738698046 0.8733040242092905\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2706 - custom_metric: 1.3340\n",
      "Epoch 9/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2407val_aucs: 0.46028641227447215 0.8785300911979674\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2407 - custom_metric: 1.3388\n",
      "Epoch 10/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2228val_aucs: 0.446364174086944 0.867620073881026\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2228 - custom_metric: 1.3140\n",
      "Epoch 11/1000\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.2131val_aucs: 0.4540018938727636 0.8673343271352684\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2131 - custom_metric: 1.3213\n",
      "Epoch 12/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1861val_aucs: 0.48308216650977837 0.8831949928907586\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1861 - custom_metric: 1.3663\n",
      "Epoch 13/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1665val_aucs: 0.4466770419601821 0.869551446463798\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1665 - custom_metric: 1.3162\n",
      "Test res 0.8744880175921493 0.4598758806953375 0.470703125\n",
      "[[0.8778769091820249, 0.4587387283117992, 0.4582933844678811], [0.8811266791826232, 0.478560401013453, 0.4902534113060429], [0.8777260071355911, 0.4590078157607206, 0.4580896686159844], [0.8739127386010052, 0.4454336490942883, 0.464354527938343], [0.879506772827908, 0.4658651451630321, 0.4668615984405458], [0.8744880175921493, 0.4598758806953375, 0.470703125]]\n",
      "Repeat 6 ld 20\n",
      "Num train: 7310 Num valid: 1852\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_20ld.h5\n",
      "Epoch 1/1000\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.4987val_aucs: 0.46208445793377323 0.8732528558378926\n",
      "229/229 [==============================] - 21s 59ms/step - loss: 0.4981 - custom_metric: 1.3353\n",
      "Epoch 2/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4310val_aucs: 0.4570056082940831 0.8738683875361379\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.4310 - custom_metric: 1.3309\n",
      "Epoch 3/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3935val_aucs: 0.4686367049046412 0.8738585652218043\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3935 - custom_metric: 1.3425\n",
      "Epoch 4/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3768val_aucs: 0.46331994029005175 0.8779217292511795\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3768 - custom_metric: 1.3412\n",
      "Epoch 5/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3516val_aucs: 0.4461809399281416 0.8814184731539779\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3516 - custom_metric: 1.3276\n",
      "Epoch 6/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3178val_aucs: 0.43966472576623206 0.8669600264547667\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3178 - custom_metric: 1.3066\n",
      "Epoch 7/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2938val_aucs: 0.41943569771887407 0.8565581955753748\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2938 - custom_metric: 1.2760\n",
      "Epoch 8/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2765val_aucs: 0.4363213925754913 0.8754661506677537\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.2765 - custom_metric: 1.3118\n",
      "Epoch 9/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2465val_aucs: 0.3601152476562089 0.8400108700278628\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2465 - custom_metric: 1.2001\n",
      "Epoch 10/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2355val_aucs: 0.4353060084893048 0.8804624345588308\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.2355 - custom_metric: 1.3158\n",
      "Epoch 11/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2340val_aucs: 0.4141414825989948 0.8694025086190807\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2340 - custom_metric: 1.2835\n",
      "Epoch 12/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1920val_aucs: 0.42027231186868097 0.8751256437708519\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1920 - custom_metric: 1.2954\n",
      "Epoch 13/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1743val_aucs: 0.40832709478364987 0.8701653750323317\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1743 - custom_metric: 1.2785\n",
      "Test res 0.8650412129009095 0.45474830965964474 0.4716796875\n",
      "[[0.8778769091820249, 0.4587387283117992, 0.4582933844678811], [0.8811266791826232, 0.478560401013453, 0.4902534113060429], [0.8777260071355911, 0.4590078157607206, 0.4580896686159844], [0.8739127386010052, 0.4454336490942883, 0.464354527938343], [0.879506772827908, 0.4658651451630321, 0.4668615984405458], [0.8744880175921493, 0.4598758806953375, 0.470703125], [0.8650412129009095, 0.45474830965964474, 0.4716796875]]\n",
      "Repeat 7 ld 20\n",
      "Num train: 7310 Num valid: 1852\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_20ld.h5\n",
      "Epoch 1/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.5171val_aucs: 0.49974685251565565 0.8828214883483425\n",
      "229/229 [==============================] - 20s 58ms/step - loss: 0.5171 - custom_metric: 1.3826\n",
      "Epoch 2/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4439val_aucs: 0.4956823275076214 0.8805425357209276\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.4439 - custom_metric: 1.3762\n",
      "Epoch 3/1000\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.4111val_aucs: 0.4753686989402847 0.8718522557848517\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.4109 - custom_metric: 1.3472\n",
      "Epoch 4/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3860val_aucs: 0.49789646408245386 0.8837576556102266\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3860 - custom_metric: 1.3817\n",
      "Epoch 5/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3630val_aucs: 0.4998050603501904 0.8592439424934831\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3630 - custom_metric: 1.3590\n",
      "Epoch 6/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3306val_aucs: 0.5178666171143258 0.8729586352761695\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3306 - custom_metric: 1.3908\n",
      "Epoch 7/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3104val_aucs: 0.522674725637798 0.8656111407056242\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3104 - custom_metric: 1.3883\n",
      "Epoch 8/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2841val_aucs: 0.4536312276214118 0.8518271021998354\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2841 - custom_metric: 1.3055\n",
      "Epoch 9/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2617val_aucs: 0.5019142145596823 0.8577813781516843\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2617 - custom_metric: 1.3597\n",
      "Epoch 10/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2431val_aucs: 0.4885056274003832 0.8635654418740997\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2431 - custom_metric: 1.3521\n",
      "Epoch 11/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1957val_aucs: 0.4780088212132792 0.8451604565470243\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1957 - custom_metric: 1.3232\n",
      "Epoch 12/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2055val_aucs: 0.4317275235609019 0.8292330047817029\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.2055 - custom_metric: 1.2610\n",
      "Epoch 13/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1832val_aucs: 0.4558798868661495 0.8399910480975631\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1832 - custom_metric: 1.2959\n",
      "Epoch 14/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1542val_aucs: 0.46134157628629185 0.8465000898342322\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.1542 - custom_metric: 1.3078\n",
      "Epoch 15/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1955val_aucs: 0.47254408508544155 0.8503960586412651\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1955 - custom_metric: 1.3229\n",
      "Epoch 16/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1411val_aucs: 0.4583966616841845 0.8515812400906537\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.1411 - custom_metric: 1.3100\n",
      "Test res 0.859364061004069 0.43617620127394663 0.4521484375\n",
      "[[0.8778769091820249, 0.4587387283117992, 0.4582933844678811], [0.8811266791826232, 0.478560401013453, 0.4902534113060429], [0.8777260071355911, 0.4590078157607206, 0.4580896686159844], [0.8739127386010052, 0.4454336490942883, 0.464354527938343], [0.879506772827908, 0.4658651451630321, 0.4668615984405458], [0.8744880175921493, 0.4598758806953375, 0.470703125], [0.8650412129009095, 0.45474830965964474, 0.4716796875], [0.859364061004069, 0.43617620127394663, 0.4521484375]]\n",
      "Repeat 8 ld 20\n",
      "Num train: 7310 Num valid: 1852\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_20ld.h5\n",
      "Epoch 1/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.5012val_aucs: 0.5001133965100502 0.8797439759036145\n",
      "229/229 [==============================] - 20s 59ms/step - loss: 0.5012 - custom_metric: 1.3799\n",
      "Epoch 2/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4311val_aucs: 0.5169496181544991 0.8883691014056225\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.4311 - custom_metric: 1.4053\n",
      "Epoch 3/1000\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.4065val_aucs: 0.5241607981453534 0.8853570532128514\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.4073 - custom_metric: 1.4095\n",
      "Epoch 4/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3806val_aucs: 0.5082310500803895 0.8718938253012049\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3806 - custom_metric: 1.3801\n",
      "Epoch 5/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3565val_aucs: 0.5194589243558274 0.8775633785140562\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3565 - custom_metric: 1.3970\n",
      "Epoch 6/1000\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.3377val_aucs: 0.45864384707128203 0.8682668172690763\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3375 - custom_metric: 1.3269\n",
      "Epoch 7/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3092val_aucs: 0.49704897364383105 0.874121485943775\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3092 - custom_metric: 1.3712\n",
      "Epoch 8/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2847val_aucs: 0.46908009718989446 0.8708898092369478\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2847 - custom_metric: 1.3400\n",
      "Epoch 9/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2630val_aucs: 0.43971054562690354 0.8683044678714859\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2630 - custom_metric: 1.3080\n",
      "Epoch 10/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2438val_aucs: 0.4724939788188227 0.8717243975903615\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2438 - custom_metric: 1.3442\n",
      "Epoch 11/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2136val_aucs: 0.4826180517755074 0.860106049196787\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2136 - custom_metric: 1.3427\n",
      "Epoch 12/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2019val_aucs: 0.4707695966388278 0.868097389558233\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2019 - custom_metric: 1.3389\n",
      "Epoch 13/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1809val_aucs: 0.44323404029340274 0.854496109437751\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1809 - custom_metric: 1.2977\n",
      "Test res 0.87757823719483 0.46612887061530445 0.4805447470817121\n",
      "[[0.8778769091820249, 0.4587387283117992, 0.4582933844678811], [0.8811266791826232, 0.478560401013453, 0.4902534113060429], [0.8777260071355911, 0.4590078157607206, 0.4580896686159844], [0.8739127386010052, 0.4454336490942883, 0.464354527938343], [0.879506772827908, 0.4658651451630321, 0.4668615984405458], [0.8744880175921493, 0.4598758806953375, 0.470703125], [0.8650412129009095, 0.45474830965964474, 0.4716796875], [0.859364061004069, 0.43617620127394663, 0.4521484375], [0.87757823719483, 0.46612887061530445, 0.4805447470817121]]\n",
      "Repeat 9 ld 20\n",
      "Num train: 7310 Num valid: 1852\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_20ld.h5\n",
      "Epoch 1/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.5116val_aucs: 0.4588832060198463 0.8752186754336471\n",
      "229/229 [==============================] - 21s 58ms/step - loss: 0.5116 - custom_metric: 1.3341\n",
      "Epoch 2/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4313val_aucs: 0.48862485806973127 0.8861280185090039\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.4313 - custom_metric: 1.3748\n",
      "Epoch 3/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4049val_aucs: 0.4815636224874002 0.8773242637533056\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.4049 - custom_metric: 1.3589\n",
      "Epoch 4/1000\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.3735val_aucs: 0.502216982964511 0.8690973393306878\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3733 - custom_metric: 1.3713\n",
      "Epoch 5/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3390val_aucs: 0.4921981605380135 0.8737088299170058\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.3390 - custom_metric: 1.3659\n",
      "Epoch 6/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3195val_aucs: 0.489924530006084 0.8846496937755909\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.3195 - custom_metric: 1.3746\n",
      "Epoch 7/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2963val_aucs: 0.4625649393727116 0.8649649646494416\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2963 - custom_metric: 1.3275\n",
      "Epoch 8/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2782val_aucs: 0.4689542838027396 0.8648451856731736\n",
      "229/229 [==============================] - 11s 49ms/step - loss: 0.2782 - custom_metric: 1.3338\n",
      "Epoch 9/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2551val_aucs: 0.44759703027636666 0.8678900933330391\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2551 - custom_metric: 1.3155\n",
      "Epoch 10/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2212val_aucs: 0.4521414707245885 0.8567159756785635\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2212 - custom_metric: 1.3089\n",
      "Epoch 11/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2122val_aucs: 0.44267012674104256 0.8545378895574799\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.2122 - custom_metric: 1.2972\n",
      "Epoch 12/1000\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1854val_aucs: 0.460246754428754 0.8594330671928535\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 0.1854 - custom_metric: 1.3197\n",
      "Test res 0.8743629671044758 0.4708567390664532 0.494140625\n",
      "[[0.8778769091820249, 0.4587387283117992, 0.4582933844678811], [0.8811266791826232, 0.478560401013453, 0.4902534113060429], [0.8777260071355911, 0.4590078157607206, 0.4580896686159844], [0.8739127386010052, 0.4454336490942883, 0.464354527938343], [0.879506772827908, 0.4658651451630321, 0.4668615984405458], [0.8744880175921493, 0.4598758806953375, 0.470703125], [0.8650412129009095, 0.45474830965964474, 0.4716796875], [0.859364061004069, 0.43617620127394663, 0.4521484375], [0.87757823719483, 0.46612887061530445, 0.4805447470817121], [0.8743629671044758, 0.4708567390664532, 0.494140625]]\n",
      "gen_res {20: [(0.8740983602725585, 0.006462064596868624), (0.4595391740653979, 0.011584988146893089), (0.4707069212850509, 0.013197653342556785)]}\n"
     ]
    }
   ],
   "source": [
    "repeats = {k:10 for k in [10,20,30,40,50,60,70,80,90,100]}\n",
    "lds = [20]\n",
    "batch_size, lr, patience = 32, 0.0005, 10\n",
    "d, N, he, dropout = 50,2,4,0.2\n",
    "\n",
    "# best val model\n",
    "fore_savepath = 'Exp1/Exp_M_Q/models/forecasting/forecasting_25_epochs.h5'\n",
    "\n",
    "f = open('Exp1/Exp_M_Q/logs/log_text_'+ str(lds[0]) +'.csv', 'a+')\n",
    "f.write('\\nTraining on different % of labeled data\\n')\n",
    "\n",
    "train_inds = np.arange(len(train_op))\n",
    "valid_inds = np.arange(len(valid_op))\n",
    "gen_res = {}\n",
    "\n",
    "np.random.seed(2023)\n",
    "for ld in lds:\n",
    "    np.random.shuffle(train_inds)\n",
    "    np.random.shuffle(valid_inds)\n",
    "    train_starts = [int(i) for i in np.linspace(0, len(train_inds)-int(ld*len(train_inds)/100), repeats[ld])]\n",
    "    valid_starts = [int(i) for i in np.linspace(0, len(valid_inds)-int(ld*len(valid_inds)/100), repeats[ld])]\n",
    "    f.write('Training on '+str(ld)+' % of labaled data+\\n'+'val_metric,roc_auc,pr_auc,min_rp,savepath\\n')\n",
    "    all_test_res = []\n",
    "    for i in range(repeats[ld]):\n",
    "        print ('Repeat', i, 'ld', ld)\n",
    "        # Get train and validation data.\n",
    "        curr_train_ind = train_inds[np.arange(train_starts[i], train_starts[i]+int(ld*len(train_inds)/100))]\n",
    "        curr_valid_ind = valid_inds[np.arange(valid_starts[i], valid_starts[i]+int(ld*len(valid_inds)/100))]\n",
    "        curr_train_ip = [ip[curr_train_ind] for ip in train_ip]\n",
    "        curr_valid_ip = [ip[curr_valid_ind] for ip in valid_ip]\n",
    "        curr_train_op = train_op[curr_train_ind]\n",
    "        curr_valid_op = valid_op[curr_valid_ind]\n",
    "        print ('Num train:',len(curr_train_op),'Num valid:',len(curr_valid_op))\n",
    "        # Construct save_path.\n",
    "        savepath = 'Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat'+str(i)+'_'+str(ld)+'ld'+'.h5'\n",
    "        print (savepath)\n",
    "        # Build and compile model.\n",
    "        model, fore_model =  build_strats(D, max_len, V, d, N, he, dropout, forecast=True)\n",
    "        model.compile(loss=mortality_loss, optimizer=Adam(lr))\n",
    "        fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "        # Load pretrained weights here.\n",
    "        fore_model.load_weights(fore_savepath)\n",
    "        # Train model.\n",
    "        es = EarlyStopping(monitor='custom_metric', patience=patience, mode='max', \n",
    "                           restore_best_weights=True)\n",
    "        cus = CustomCallback(validation_data=(curr_valid_ip, curr_valid_op), batch_size=batch_size)\n",
    "        his = model.fit(curr_train_ip, curr_train_op, batch_size=batch_size, epochs=1000,\n",
    "                        verbose=1, callbacks=[cus, es]).history\n",
    "        model.save_weights(savepath)\n",
    "        # Test and write to log.\n",
    "        rocauc, prauc, minrp = get_res(test_op, model.predict(test_ip, verbose=0, batch_size=batch_size))\n",
    "        f.write(str(np.min(his['custom_metric']))+str(rocauc)+str(prauc)+str(minrp)+savepath+'\\n')\n",
    "        print ('Test res', rocauc, prauc, minrp)\n",
    "        all_test_res.append([rocauc, prauc, minrp])\n",
    "        \n",
    "        # in case of unexpected disconnection\n",
    "        print(all_test_res)\n",
    "        \n",
    "    gen_res[ld] = []\n",
    "    for i in range(len(all_test_res[0])):\n",
    "        nums = [test_res[i] for test_res in all_test_res]\n",
    "        gen_res[ld].append((np.mean(nums), np.std(nums)))\n",
    "    print ('gen_res', gen_res)\n",
    "f.close()\n",
    "\n",
    "# # save to local\n",
    "# log_path = '/content/log.csv'\n",
    "# files.download(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 0 ld 30\n",
      "Num train: 10965 Num valid: 2778\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_30ld.h5\n",
      "Epoch 1/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.5055val_aucs: 0.5045328511822311 0.8851243355203294\n",
      "343/343 [==============================] - 25s 55ms/step - loss: 0.5055 - custom_metric: 1.3897\n",
      "Epoch 2/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.4434val_aucs: 0.5212324625901905 0.894464465303386\n",
      "343/343 [==============================] - 17s 49ms/step - loss: 0.4434 - custom_metric: 1.4157\n",
      "Epoch 3/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.4106val_aucs: 0.5320945444388638 0.8965387194099901\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.4106 - custom_metric: 1.4286\n",
      "Epoch 4/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3921val_aucs: 0.5186734529497959 0.8913560772951487\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.3921 - custom_metric: 1.4100\n",
      "Epoch 5/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3703val_aucs: 0.542905057870522 0.8913246492026243\n",
      "343/343 [==============================] - 17s 50ms/step - loss: 0.3703 - custom_metric: 1.4342\n",
      "Epoch 6/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3558val_aucs: 0.5207440865204275 0.8833718452181408\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.3558 - custom_metric: 1.4041\n",
      "Epoch 7/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3341val_aucs: 0.5287545533157181 0.8906003064987308\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.3341 - custom_metric: 1.4194\n",
      "Epoch 8/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3181val_aucs: 0.5289052405603668 0.8945048728509171\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.3181 - custom_metric: 1.4234\n",
      "Epoch 9/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2861val_aucs: 0.514377062298337 0.877641456347876\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.2861 - custom_metric: 1.3920\n",
      "Epoch 10/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2674val_aucs: 0.4975084105958031 0.8770233705282313\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2674 - custom_metric: 1.3745\n",
      "Epoch 11/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2531val_aucs: 0.5175946841483211 0.8807348785977682\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2531 - custom_metric: 1.3983\n",
      "Epoch 12/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2354val_aucs: 0.4940730760989068 0.8724498347780278\n",
      "343/343 [==============================] - 17s 49ms/step - loss: 0.2354 - custom_metric: 1.3665\n",
      "Epoch 13/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2158val_aucs: 0.5005064177501826 0.8743998730903693\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2158 - custom_metric: 1.3749\n",
      "Epoch 14/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.1979val_aucs: 0.48373352067846953 0.8620710813658351\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.1979 - custom_metric: 1.3458\n",
      "Epoch 15/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.1749val_aucs: 0.5023580881143418 0.8729407116517408\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.1749 - custom_metric: 1.3753\n",
      "Test res 0.8859952335896364 0.5013008256447689 0.48588120740019475\n",
      "[[0.8859952335896364, 0.5013008256447689, 0.48588120740019475]]\n",
      "Repeat 1 ld 30\n",
      "Num train: 10965 Num valid: 2778\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_30ld.h5\n",
      "Epoch 1/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.4873val_aucs: 0.486362936806369 0.8887840206483425\n",
      "343/343 [==============================] - 26s 56ms/step - loss: 0.4873 - custom_metric: 1.3751\n",
      "Epoch 2/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.4263val_aucs: 0.5231145595734813 0.8979806525504467\n",
      "343/343 [==============================] - 17s 49ms/step - loss: 0.4263 - custom_metric: 1.4211\n",
      "Epoch 3/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.4014val_aucs: 0.5523269949406234 0.9032760871272342\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.4014 - custom_metric: 1.4556\n",
      "Epoch 4/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3731val_aucs: 0.5402189179651478 0.9014121652756396\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.3731 - custom_metric: 1.4416\n",
      "Epoch 5/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3644val_aucs: 0.5361939154884517 0.90212039631305\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.3644 - custom_metric: 1.4383\n",
      "Epoch 6/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3422val_aucs: 0.5076014749304502 0.8984547821152401\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.3422 - custom_metric: 1.4061\n",
      "Epoch 7/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3309val_aucs: 0.5196788680987159 0.8989407649191535\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.3309 - custom_metric: 1.4186\n",
      "Epoch 8/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3058val_aucs: 0.508777964730119 0.8876016600461387\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.3058 - custom_metric: 1.3964\n",
      "Epoch 9/1000\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.2876val_aucs: 0.4677525847474641 0.8842531199947847\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.2880 - custom_metric: 1.3520\n",
      "Epoch 10/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2670val_aucs: 0.5286738833674723 0.8934127105246392\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.2670 - custom_metric: 1.4221\n",
      "Epoch 11/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2460val_aucs: 0.4867778244879013 0.8868682408755987\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.2460 - custom_metric: 1.3736\n",
      "Epoch 12/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2223val_aucs: 0.5088330628011338 0.8897663578403991\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.2223 - custom_metric: 1.3986\n",
      "Epoch 13/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2156val_aucs: 0.4810959882474351 0.8783324270544256\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.2156 - custom_metric: 1.3594\n",
      "Test res 0.8859689145524173 0.4808535652665493 0.49131274131274133\n",
      "[[0.8859952335896364, 0.5013008256447689, 0.48588120740019475], [0.8859689145524173, 0.4808535652665493, 0.49131274131274133]]\n",
      "Repeat 2 ld 30\n",
      "Num train: 10965 Num valid: 2778\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_30ld.h5\n",
      "Epoch 1/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.4845val_aucs: 0.4713740983955335 0.8656956094890028\n",
      "343/343 [==============================] - 26s 55ms/step - loss: 0.4845 - custom_metric: 1.3371\n",
      "Epoch 2/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.4152val_aucs: 0.4887931758737765 0.877879943538167\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.4152 - custom_metric: 1.3667\n",
      "Epoch 3/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3846val_aucs: 0.5209901544033949 0.8882464891661283\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.3846 - custom_metric: 1.4092\n",
      "Epoch 4/1000\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.3693val_aucs: 0.4993833445990787 0.8922618145208178\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.3689 - custom_metric: 1.3916\n",
      "Epoch 5/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3508val_aucs: 0.5179369075585545 0.888175838280122\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.3508 - custom_metric: 1.4061\n",
      "Epoch 6/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3277val_aucs: 0.520402619339434 0.8921381754703069\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.3277 - custom_metric: 1.4125\n",
      "Epoch 7/1000\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.3192val_aucs: 0.4995519847681849 0.8837925395608165\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.3188 - custom_metric: 1.3833\n",
      "Epoch 8/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2892val_aucs: 0.5120617421517863 0.8794960825555603\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2892 - custom_metric: 1.3916\n",
      "Epoch 9/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2754val_aucs: 0.49684479998661507 0.8780830648354349\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.2754 - custom_metric: 1.3749\n",
      "Epoch 10/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2564val_aucs: 0.4728300414359044 0.8749920885726608\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2564 - custom_metric: 1.3478\n",
      "Epoch 11/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2394val_aucs: 0.45852125710039976 0.8685981833890934\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2394 - custom_metric: 1.3271\n",
      "Epoch 12/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2213val_aucs: 0.4316776828567251 0.8671027396352942\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2213 - custom_metric: 1.2988\n",
      "Epoch 13/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2018val_aucs: 0.47886085828885944 0.8788587526880454\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2018 - custom_metric: 1.3577\n",
      "Epoch 14/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.1787val_aucs: 0.45947641485785484 0.8721675250258686\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.1787 - custom_metric: 1.3316\n",
      "Epoch 15/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.1848val_aucs: 0.46917023244466116 0.8803350618268848\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.1848 - custom_metric: 1.3495\n",
      "Epoch 16/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.1719val_aucs: 0.3958523357471823 0.859547510512999\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.1719 - custom_metric: 1.2554\n",
      "Test res 0.8800799481659884 0.4542558074010709 0.4765625\n",
      "[[0.8859952335896364, 0.5013008256447689, 0.48588120740019475], [0.8859689145524173, 0.4808535652665493, 0.49131274131274133], [0.8800799481659884, 0.4542558074010709, 0.4765625]]\n",
      "Repeat 3 ld 30\n",
      "Num train: 10965 Num valid: 2778\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_30ld.h5\n",
      "Epoch 1/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.4757val_aucs: 0.48444850549658286 0.8758497866493095\n",
      "343/343 [==============================] - 25s 56ms/step - loss: 0.4757 - custom_metric: 1.3603\n",
      "Epoch 2/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.4026val_aucs: 0.52510461521298 0.8887804054868494\n",
      "343/343 [==============================] - 17s 49ms/step - loss: 0.4026 - custom_metric: 1.4139\n",
      "Epoch 3/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3813val_aucs: 0.523313499775801 0.8871637014536775\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.3813 - custom_metric: 1.4105\n",
      "Epoch 4/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3564val_aucs: 0.5258669137597254 0.8931619295581109\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.3564 - custom_metric: 1.4190\n",
      "Epoch 5/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3328val_aucs: 0.4862934604428955 0.8765880764687447\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.3328 - custom_metric: 1.3629\n",
      "Epoch 6/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3104val_aucs: 0.49571921001739194 0.8817787059135508\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.3104 - custom_metric: 1.3775\n",
      "Epoch 7/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2860val_aucs: 0.47618911970068145 0.8797597092644824\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.2860 - custom_metric: 1.3559\n",
      "Epoch 8/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2756val_aucs: 0.4565999793449421 0.875756370386442\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2756 - custom_metric: 1.3324\n",
      "Epoch 9/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2543val_aucs: 0.4760120936731716 0.8719489043176395\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.2543 - custom_metric: 1.3480\n",
      "Epoch 10/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2281val_aucs: 0.45591534288425895 0.8650436344350425\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2281 - custom_metric: 1.3210\n",
      "Epoch 11/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2142val_aucs: 0.43715994160872285 0.8700835924881271\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2142 - custom_metric: 1.3072\n",
      "Epoch 12/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.1940val_aucs: 0.4603084073680399 0.8609830404281478\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.1940 - custom_metric: 1.3213\n",
      "Epoch 13/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.1643val_aucs: 0.4844883663401313 0.8715134639955643\n",
      "343/343 [==============================] - 17s 49ms/step - loss: 0.1643 - custom_metric: 1.3560\n",
      "Epoch 14/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.1611val_aucs: 0.4198407717181627 0.8550179600298933\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.1611 - custom_metric: 1.2749\n",
      "Test res 0.8860218331139302 0.4902320883039147 0.5029296875\n",
      "[[0.8859952335896364, 0.5013008256447689, 0.48588120740019475], [0.8859689145524173, 0.4808535652665493, 0.49131274131274133], [0.8800799481659884, 0.4542558074010709, 0.4765625], [0.8860218331139302, 0.4902320883039147, 0.5029296875]]\n",
      "Repeat 4 ld 30\n",
      "Num train: 10965 Num valid: 2778\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_30ld.h5\n",
      "Epoch 1/1000\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.4805val_aucs: 0.47791003004508964 0.8826411728297674\n",
      "343/343 [==============================] - 26s 55ms/step - loss: 0.4801 - custom_metric: 1.3606\n",
      "Epoch 2/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.4128val_aucs: 0.49020485143881387 0.8919404361703418\n",
      "343/343 [==============================] - 17s 49ms/step - loss: 0.4128 - custom_metric: 1.3821\n",
      "Epoch 3/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3834val_aucs: 0.4929670254295561 0.891846381630845\n",
      "343/343 [==============================] - 17s 49ms/step - loss: 0.3834 - custom_metric: 1.3848\n",
      "Epoch 4/1000\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.3582val_aucs: 0.4984298024175664 0.8983285598126192\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.3584 - custom_metric: 1.3968\n",
      "Epoch 5/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3363val_aucs: 0.5088079702451409 0.8913533538028373\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.3363 - custom_metric: 1.4002\n",
      "Epoch 6/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3103val_aucs: 0.492793842923704 0.8886121190791151\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.3103 - custom_metric: 1.3814\n",
      "Epoch 7/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2976val_aucs: 0.48952258149834776 0.8906373256957001\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2976 - custom_metric: 1.3802\n",
      "Epoch 8/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2799val_aucs: 0.47507887052694686 0.8878718188327528\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.2799 - custom_metric: 1.3630\n",
      "Epoch 9/1000\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.2572val_aucs: 0.4568567402329671 0.8800637750458137\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2579 - custom_metric: 1.3369\n",
      "Epoch 10/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2379val_aucs: 0.4412661763917894 0.8792506583817765\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2379 - custom_metric: 1.3205\n",
      "Epoch 11/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2174val_aucs: 0.4617634028077839 0.8829400235439752\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2174 - custom_metric: 1.3447\n",
      "Epoch 12/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2024val_aucs: 0.42369232602516216 0.872157125693273\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.2024 - custom_metric: 1.2958\n",
      "Epoch 13/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.1908val_aucs: 0.45269351092113846 0.8699210548671706\n",
      "343/343 [==============================] - 17s 49ms/step - loss: 0.1908 - custom_metric: 1.3226\n",
      "Epoch 14/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.1675val_aucs: 0.42223555042168054 0.868250828286751\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.1675 - custom_metric: 1.2905\n",
      "Epoch 15/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.1525val_aucs: 0.46547278413217863 0.8761787157611136\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.1525 - custom_metric: 1.3417\n",
      "Test res 0.882776971637147 0.48217720333305586 0.4868292682926829\n",
      "[[0.8859952335896364, 0.5013008256447689, 0.48588120740019475], [0.8859689145524173, 0.4808535652665493, 0.49131274131274133], [0.8800799481659884, 0.4542558074010709, 0.4765625], [0.8860218331139302, 0.4902320883039147, 0.5029296875], [0.882776971637147, 0.48217720333305586, 0.4868292682926829]]\n",
      "Repeat 5 ld 30\n",
      "Num train: 10965 Num valid: 2778\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_30ld.h5\n",
      "Epoch 1/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.5011val_aucs: 0.45585014950346103 0.8811651650006013\n",
      "343/343 [==============================] - 26s 56ms/step - loss: 0.5011 - custom_metric: 1.3370\n",
      "Epoch 2/1000\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.4283val_aucs: 0.48346125592856387 0.8831082737005224\n",
      "343/343 [==============================] - 17s 49ms/step - loss: 0.4278 - custom_metric: 1.3666\n",
      "Epoch 3/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3927val_aucs: 0.5160423611559278 0.896384280380006\n",
      "343/343 [==============================] - 17s 49ms/step - loss: 0.3927 - custom_metric: 1.4124\n",
      "Epoch 4/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3726val_aucs: 0.48163652354942776 0.8882921802242834\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.3726 - custom_metric: 1.3699\n",
      "Epoch 5/1000\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.3524val_aucs: 0.4853526884540983 0.8875858720090358\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.3529 - custom_metric: 1.3729\n",
      "Epoch 6/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3325val_aucs: 0.4459324160967767 0.8790903846183119\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.3325 - custom_metric: 1.3250\n",
      "Epoch 7/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3044val_aucs: 0.4524158266299169 0.8741325271677497\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.3044 - custom_metric: 1.3265\n",
      "Epoch 8/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2904val_aucs: 0.48464943050067893 0.8838001208639488\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.2904 - custom_metric: 1.3684\n",
      "Epoch 9/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2673val_aucs: 0.4577436408969777 0.8815700744515836\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2673 - custom_metric: 1.3393\n",
      "Epoch 10/1000\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.2453val_aucs: 0.4637980877087247 0.8800356807425977\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.2454 - custom_metric: 1.3438\n",
      "Epoch 11/1000\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.2306val_aucs: 0.44404479197781443 0.8767202943356821\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.2304 - custom_metric: 1.3208\n",
      "Epoch 12/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2111val_aucs: 0.41064644629439606 0.8689158930003943\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2111 - custom_metric: 1.2796\n",
      "Epoch 13/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2064val_aucs: 0.3985750942641166 0.8697089675265665\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.2064 - custom_metric: 1.2683\n",
      "Test res 0.8850763111835805 0.4762306663567769 0.481086323957323\n",
      "[[0.8859952335896364, 0.5013008256447689, 0.48588120740019475], [0.8859689145524173, 0.4808535652665493, 0.49131274131274133], [0.8800799481659884, 0.4542558074010709, 0.4765625], [0.8860218331139302, 0.4902320883039147, 0.5029296875], [0.882776971637147, 0.48217720333305586, 0.4868292682926829], [0.8850763111835805, 0.4762306663567769, 0.481086323957323]]\n",
      "Repeat 6 ld 30\n",
      "Num train: 10965 Num valid: 2778\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_30ld.h5\n",
      "Epoch 1/1000\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.5184val_aucs: 0.4917052160089305 0.8911021582733812\n",
      "343/343 [==============================] - 25s 55ms/step - loss: 0.5180 - custom_metric: 1.3828\n",
      "Epoch 2/1000\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.4382val_aucs: 0.5008359058115653 0.8957812949640287\n",
      "343/343 [==============================] - 17s 49ms/step - loss: 0.4385 - custom_metric: 1.3966\n",
      "Epoch 3/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.4123val_aucs: 0.48606445486337846 0.8998187050359713\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.4123 - custom_metric: 1.3859\n",
      "Epoch 4/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3881val_aucs: 0.5181757342300976 0.9042402877697842\n",
      "343/343 [==============================] - 17s 49ms/step - loss: 0.3881 - custom_metric: 1.4224\n",
      "Epoch 5/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3648val_aucs: 0.5143182164649769 0.9023007194244604\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.3648 - custom_metric: 1.4166\n",
      "Epoch 6/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3489val_aucs: 0.4514460023010718 0.8822489208633093\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.3489 - custom_metric: 1.3337\n",
      "Epoch 7/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3282val_aucs: 0.4665551444131368 0.8959496402877697\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.3282 - custom_metric: 1.3625\n",
      "Epoch 8/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.3092val_aucs: 0.49028865943572564 0.8921517985611511\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.3092 - custom_metric: 1.3824\n",
      "Epoch 9/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2899val_aucs: 0.5079197180224688 0.8939856115107915\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2899 - custom_metric: 1.4019\n",
      "Epoch 10/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2632val_aucs: 0.4670871716365595 0.8850561151079137\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2632 - custom_metric: 1.3521\n",
      "Epoch 11/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2560val_aucs: 0.44710331435909545 0.8813582733812948\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2560 - custom_metric: 1.3285\n",
      "Epoch 12/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2256val_aucs: 0.4540379972290708 0.8749928057553956\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2256 - custom_metric: 1.3290\n",
      "Epoch 13/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.2017val_aucs: 0.4299023115202753 0.8735338129496403\n",
      "343/343 [==============================] - 16s 48ms/step - loss: 0.2017 - custom_metric: 1.3034\n",
      "Epoch 14/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.1760val_aucs: 0.4454941116160872 0.8652071942446042\n",
      "343/343 [==============================] - 17s 48ms/step - loss: 0.1760 - custom_metric: 1.3107\n",
      "Test res 0.8833373848133078 0.49287824290934645 0.4874031007751938\n",
      "[[0.8859952335896364, 0.5013008256447689, 0.48588120740019475], [0.8859689145524173, 0.4808535652665493, 0.49131274131274133], [0.8800799481659884, 0.4542558074010709, 0.4765625], [0.8860218331139302, 0.4902320883039147, 0.5029296875], [0.882776971637147, 0.48217720333305586, 0.4868292682926829], [0.8850763111835805, 0.4762306663567769, 0.481086323957323], [0.8833373848133078, 0.49287824290934645, 0.4874031007751938]]\n",
      "Repeat 7 ld 30\n",
      "Num train: 10965 Num valid: 2778\n",
      "Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_30ld.h5\n",
      "Epoch 1/1000\n",
      "343/343 [==============================] - ETA: 0s - loss: 0.5006"
     ]
    }
   ],
   "source": [
    "repeats = {k:10 for k in [10,20,30,40,50,60,70,80,90,100]}\n",
    "lds = [30]\n",
    "batch_size, lr, patience = 32, 0.0005, 10\n",
    "d, N, he, dropout = 50,2,4,0.2\n",
    "\n",
    "# best val model\n",
    "fore_savepath = 'Exp1/Exp_M_Q/models/forecasting/forecasting_25_epochs.h5'\n",
    "\n",
    "f = open('Exp1/Exp_M_Q/logs/log_text_'+ str(lds[0]) +'.csv', 'a+')\n",
    "f.write('\\nTraining on different % of labeled data\\n')\n",
    "\n",
    "train_inds = np.arange(len(train_op))\n",
    "valid_inds = np.arange(len(valid_op))\n",
    "gen_res = {}\n",
    "\n",
    "np.random.seed(2023)\n",
    "for ld in lds:\n",
    "    np.random.shuffle(train_inds)\n",
    "    np.random.shuffle(valid_inds)\n",
    "    train_starts = [int(i) for i in np.linspace(0, len(train_inds)-int(ld*len(train_inds)/100), repeats[ld])]\n",
    "    valid_starts = [int(i) for i in np.linspace(0, len(valid_inds)-int(ld*len(valid_inds)/100), repeats[ld])]\n",
    "    f.write('Training on '+str(ld)+' % of labaled data+\\n'+'val_metric,roc_auc,pr_auc,min_rp,savepath\\n')\n",
    "    all_test_res = []\n",
    "    for i in range(repeats[ld]):\n",
    "        print ('Repeat', i, 'ld', ld)\n",
    "        # Get train and validation data.\n",
    "        curr_train_ind = train_inds[np.arange(train_starts[i], train_starts[i]+int(ld*len(train_inds)/100))]\n",
    "        curr_valid_ind = valid_inds[np.arange(valid_starts[i], valid_starts[i]+int(ld*len(valid_inds)/100))]\n",
    "        curr_train_ip = [ip[curr_train_ind] for ip in train_ip]\n",
    "        curr_valid_ip = [ip[curr_valid_ind] for ip in valid_ip]\n",
    "        curr_train_op = train_op[curr_train_ind]\n",
    "        curr_valid_op = valid_op[curr_valid_ind]\n",
    "        print ('Num train:',len(curr_train_op),'Num valid:',len(curr_valid_op))\n",
    "        # Construct save_path.\n",
    "        savepath = 'Exp1/Exp_M_Q/models/classification/new_mimic_iii_24hm_strats_no_interp_with_ss_repeat'+str(i)+'_'+str(ld)+'ld'+'.h5'\n",
    "        print (savepath)\n",
    "        # Build and compile model.\n",
    "        model, fore_model =  build_strats(D, max_len, V, d, N, he, dropout, forecast=True)\n",
    "        model.compile(loss=mortality_loss, optimizer=Adam(lr))\n",
    "        fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "        # Load pretrained weights here.\n",
    "        fore_model.load_weights(fore_savepath)\n",
    "        # Train model.\n",
    "        es = EarlyStopping(monitor='custom_metric', patience=patience, mode='max', \n",
    "                           restore_best_weights=True)\n",
    "        cus = CustomCallback(validation_data=(curr_valid_ip, curr_valid_op), batch_size=batch_size)\n",
    "        his = model.fit(curr_train_ip, curr_train_op, batch_size=batch_size, epochs=1000,\n",
    "                        verbose=1, callbacks=[cus, es]).history\n",
    "        model.save_weights(savepath)\n",
    "        # Test and write to log.\n",
    "        rocauc, prauc, minrp = get_res(test_op, model.predict(test_ip, verbose=0, batch_size=batch_size))\n",
    "        f.write(str(np.min(his['custom_metric']))+str(rocauc)+str(prauc)+str(minrp)+savepath+'\\n')\n",
    "        print ('Test res', rocauc, prauc, minrp)\n",
    "        all_test_res.append([rocauc, prauc, minrp])\n",
    "        \n",
    "        # in case of unexpected disconnection\n",
    "        print(all_test_res)\n",
    "        \n",
    "    gen_res[ld] = []\n",
    "    for i in range(len(all_test_res[0])):\n",
    "        nums = [test_res[i] for test_res in all_test_res]\n",
    "        gen_res[ld].append((np.mean(nums), np.std(nums)))\n",
    "    print ('gen_res', gen_res)\n",
    "f.close()\n",
    "\n",
    "# # save to local\n",
    "# log_path = '/content/log.csv'\n",
    "# files.download(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_res {30: [(0.8821276487329464, 0.003922290391139405), (0.4804192653849372, 0.014892364470943999), (0.4837907200380675, 0.012114220125317626)]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "gen_res = {}\n",
    "ld = 30\n",
    "gen_res[ld] = []\n",
    "all_test_res = [[0.8859952335896364, 0.5013008256447689, 0.48588120740019475], [0.8859689145524173, 0.4808535652665493, 0.49131274131274133], [0.8800799481659884, 0.4542558074010709, 0.4765625], [0.8860218331139302, 0.4902320883039147, 0.5029296875], [0.882776971637147, 0.48217720333305586, 0.4868292682926829], [0.8850763111835805, 0.4762306663567769, 0.481086323957323], [0.8833373848133078, 0.49287824290934645, 0.4874031007751938]]+[[0.873752720724629, 0.45307632147149174, 0.453125], [0.8808834968884635, 0.48731080428512497, 0.4878993223620523], [0.8773836726603639, 0.4858771288772714, 0.4848780487804878]]\n",
    "\n",
    "for i in range(len(all_test_res[0])):\n",
    "    nums = [test_res[i] for test_res in all_test_res]\n",
    "    gen_res[ld].append((np.mean(nums), np.std(nums)))\n",
    "print ('gen_res', gen_res)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
